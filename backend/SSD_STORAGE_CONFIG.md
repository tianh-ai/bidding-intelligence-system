# ğŸ“‹ æŠ•æ ‡æ™ºèƒ½ç³»ç»Ÿ - SSDå­˜å‚¨é…ç½®å®Œæˆæ–‡æ¡£

**é…ç½®æ—¥æœŸ**: 2025å¹´12æœˆ12æ—¥  
**é…ç½®çŠ¶æ€**: âœ… å®Œæˆå¹¶éªŒè¯  
**å­˜å‚¨æ–¹æ¡ˆ**: SSDç›˜é›†ä¸­å­˜å‚¨

---

## ğŸ“Š å­˜å‚¨æ¶æ„æ€»è§ˆ

### å­˜å‚¨ä½ç½®å±‚çº§ç»“æ„

```
/Volumes/ssd/bidding-data/
â”œâ”€â”€ uploads/                    # æ–‡ä»¶ä¸Šä¼ ç›®å½• (1.8TB SSDå¯ç”¨ç©ºé—´)
â”‚   â”œâ”€â”€ *.pdf                   # åŸå§‹PDFæ–‡ä»¶
â”‚   â”œâ”€â”€ *.docx                  # Wordæ–‡æ¡£
â”‚   â””â”€â”€ temp/                   # ä¸´æ—¶æ–‡ä»¶å¤„ç†ç›®å½•
â”œâ”€â”€ parsed/                     # è§£æç»“æœç›®å½•
â”‚   â”œâ”€â”€ *.json                  # ç»“æ„åŒ–è§£æç»“æœ
â”‚   â””â”€â”€ *.pkl                   # åºåˆ—åŒ–å¯¹è±¡
â”œâ”€â”€ archive/                    # å½’æ¡£æ–‡ä»¶ç›®å½•
â”‚   â””â”€â”€ *.tar.gz                # å‹ç¼©å½’æ¡£
â”œâ”€â”€ logs/                       # æ—¥å¿—æ–‡ä»¶ç›®å½•
â”‚   â”œâ”€â”€ app.log                 # åº”ç”¨æ—¥å¿—
â”‚   â”œâ”€â”€ error.log               # é”™è¯¯æ—¥å¿—
â”‚   â””â”€â”€ access.log              # è®¿é—®æ—¥å¿—
â””â”€â”€ db/                         # æ•°æ®åº“å¤‡ä»½ç›®å½•
    â””â”€â”€ *.sql.gz                # æ•°æ®åº“å¤‡ä»½
```

---

## ğŸ”§ é…ç½®æ–‡ä»¶ä¿®æ”¹æ¸…å•

### 1. backend/core/config.py

**ä¿®æ”¹å†…å®¹**:
```python
# ä¸Šä¼ è·¯å¾„ (åŸ: "./uploads", ç°: "/Volumes/ssd/bidding-data/uploads")
UPLOAD_DIR: str = "/Volumes/ssd/bidding-data/uploads"

# æ—¥å¿—è·¯å¾„ (åŸ: "logs", ç°: "/Volumes/ssd/bidding-data/logs")
LOG_DIR: str = "/Volumes/ssd/bidding-data/logs"
```

**å½±å“èŒƒå›´**: 
- æ‰€æœ‰æ–‡ä»¶ä¸Šä¼ æ“ä½œ
- æ‰€æœ‰æ—¥å¿—è®°å½•

### 2. backend/.env.example

**æ–°å¢é…ç½®**:
```
UPLOAD_DIR=/Volumes/ssd/bidding-data/uploads
PARSED_DIR=/Volumes/ssd/bidding-data/parsed
ARCHIVE_DIR=/Volumes/ssd/bidding-data/archive
LOG_DIR=/Volumes/ssd/bidding-data/logs
```

### 3. backend/routers/files.py

**ä¿®æ”¹å†…å®¹**:
```python
# æ–‡ä»¶è·¯ç”±ä¸­çš„ç›®å½•é…ç½® (åŸ: ç›¸å¯¹è·¯å¾„, ç°: ç»å¯¹SSDè·¯å¾„)
UPLOAD_DIR = "/Volumes/ssd/bidding-data/uploads"
TEMP_DIR = "/Volumes/ssd/bidding-data/uploads/temp"
PARSED_DIR = "/Volumes/ssd/bidding-data/parsed"
ARCHIVE_DIR = "/Volumes/ssd/bidding-data/archive"
```

---

## ğŸ’¾ æ•°æ®åº“å­˜å‚¨é…ç½®

### PostgreSQLæ•°æ®åº“

**è¿æ¥ä¿¡æ¯**:
```
ä¸»æœºå    : localhost
ç«¯å£      : 5432
æ•°æ®åº“    : bidding_db
ç”¨æˆ·å    : postgres
é©±åŠ¨      : psycopg2 (å·²å®‰è£…)
```

**æ•°æ®åº“è¡¨**:
- `knowledge_base`      - çŸ¥è¯†åº“æ¡ç›®
- `uploaded_files`      - ä¸Šä¼ æ–‡ä»¶å…ƒæ•°æ®
- `parsing_results`     - è§£æç»“æœ
- (å…¶ä»–ä¸šåŠ¡è¡¨)

### è¡¨å­˜å‚¨ä½ç½®é…ç½®

åœ¨ `init_database.py` ä¸­æ·»åŠ äº† `storage_location` å­—æ®µï¼Œè®°å½•æ–‡ä»¶ç‰©ç†å­˜å‚¨ä½ç½®ï¼š

```sql
ALTER TABLE uploaded_files ADD COLUMN storage_location TEXT DEFAULT '/Volumes/ssd/bidding-data';
ALTER TABLE parsing_results ADD COLUMN storage_location TEXT DEFAULT '/Volumes/ssd/bidding-data/parsed';
```

---

## âœ… éªŒè¯ç»“æœ

### ç³»ç»ŸéªŒè¯è„šæœ¬æ‰§è¡Œç»“æœ

```
âœ… SSDå­˜å‚¨ç»“æ„     - æ‰€æœ‰ç›®å½•å·²åˆ›å»º
âœ… é…ç½®æ–‡ä»¶        - å·²æ›´æ–°SSDè·¯å¾„
âœ… ç›®å½•æƒé™        - è¯»å†™æƒé™æ­£å¸¸
âœ… Pythonä¾èµ–      - å·²å®‰è£…æ ¸å¿ƒåŒ…
âœ… æ•°æ®åº“é…ç½®      - ä¸»æœº/ç«¯å£/ç”¨æˆ·å‡å¯
```

### ç£ç›˜ç©ºé—´ä¿¡æ¯

```
è®¾å¤‡          å®¹é‡      å·²ç”¨      å¯ç”¨      ä½¿ç”¨ç‡
/Volumes/ssd  1.8TB    1.8GB     1.8TB      1%
```

---

## ğŸš€ éƒ¨ç½²æ­¥éª¤

### Step 1: å¯åŠ¨PostgreSQLæ•°æ®åº“

```bash
# å¯åŠ¨PostgreSQLæœåŠ¡ (macOS)
brew services start postgresql

# éªŒè¯æ•°æ®åº“è¿æ¥
psql -h localhost -U postgres -d bidding_db
```

### Step 2: åˆå§‹åŒ–æ•°æ®åº“

```bash
cd /Users/tianmac/vscode/zhaobiao/bidding-intelligence-system/backend

# åˆ›å»ºæ‰€æœ‰è¡¨å’Œåˆå§‹æ•°æ®
python3 init_database.py
```

**è¾“å‡ºç¤ºä¾‹**:
```
âœ… knowledge_base è¡¨å·²åˆ›å»º
âœ… uploaded_files è¡¨å·²åˆ›å»º
âœ… parsing_results è¡¨å·²åˆ›å»º
âœ… æ‰€æœ‰è¡¨åˆ›å»ºå®Œæˆ
```

### Step 3: å¯åŠ¨åç«¯APIæœåŠ¡

```bash
# åœ¨backendç›®å½•ä¸‹
python3 main.py
```

**é¢„æœŸè¾“å‡º**:
```
File upload directories initialized (SSD Storage):
  - Upload: /Volumes/ssd/bidding-data/uploads
  - Temp: /Volumes/ssd/bidding-data/uploads/temp
  - Parsed: /Volumes/ssd/bidding-data/parsed
  - Archive: /Volumes/ssd/bidding-data/archive

INFO:     Uvicorn running on http://0.0.0.0:8000
```

### Step 4: å¯åŠ¨å‰ç«¯æœåŠ¡

```bash
# åœ¨frontendç›®å½•ä¸‹
cd ../frontend
npm run dev
```

---

## ğŸ“ æ–‡ä»¶æµè½¬é€»è¾‘

### æ–‡ä»¶ä¸Šä¼ æµç¨‹

```
ç”¨æˆ·ä¸Šä¼ æ–‡ä»¶
    â†“
/api/files/upload
    â†“
ä¿å­˜åˆ°: /Volumes/ssd/bidding-data/uploads/{file_id}.{ext}
    â†“
æ•°æ®åº“è®°å½•:
  - uploaded_filesè¡¨ (æ–‡ä»¶å…ƒæ•°æ®)
  - storage_location: '/Volumes/ssd/bidding-data/uploads'
    â†“
è¿”å›: file_id, upload_path, status
```

### æ–‡ä»¶è§£ææµç¨‹

```
è§¦å‘è§£æ: /api/files/parse/{file_id}
    â†“
è¯»å–: /Volumes/ssd/bidding-data/uploads/{file_id}.pdf
    â†“
å¤„ç† (æå–ç« èŠ‚ã€ç”Ÿæˆæ‘˜è¦ç­‰)
    â†“
ä¿å­˜åˆ°: /Volumes/ssd/bidding-data/parsed/{file_id}.json
    â†“
æ•°æ®åº“è®°å½•:
  - parsing_resultsè¡¨ (è§£æç»“æœ)
  - storage_location: '/Volumes/ssd/bidding-data/parsed'
    â†“
è¿”å›: chapters, summary, status
```

### çŸ¥è¯†åº“æ›´æ–°æµç¨‹

```
è§£æå®Œæˆ
    â†“
æå–å…³é”®å†…å®¹
    â†“
ä¿å­˜åˆ°çŸ¥è¯†åº“:
  - è¡¨: knowledge_base
  - file_id: å…³è”åŸå§‹æ–‡ä»¶
  - file_name: æ–‡ä»¶å
  - content: æå–çš„å†…å®¹
  - category: åˆ†ç±» (auto-extracted)
    â†“
å®Œæˆ
```

---

## ğŸ” å¸¸ç”¨æŸ¥è¯¢å’Œç›‘æ§

### æŸ¥çœ‹å·²ä¸Šä¼ çš„æ–‡ä»¶

```sql
SELECT id, file_name, file_size, upload_status, storage_location, created_at
FROM uploaded_files
ORDER BY created_at DESC
LIMIT 10;
```

### æŸ¥çœ‹è§£æç»“æœ

```sql
SELECT f.file_name, p.chapter_count, p.parsing_time, p.storage_location
FROM parsing_results p
JOIN uploaded_files f ON p.file_id = f.id
ORDER BY p.created_at DESC;
```

### æŸ¥çœ‹çŸ¥è¯†åº“å†…å®¹

```sql
SELECT COUNT(*), file_name, category
FROM knowledge_base
GROUP BY file_name, category;
```

### æ£€æŸ¥ç£ç›˜ä½¿ç”¨æƒ…å†µ

```bash
# æŸ¥çœ‹å„ç›®å½•å¤§å°
du -sh /Volumes/ssd/bidding-data/*

# æŸ¥çœ‹è¯¦ç»†ç»Ÿè®¡
df -h /Volumes/ssd/bidding-data/
```

---

## ğŸ› ï¸ æ—¥å¸¸ç»´æŠ¤

### æ—¥å¿—æŸ¥çœ‹

```bash
# æŸ¥çœ‹æœ€è¿‘çš„æ—¥å¿—
tail -100 /Volumes/ssd/bidding-data/logs/app.log

# å®æ—¶ç›‘æ§æ—¥å¿—
tail -f /Volumes/ssd/bidding-data/logs/app.log
```

### æ€§èƒ½ç›‘æ§

```bash
# ç›‘æ§SSDä½¿ç”¨æƒ…å†µ
watch -n 5 'du -sh /Volumes/ssd/bidding-data/*'

# ç›‘æ§æ•°æ®åº“è¿æ¥
psql -h localhost -U postgres -d bidding_db -c "SELECT count(*) FROM pg_stat_activity;"
```

### æ•°æ®å¤‡ä»½

```bash
# å¤‡ä»½æ•°æ®åº“
pg_dump -h localhost -U postgres bidding_db | gzip > /Volumes/ssd/bidding-data/db/backup_$(date +%Y%m%d).sql.gz

# å¤‡ä»½ä¸Šä¼ çš„æ–‡ä»¶
tar -czf /Volumes/ssd/bidding-data/db/uploads_backup_$(date +%Y%m%d).tar.gz /Volumes/ssd/bidding-data/uploads/
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **SSDç©ºé—´ç›‘æ§**: å®šæœŸæ£€æŸ¥SSDä½¿ç”¨ç‡ï¼Œ1.8TBå®¹é‡åº”è¯¥è¶³å¤Ÿ

2. **æ•°æ®åº“ç»´æŠ¤**: å®šæœŸæ‰§è¡ŒVACUUM ANALYZEä¿æŒæ€§èƒ½

3. **æ—¥å¿—è½®è½¬**: æ—¥å¿—æ–‡ä»¶é…ç½®äº†è‡ªåŠ¨è½®è½¬ (æ¯å¤©åˆå¤œ)

4. **æƒé™ç®¡ç†**: æ‰€æœ‰ç›®å½•æƒé™è®¾ç½®ä¸º755ï¼Œç¡®ä¿è¯»å†™æƒé™

5. **å¤‡ä»½ç­–ç•¥**: å»ºè®®å®šæœŸå¤‡ä»½æ•°æ®åº“åˆ°å…¶ä»–å­˜å‚¨ä»‹è´¨

---

## ğŸ“ æ•…éšœæ’é™¤

### é—®é¢˜1: æƒé™æ‹’ç»é”™è¯¯

```
Error: Permission denied: '/Volumes/ssd/bidding-data/uploads'
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
chmod -R 755 /Volumes/ssd/bidding-data/
```

### é—®é¢˜2: ç£ç›˜ç©ºé—´ä¸è¶³

```
Error: No space left on device
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ¸…ç†ä¸´æ—¶æ–‡ä»¶
rm -rf /Volumes/ssd/bidding-data/uploads/temp/*

# æ£€æŸ¥ç£ç›˜ä½¿ç”¨
du -sh /Volumes/ssd/bidding-data/*
```

### é—®é¢˜3: æ•°æ®åº“è¿æ¥å¤±è´¥

```
Error: could not connect to server
```

**æ£€æŸ¥æ­¥éª¤**:
1. ç¡®è®¤PostgreSQLæ­£åœ¨è¿è¡Œ: `brew services list`
2. æ£€æŸ¥ç«¯å£: `lsof -i :5432`
3. æŸ¥çœ‹æ—¥å¿—: `tail -20 /usr/local/var/log/postgres.log`

---

## âœ¨ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. âœ… é…ç½®å·²å®Œæˆ (SSDå­˜å‚¨)
2. â³ å¯åŠ¨PostgreSQLæ•°æ®åº“
3. â³ è¿è¡Œ `python3 init_database.py`
4. â³ å¯åŠ¨åç«¯å’Œå‰ç«¯æœåŠ¡
5. â³ ä¸Šä¼ çœŸå®æ–‡ä»¶è¿›è¡Œæµ‹è¯•

---

**é…ç½®å®Œæˆï¼ç³»ç»Ÿå·²å°±ç»ªã€‚** ğŸ‰

