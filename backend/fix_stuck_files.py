#!/usr/bin/env python3
"""
ä¿®å¤å¡åœ¨ parsing çŠ¶æ€çš„æ–‡ä»¶
æ‰‹åŠ¨è§¦å‘è§£æå¹¶æ›´æ–°æ•°æ®åº“
"""
import sys
import os

# ä¿®å¤å¯¼å…¥è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)
sys.path.insert(0, os.path.join(current_dir, '..'))

from database import db
from engines.parse_engine import ParseEngine
from engines.document_classifier import DocumentClassifier
from core.logger import logger
import json
from datetime import datetime
import shutil

# åˆå§‹åŒ–
parse_engine = ParseEngine()
classifier = DocumentClassifier()

# ç›®å½•é…ç½®
ARCHIVE_DIR = "./uploads/archive"
os.makedirs(ARCHIVE_DIR, exist_ok=True)

def fix_stuck_file(file_id: str):
    """ä¿®å¤å•ä¸ªå¡ä½çš„æ–‡ä»¶"""
    try:
        # 1. ä»æ•°æ®åº“è·å–æ–‡ä»¶ä¿¡æ¯
        file_info = db.query_one(
            "SELECT * FROM uploaded_files WHERE id = %s",
            (file_id,)
        )
        
        if not file_info:
            logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_id}")
            return False
        
        filename = file_info['filename']
        temp_path = file_info['temp_path']
        
        logger.info(f"ğŸ“„ å¤„ç†æ–‡ä»¶: {filename}")
        logger.info(f"   è·¯å¾„: {temp_path}")
        
        # 2. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(temp_path):
            logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨äºç£ç›˜: {temp_path}")
            db.execute(
                "UPDATE uploaded_files SET status = 'failed' WHERE id = %s",
                (file_id,)
            )
            return False
        
        # 3. è§£ææ–‡ä»¶ï¼ˆä½¿ç”¨åº•å±‚æ–¹æ³•é¿å…é‡å¤ä¿å­˜DBï¼‰
        logger.info("ğŸ”„ å¼€å§‹è§£æ...")
        db.execute(
            "UPDATE uploaded_files SET status = 'parsing' WHERE id = %s",
            (file_id,)
        )
        
        # è°ƒç”¨åº•å±‚è§£ææ–¹æ³•ï¼ˆä¸ä¿å­˜DBï¼‰
        if temp_path.endswith('.pdf'):
            content = parse_engine._parse_pdf(temp_path)
        else:
            logger.error(f"æš‚ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {temp_path}")
            return False
        
        chapters = parse_engine._extract_from_content(content)
        
        logger.info(f"âœ… è§£æå®Œæˆ: {len(chapters)} ä¸ªç« èŠ‚")
        
        # 4. ç”Ÿæˆå…ƒæ•°æ®
        metadata = {
            "chapters": [
                {
                    "title": ch.get('chapter_title', ''),
                    "level": ch.get('chapter_level', 1),
                    "page": ch.get('page', 0),
                    "number": ch.get('chapter_number', '')
                }
                for ch in chapters
            ],
            "page_count": len(chapters),
            "has_tables": False,  # ç®€åŒ–ï¼šä¸æ£€æµ‹è¡¨æ ¼
            "parse_time": datetime.now().isoformat()
        }
        
        # 5. æ™ºèƒ½åˆ†ç±»
        category, semantic_filename = classifier.classify(
            filename,
            metadata,
            content
        )
        
        logger.info(f"ğŸ·ï¸  åˆ†ç±»: {category}, è¯­ä¹‰å: {semantic_filename}")
        
        # 6. å½’æ¡£æ–‡ä»¶
        now = datetime.now()
        year = now.year
        month = now.month
        archive_dir = os.path.join(ARCHIVE_DIR, str(year), f"{month:02d}", category)
        os.makedirs(archive_dir, exist_ok=True)
        
        archive_path = os.path.join(archive_dir, semantic_filename)
        shutil.copy2(temp_path, archive_path)
        
        logger.info(f"ğŸ“¦ å½’æ¡£åˆ°: {archive_path}")
        
        # 7. æ›´æ–°æ•°æ®åº“
        db.execute(
            """
            UPDATE uploaded_files 
            SET status = 'archived', 
                archive_path = %s, 
                category = %s, 
                semantic_filename = %s,
                metadata = %s,
                parsed_at = NOW(),
                archived_at = NOW(),
                file_path = %s
            WHERE id = %s
            """,
            (archive_path, category, semantic_filename, json.dumps(metadata), archive_path, file_id)
        )
        
        # 8. æ’å…¥åˆ° files è¡¨ï¼ˆä½¿ç”¨ reference ç±»å‹ï¼Œæ·»åŠ  filetypeï¼‰
        file_ext = os.path.splitext(filename)[1][1:]  # å»æ‰ç‚¹å·
        db.execute(
            """
            INSERT INTO files (id, filename, filepath, filetype, doc_type, created_at, updated_at)
            VALUES (%s, %s, %s, %s, 'reference', NOW(), NOW())
            ON CONFLICT (id) DO UPDATE SET
                filename = EXCLUDED.filename,
                filepath = EXCLUDED.filepath,
                filetype = EXCLUDED.filetype,
                updated_at = NOW()
            """,
            (file_id, semantic_filename, archive_path, file_ext)
        )
        
        # 9. æ’å…¥ç« èŠ‚
        for idx, ch in enumerate(chapters):
            db.execute(
                """
                INSERT INTO chapters (
                    file_id, chapter_title, chapter_level, content, 
                    chapter_number, position_order, structure_data
                )
                VALUES (%s, %s, %s, %s, %s, %s, %s)
                ON CONFLICT DO NOTHING
                """,
                (
                    file_id,
                    ch.get('chapter_title', ''),
                    ch.get('chapter_level', 1),
                    ch.get('content', ''),
                    ch.get('chapter_number', ''),
                    idx + 1,  # position_order ä»1å¼€å§‹
                    json.dumps({"page": ch.get('page', 0)})
                )
            )
        
        logger.info(f"âœ… å®Œæˆï¼ç« èŠ‚å·²æ’å…¥: {len(chapters)} æ¡")
        return True
        
    except Exception as e:
        import traceback
        error_msg = f"å¤„ç†å¤±è´¥: {str(e)}"
        logger.error(error_msg)
        logger.error(traceback.format_exc())
        db.execute(
            "UPDATE uploaded_files SET status = 'failed' WHERE id = %s",
            (file_id,)
        )
        return False

if __name__ == "__main__":
    # æŸ¥æ‰¾æ‰€æœ‰å¡åœ¨ parsing çŠ¶æ€çš„æ–‡ä»¶
    stuck_files = db.query(
        """
        SELECT id, filename, created_at 
        FROM uploaded_files 
        WHERE status = 'parsing' 
        AND parsed_at IS NULL
        ORDER BY created_at DESC
        """
    )
    
    if not stuck_files:
        logger.info("æ²¡æœ‰å¡ä½çš„æ–‡ä»¶")
        sys.exit(0)
    
    logger.info(f"æ‰¾åˆ° {len(stuck_files)} ä¸ªå¡ä½çš„æ–‡ä»¶")
    
    success_count = 0
    for file in stuck_files:
        logger.info(f"\n{'='*60}")
        if fix_stuck_file(file['id']):
            success_count += 1
    
    logger.info(f"\n{'='*60}")
    logger.info(f"âœ… æˆåŠŸ: {success_count}/{len(stuck_files)}")
