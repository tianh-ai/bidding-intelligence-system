#!/usr/bin/env python3
"""
æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬ - åˆ›å»ºæ‰€æœ‰å¿…éœ€çš„è¡¨å’Œåˆå§‹æ•°æ®
"""

import os
import sys
import asyncio
from pathlib import Path

# æ·»åŠ åç«¯ç›®å½•åˆ°Pythonè·¯å¾„
backend_path = Path(__file__).parent
sys.path.insert(0, str(backend_path))

from core.config import get_settings
from core.logger import logger
from db.ontology import OntologyDB

async def init_database():
    """åˆå§‹åŒ–æ•°æ®åº“"""
    try:
        settings = get_settings()
        logger.info(f"è¿æ¥æ•°æ®åº“: {settings.database_url}")
        
        db = OntologyDB()
        await db.init()
        
        logger.info("âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
        
        # åˆ›å»ºçŸ¥è¯†åº“è¡¨
        await create_knowledge_base_table(db)
        
        # åˆ›å»ºä¸Šä¼ æ–‡ä»¶è¡¨
        await create_uploaded_files_table(db)
        
        # åˆ›å»ºè§£æç»“æœè¡¨
        await create_parsing_results_table(db)
        
        logger.info("âœ… æ‰€æœ‰è¡¨åˆ›å»ºå®Œæˆ")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
        return False

async def create_knowledge_base_table(db):
    """åˆ›å»ºçŸ¥è¯†åº“è¡¨"""
    try:
        query = """
        CREATE TABLE IF NOT EXISTS knowledge_base (
            id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
            title TEXT NOT NULL,
            content TEXT NOT NULL,
            category TEXT DEFAULT 'general',
            file_id UUID,
            file_name TEXT,
            source TEXT DEFAULT 'manual',
            embedding VECTOR(1536),
            created_at TIMESTAMPTZ DEFAULT NOW(),
            updated_at TIMESTAMPTZ DEFAULT NOW()
        )
        """
        await db.execute(query)
        logger.info("âœ“ knowledge_base è¡¨å·²åˆ›å»º")
        
        # åˆ›å»ºç´¢å¼•
        await db.execute("""
            CREATE INDEX IF NOT EXISTS idx_knowledge_base_file_id 
            ON knowledge_base(file_id)
        """)
        await db.execute("""
            CREATE INDEX IF NOT EXISTS idx_knowledge_base_category 
            ON knowledge_base(category)
        """)
        
    except Exception as e:
        logger.warning(f"knowledge_base è¡¨å¯èƒ½å·²å­˜åœ¨: {e}")

async def create_uploaded_files_table(db):
    """åˆ›å»ºä¸Šä¼ æ–‡ä»¶è¡¨"""
    try:
        query = """
        CREATE TABLE IF NOT EXISTS uploaded_files (
            id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
            file_name TEXT NOT NULL,
            file_path TEXT NOT NULL,
            file_size INTEGER,
            file_type TEXT,
            mime_type TEXT,
            upload_status TEXT DEFAULT 'pending',
            parse_status TEXT DEFAULT 'pending',
            storage_location TEXT DEFAULT '/Volumes/ssd/bidding-data',
            created_at TIMESTAMPTZ DEFAULT NOW(),
            updated_at TIMESTAMPTZ DEFAULT NOW()
        )
        """
        await db.execute(query)
        logger.info("âœ“ uploaded_files è¡¨å·²åˆ›å»º")
        
        # åˆ›å»ºç´¢å¼•
        await db.execute("""
            CREATE INDEX IF NOT EXISTS idx_uploaded_files_name 
            ON uploaded_files(file_name)
        """)
        await db.execute("""
            CREATE INDEX IF NOT EXISTS idx_uploaded_files_status 
            ON uploaded_files(upload_status, parse_status)
        """)
        
    except Exception as e:
        logger.warning(f"uploaded_files è¡¨å¯èƒ½å·²å­˜åœ¨: {e}")

async def create_parsing_results_table(db):
    """åˆ›å»ºè§£æç»“æœè¡¨"""
    try:
        query = """
        CREATE TABLE IF NOT EXISTS parsing_results (
            id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
            file_id UUID REFERENCES uploaded_files(id) ON DELETE CASCADE,
            chapter_count INTEGER,
            parsing_time FLOAT,
            parsing_status TEXT DEFAULT 'pending',
            error_message TEXT,
            result_json JSONB,
            storage_location TEXT DEFAULT '/Volumes/ssd/bidding-data/parsed',
            created_at TIMESTAMPTZ DEFAULT NOW()
        )
        """
        await db.execute(query)
        logger.info("âœ“ parsing_results è¡¨å·²åˆ›å»º")
        
        # åˆ›å»ºç´¢å¼•
        await db.execute("""
            CREATE INDEX IF NOT EXISTS idx_parsing_results_file_id 
            ON parsing_results(file_id)
        """)
        
    except Exception as e:
        logger.warning(f"parsing_results è¡¨å¯èƒ½å·²å­˜åœ¨: {e}")

async def verify_storage_paths():
    """éªŒè¯å­˜å‚¨è·¯å¾„"""
    paths = [
        "/Volumes/ssd/bidding-data/uploads",
        "/Volumes/ssd/bidding-data/parsed",
        "/Volumes/ssd/bidding-data/archive",
        "/Volumes/ssd/bidding-data/logs"
    ]
    
    logger.info("éªŒè¯å­˜å‚¨è·¯å¾„:")
    for path in paths:
        if os.path.exists(path):
            logger.info(f"  âœ“ {path}")
        else:
            logger.warning(f"  âš ï¸  {path} ä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»º...")
            os.makedirs(path, exist_ok=True)

async def main():
    """ä¸»å‡½æ•°"""
    print("="*60)
    print("ğŸš€ æ•°æ®åº“åˆå§‹åŒ–")
    print("="*60)
    print()
    
    # éªŒè¯å­˜å‚¨è·¯å¾„
    await verify_storage_paths()
    print()
    
    # åˆå§‹åŒ–æ•°æ®åº“
    success = await init_database()
    
    print()
    print("="*60)
    if success:
        print("âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆï¼")
        print()
        print("å­˜å‚¨é…ç½®:")
        print("  - æ–‡ä»¶ä¸Šä¼ : /Volumes/ssd/bidding-data/uploads")
        print("  - è§£æç»“æœ: /Volumes/ssd/bidding-data/parsed")
        print("  - å½’æ¡£æ–‡ä»¶: /Volumes/ssd/bidding-data/archive")
        print("  - æ—¥å¿—æ–‡ä»¶: /Volumes/ssd/bidding-data/logs")
        print()
        print("ä¸‹ä¸€æ­¥: å¯åŠ¨åç«¯æœåŠ¡")
        print("  python3 main.py")
    else:
        print("âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥")
        return 1
    print("="*60)
    
    return 0

if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
