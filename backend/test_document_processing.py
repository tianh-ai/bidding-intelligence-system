#!/usr/bin/env python3
"""
ç»¼åˆæµ‹è¯•ï¼šæ–‡æ¡£åˆ†ç±»ã€OCR æå–ã€å¤„ç†æµç¨‹
ç”¨äºéªŒè¯æ–°å¢çš„æ–‡æ¡£å¤„ç†ç³»ç»Ÿ
"""

import asyncio
import os
import sys
import json
from pathlib import Path
from typing import Dict, List, Any
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# å¯¼å…¥æ–°æ¨¡å—
try:
    from engines.smart_document_classifier import SmartDocumentClassifier, DocumentType
    from engines.ocr_extractor import (
        HybridTextExtractor, 
        DirectTextExtractor,
        ImageMetadataExtractor
    )
    from engines.document_processor import DocumentProcessor
    logger.info("âœ… æˆåŠŸå¯¼å…¥æ‰€æœ‰æ–°æ¨¡å—")
except ImportError as e:
    logger.error(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)


class DocumentProcessingTest:
    """æ–‡æ¡£å¤„ç†ç³»ç»Ÿç»¼åˆæµ‹è¯•"""
    
    def __init__(self):
        self.classifier = SmartDocumentClassifier()
        self.processor = DocumentProcessor()
        self.test_results = []
    
    async def test_classifier(self, file_path: str, expected_type: DocumentType = None):
        """æµ‹è¯•æ–‡æ¡£åˆ†ç±»å™¨"""
        logger.info(f"\nğŸ“‹ æµ‹è¯•åˆ†ç±»: {Path(file_path).name}")
        
        if not os.path.exists(file_path):
            logger.error(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return None
        
        try:
            analysis = self.classifier.classify(file_path, Path(file_path).name)
            
            result = {
                'test': 'æ–‡æ¡£åˆ†ç±»',
                'file': Path(file_path).name,
                'type': analysis.file_type.value,
                'strategy': analysis.processing_strategy,
                'pages': analysis.total_pages,
                'text_ratio': f"{analysis.text_page_ratio:.1%}",
                'scan_ratio': f"{analysis.scan_page_ratio:.1%}",
                'status': 'âœ… é€šè¿‡' if expected_type is None or analysis.file_type == expected_type else 'âš ï¸ é¢„æœŸä¸ç¬¦'
            }
            
            logger.info(f"  æ–‡ä»¶ç±»å‹: {analysis.file_type.value}")
            logger.info(f"  å¤„ç†ç­–ç•¥: {analysis.processing_strategy}")
            logger.info(f"  æ€»é¡µæ•°: {analysis.total_pages}")
            logger.info(f"  æ–‡æœ¬é¡µæ¯”ä¾‹: {analysis.text_page_ratio:.1%}")
            logger.info(f"  æ‰«æé¡µæ¯”ä¾‹: {analysis.scan_page_ratio:.1%}")
            
            if analysis.is_financial_report:
                logger.info(f"  è´¢åŠ¡æŠ¥å‘Šå¹´ä»½: {analysis.financial_years}")
                result['financial_years'] = analysis.financial_years
            
            if analysis.is_certificate:
                logger.info(f"  âœ“ æ£€æµ‹ä¸ºè¯ä»¶ç±»å‹")
                result['is_certificate'] = True
            
            self.test_results.append(result)
            return analysis
            
        except Exception as e:
            logger.error(f"âŒ åˆ†ç±»é”™è¯¯: {e}", exc_info=True)
            self.test_results.append({
                'test': 'æ–‡æ¡£åˆ†ç±»',
                'file': Path(file_path).name,
                'error': str(e),
                'status': 'âŒ å¤±è´¥'
            })
            return None
    
    async def test_text_extraction(self, file_path: str):
        """æµ‹è¯•æ–‡æœ¬æå–"""
        logger.info(f"\nğŸ”¤ æµ‹è¯•æ–‡æœ¬æå–: {Path(file_path).name}")
        
        if not os.path.exists(file_path):
            logger.error(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return None
        
        try:
            # æµ‹è¯•ç›´æ¥æ–‡æœ¬æå–
            extractor = DirectTextExtractor()
            text = extractor.extract(file_path)
            
            result = {
                'test': 'æ–‡æœ¬æå–',
                'file': Path(file_path).name,
                'text_length': len(text),
                'text_preview': text[:100] + '...' if len(text) > 100 else text,
                'status': 'âœ… é€šè¿‡'
            }
            
            logger.info(f"  æå–å­—æ•°: {len(text)}")
            logger.info(f"  é¢„è§ˆ: {text[:100]}...")
            
            self.test_results.append(result)
            return text
            
        except Exception as e:
            logger.error(f"âŒ æå–é”™è¯¯: {e}", exc_info=True)
            self.test_results.append({
                'test': 'æ–‡æœ¬æå–',
                'file': Path(file_path).name,
                'error': str(e),
                'status': 'âŒ å¤±è´¥'
            })
            return None
    
    async def test_full_processing(self, file_path: str):
        """æµ‹è¯•å®Œæ•´å¤„ç†æµç¨‹"""
        logger.info(f"\nâš™ï¸  æµ‹è¯•å®Œæ•´å¤„ç†: {Path(file_path).name}")
        
        if not os.path.exists(file_path):
            logger.error(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return None
        
        try:
            result = await self.processor.process(file_path, Path(file_path).name)
            
            test_result = {
                'test': 'å®Œæ•´å¤„ç†',
                'file': Path(file_path).name,
                'status_code': result.get('status'),
                'file_type': result.get('file_type'),
                'strategy': result.get('processing_strategy'),
                'pages': result.get('total_pages'),
                'time': result.get('processing_time'),
            }
            
            logger.info(f"  çŠ¶æ€: {result.get('status')}")
            logger.info(f"  æ–‡ä»¶ç±»å‹: {result.get('file_type')}")
            logger.info(f"  å¤„ç†ç­–ç•¥: {result.get('processing_strategy')}")
            logger.info(f"  é¡µæ•°: {result.get('total_pages')}")
            
            if result.get('chapters'):
                logger.info(f"  æå–ç« èŠ‚æ•°: {len(result['chapters'])}")
                test_result['chapters_count'] = len(result['chapters'])
                
                # æ˜¾ç¤ºå‰ 5 ä¸ªç« èŠ‚
                for i, ch in enumerate(result['chapters'][:5]):
                    logger.info(f"    [{i+1}] {ch.get('title', 'N/A')} (L{ch.get('level')})")
            
            test_result['status'] = 'âœ… é€šè¿‡'
            self.test_results.append(test_result)
            return result
            
        except Exception as e:
            logger.error(f"âŒ å¤„ç†é”™è¯¯: {e}", exc_info=True)
            self.test_results.append({
                'test': 'å®Œæ•´å¤„ç†',
                'file': Path(file_path).name,
                'error': str(e),
                'status': 'âŒ å¤±è´¥'
            })
            return None
    
    def generate_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        logger.info("\n" + "="*60)
        logger.info("ğŸ“Š æµ‹è¯•æŠ¥å‘Šæ±‡æ€»")
        logger.info("="*60)
        
        # æŒ‰æµ‹è¯•ç±»å‹åˆ†ç±»
        tests_by_type = {}
        for result in self.test_results:
            test_type = result.get('test', 'æœªçŸ¥')
            if test_type not in tests_by_type:
                tests_by_type[test_type] = []
            tests_by_type[test_type].append(result)
        
        # è¾“å‡ºæ¯ç±»æµ‹è¯•çš„æ±‡æ€»
        for test_type, results in tests_by_type.items():
            passed = sum(1 for r in results if 'âœ…' in str(r.get('status', '')))
            total = len(results)
            logger.info(f"\n{test_type}: {passed}/{total} é€šè¿‡")
            
            for result in results:
                status = result.get('status', 'âŒ æœªçŸ¥')
                file = result.get('file', 'N/A')
                logger.info(f"  {status} {file}")
                
                # æ˜¾ç¤ºå…³é”®ä¿¡æ¯
                if result.get('type'):
                    logger.info(f"      ç±»å‹: {result['type']}")
                if result.get('text_length'):
                    logger.info(f"      å­—æ•°: {result['text_length']}")
                if result.get('chapters_count'):
                    logger.info(f"      ç« èŠ‚: {result['chapters_count']}")
                if result.get('error'):
                    logger.info(f"      é”™è¯¯: {result['error']}")
        
        # æ€»è®¡
        total_tests = len(self.test_results)
        passed_tests = sum(1 for r in self.test_results if 'âœ…' in str(r.get('status', '')))
        logger.info(f"\n{'='*60}")
        logger.info(f"æ€»è®¡: {passed_tests}/{total_tests} æµ‹è¯•é€šè¿‡")
        logger.info(f"{'='*60}")
        
        return {
            'total': total_tests,
            'passed': passed_tests,
            'rate': f"{100 * passed_tests / total_tests:.1f}%" if total_tests > 0 else "0%",
            'results': self.test_results
        }


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹æ–‡æ¡£å¤„ç†ç³»ç»Ÿæµ‹è¯•\n")
    
    tester = DocumentProcessingTest()
    
    # æŸ¥æ‰¾æµ‹è¯•æ–‡ä»¶
    test_dir = Path(__file__).parent / 'uploads'
    test_files = []
    
    if test_dir.exists():
        # æŸ¥æ‰¾æ‰€æœ‰ PDF å’Œ DOC æ–‡ä»¶
        test_files.extend(list(test_dir.glob('*.pdf')))
        test_files.extend(list(test_dir.glob('*.docx')))
    
    if test_files:
        logger.info(f"ğŸ“ æ‰¾åˆ° {len(test_files)} ä¸ªæµ‹è¯•æ–‡ä»¶\n")
        
        # æµ‹è¯•æ¯ä¸ªæ–‡ä»¶
        for file_path in test_files[:3]:  # é™åˆ¶ä¸ºå‰ 3 ä¸ªæ–‡ä»¶ï¼Œé¿å…è€—æ—¶è¿‡é•¿
            logger.info(f"\n{'='*60}")
            logger.info(f"æµ‹è¯•æ–‡ä»¶: {file_path.name}")
            logger.info(f"{'='*60}")
            
            # 1. æµ‹è¯•åˆ†ç±»
            analysis = await tester.test_classifier(str(file_path))
            
            # 2. æµ‹è¯•æ–‡æœ¬æå–
            if analysis and analysis.file_type in [
                DocumentType.MAIN_PROPOSAL,
                DocumentType.UNKNOWN
            ]:
                await tester.test_text_extraction(str(file_path))
            
            # 3. æµ‹è¯•å®Œæ•´å¤„ç†
            await tester.test_full_processing(str(file_path))
    else:
        logger.warning("âš ï¸  æœªæ‰¾åˆ°æµ‹è¯•æ–‡ä»¶ã€‚æ‰§è¡Œæ¨¡æ‹Ÿæµ‹è¯•...\n")
        
        # æ‰§è¡Œæ¨¡æ‹Ÿæµ‹è¯•
        logger.info("ğŸ“‹ æ¨¡æ‹Ÿæµ‹è¯• 1: æ–‡æ¡£åˆ†ç±»å™¨åˆå§‹åŒ–")
        try:
            classifier = SmartDocumentClassifier()
            logger.info("  âœ… SmartDocumentClassifier åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"  âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        
        logger.info("\nğŸ”¤ æ¨¡æ‹Ÿæµ‹è¯• 2: OCR æå–å™¨åˆå§‹åŒ–")
        try:
            extractor = HybridTextExtractor(use_paddle_ocr=False)  # ç¦ç”¨ OCRï¼Œåªæµ‹è¯•æ–‡æœ¬
            logger.info("  âœ… HybridTextExtractor åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"  âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        
        logger.info("\nâš™ï¸  æ¨¡æ‹Ÿæµ‹è¯• 3: æ–‡æ¡£å¤„ç†å™¨åˆå§‹åŒ–")
        try:
            processor = DocumentProcessor()
            logger.info("  âœ… DocumentProcessor åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"  âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
    
    # ç”ŸæˆæŠ¥å‘Š
    report = tester.generate_report()
    
    # ä¿å­˜æŠ¥å‘Š
    report_path = Path(__file__).parent / 'TEST_REPORT.json'
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    logger.info(f"\nğŸ’¾ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")


if __name__ == '__main__':
    asyncio.run(main())
