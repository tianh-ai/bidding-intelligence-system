"""
æ–‡æ¡£è§£æå¼•æ“
æ”¯æŒPDFå’ŒWordæ–‡æ¡£çš„è§£æ,è‡ªåŠ¨åˆ†å‰²ç« èŠ‚
"""
from pypdf import PdfReader
import docx
import re
import uuid
import os
import json
from typing import Dict, List, Optional
from engines.parse_engine_v2 import EnhancedChapterExtractor
from engines.image_extractor import ImageExtractor
from database import db


class ParseEngine:
    """æ–‡æ¡£è§£æå¼•æ“"""
    
    def __init__(self):
        """åˆå§‹åŒ–è§£æå¼•æ“"""
        self.db = db
        self.enhanced_extractor = EnhancedChapterExtractor()
        self.image_extractor = ImageExtractor()
        self._ocr_extractor = None  # å»¶è¿Ÿåˆå§‹åŒ–OCR
        # æ”¹è¿›çš„ç« èŠ‚æ¨¡å¼è¯†åˆ«
        self.chapter_patterns = [
            # ä¸­æ–‡ç« èŠ‚å·ï¼šç¬¬ä¸€ç« ã€ç¬¬ä¸€èŠ‚
            (r'^ç¬¬([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+)ç« [\sã€€]*(.+)$', 1),
            (r'^ç¬¬([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+)èŠ‚[\sã€€]*(.+)$', 1),
            # æ•°å­—ç¼–å·ï¼šä¼˜å…ˆçº§ä»é«˜åˆ°ä½
            (r'^(\d+\.\d+\.\d+\.\d+)[\sã€€]+(.+)$', 2),  # 4çº§ç¼–å· (1.1.1.1)
            (r'^(\d+\.\d+\.\d+)[\sã€€]+(.+)$', 2),       # 3çº§ç¼–å· (1.1.1)
            (r'^(\d+\.\d+)[\sã€€]+(.+)$', 2),            # 2çº§ç¼–å· (1.1)
            # å•ä¸ªæ•°å­—ï¼šéœ€è¦æ›´å¤šé™åˆ¶
            # - èŒƒå›´1-99
            # - æ ‡é¢˜è‡³å°‘8ä¸ªå­—ç¬¦
            # - ä¸ä»¥æ—¶é—´å•ä½ç»“å°¾ï¼ˆæ—¥ã€æœˆã€å¹´ã€å¤©ã€å°æ—¶ç­‰ï¼‰
            (r'^([1-9]|[1-9]\d)[\sã€€]+((?!.*[æ—¥æœˆå¹´å¤©å°æ—¶åˆ†ç§’åˆ†é’Ÿ$]).{8,})$', 2),
        ]
    
    def parse(self, file_path: str, doc_type: str, save_to_db: bool = True, file_id: str = None) -> Dict:
        """
        è§£ææ–‡ä»¶å¹¶å­˜å…¥æ•°æ®åº“
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            doc_type: æ–‡æ¡£ç±»å‹(tender/proposal/reference)
            save_to_db: æ˜¯å¦ä¿å­˜åˆ°æ•°æ®åº“
            file_id: æ–‡ä»¶ID(ç”¨äºå›¾ç‰‡æå–)
            
        Returns:
            dict: {file_id, filename, content, chapters, images}
        """
        # 1. æå–æ–‡æœ¬
        if file_path.endswith('.pdf'):
            content = self._parse_pdf(file_path)
        elif file_path.endswith(('.docx', '.doc')):
            content = self._parse_docx(file_path)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_path}")
        
        # 2. ä»æ­£æ–‡è¯†åˆ«æ¡æ¬¾ç»“æ„ï¼ˆæ–°ç­–ç•¥ï¼‰
        chapters = self._extract_from_content(content)
        
        # 2.1 è¾¹ç•Œæ£€æŸ¥:å¦‚æœæ²¡æœ‰è¯†åˆ«åˆ°ç« èŠ‚,åˆ›å»ºé»˜è®¤ç« èŠ‚
        if not chapters:
            chapters = [{
                'chapter_number': '1',
                'chapter_title': 'å…¨æ–‡',
                'chapter_level': 1,
                'content': content
            }]
        
        # 3. ç»Ÿä¸€æ–‡æ¡£ç±»å‹ï¼Œé¿å…è¿åæ•°æ®åº“çº¦æŸ
        allowed_doc_types = {"tender", "proposal", "reference"}
        safe_doc_type = doc_type if doc_type in allowed_doc_types else "reference"

        # 4. æå–å¹¶ä¿å­˜å›¾ç‰‡(ä¸è¿›è¡ŒOCR,åªä¿å­˜åŸå§‹å›¾ç‰‡)
        extracted_images = []
        if file_id:
            from datetime import datetime
            
            # å°è¯•ä»æ•°æ®åº“è·å–æ–‡ä»¶å¹´ä»½ä¿¡æ¯
            year = datetime.now().year  # é»˜è®¤å½“å‰å¹´ä»½
            try:
                result = self.db.query_one(
                    "SELECT created_at FROM uploaded_files WHERE id = %s",
                    (file_id,)
                )
                if result and result['created_at']:
                    year = result['created_at'].year
            except Exception as e:
                from core.logger import logger
                logger.warning(f"æ— æ³•ä»æ•°æ®åº“è·å–æ–‡ä»¶å¹´ä»½ï¼Œä½¿ç”¨å½“å‰å¹´ä»½: {e}")
            
            if file_path.endswith('.pdf'):
                extracted_images = self.image_extractor.extract_from_pdf(file_path, file_id, year)
            elif file_path.endswith(('.docx', '.doc')):
                extracted_images = self.image_extractor.extract_from_docx(file_path, file_id, year)
            
            from core.logger import logger
            logger.info(f"ğŸ“· æå–å¹¶ä¿å­˜äº† {len(extracted_images)} å¼ å›¾ç‰‡åˆ° /images/{year}/{file_id}/")

        # 5. ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆå¯é€‰ï¼‰
        if save_to_db and not file_id:
            file_id = self._save_to_db(file_path, safe_doc_type, content, chapters)
        elif save_to_db and file_id:
            # åªæ›´æ–°ç« èŠ‚ä¿¡æ¯
            self._update_chapters(file_id, chapters)
        
        return {
            'file_id': file_id,
            'filename': os.path.basename(file_path),
            'content': content,
            'total_chapters': len(chapters),
            'chapters': chapters,
            'images': extracted_images,  # æ–°å¢: å›¾ç‰‡åˆ—è¡¨
            'image_count': len(extracted_images)
        }
    
    def _parse_pdf(self, file_path: str) -> str:
        """
        è§£æPDFæ–‡ä»¶ï¼ˆä½¿ç”¨OCRæ”¯æŒæ‰«ææ–‡æ¡£ï¼‰
        
        Args:
            file_path: PDFæ–‡ä»¶è·¯å¾„
            
        Returns:
            str: æå–çš„æ–‡æœ¬å†…å®¹
        """
        # å»¶è¿Ÿåˆå§‹åŒ–OCRæå–å™¨
        if self._ocr_extractor is None:
            try:
                from engines.ocr_extractor import HybridTextExtractor
                import os
                use_ocr = os.getenv('OCR_ENABLED', 'true').lower() == 'true'
                self._ocr_extractor = HybridTextExtractor(use_paddle_ocr=use_ocr)
                from core.logger import logger
                logger.info(f"OCRæå–å™¨åˆå§‹åŒ–æˆåŠŸ (OCR={'å¯ç”¨' if use_ocr else 'ç¦ç”¨'})")
            except Exception as e:
                from core.logger import logger
                logger.warning(f"OCRåˆå§‹åŒ–å¤±è´¥,ä½¿ç”¨åŸºç¡€æå–: {e}")
                self._ocr_extractor = None
        
        # ä½¿ç”¨OCRå¢å¼ºçš„æå–å™¨
        if self._ocr_extractor:
            try:
                import asyncio
                # åŒæ­¥è°ƒç”¨å¼‚æ­¥æ–¹æ³•
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                results = loop.run_until_complete(
                    self._ocr_extractor.extract_document(file_path)
                )
                loop.close()
                
                # åˆå¹¶æ‰€æœ‰é¡µé¢æ–‡æœ¬
                text_parts = [r['text'] for r in results if r.get('text')]
                return '\n'.join(text_parts)
            except Exception as e:
                from core.logger import logger
                logger.warning(f"OCRæå–å¤±è´¥,å›é€€åˆ°åŸºç¡€æå–: {e}")
        
        # å›é€€: åŸºç¡€PDFæ–‡æœ¬æå–
        reader = PdfReader(file_path)
        text_parts = []
        
        for page in reader.pages:
            text = page.extract_text()
            if text:
                text_parts.append(text)
        
        return '\n'.join(text_parts)
    
    def _clean_pdf_line_breaks(self, text: str) -> str:
        """
        æ¸…ç†PDFæå–æ—¶äº§ç”Ÿçš„ä¸åˆç†æ¢è¡Œ
        
        æ³¨æ„ï¼šä¸åšè¿‡åº¦æ¸…ç†ï¼Œä¿ç•™æ®µè½ç»“æ„
        åªåˆå¹¶æ˜æ˜¾çš„åˆ†è¯é”™è¯¯ï¼ˆå¦‚"è¯è¯­\nå®šä¹‰"è¿™ç§è¶…çŸ­è¡Œï¼‰
        
        Args:
            text: åŸå§‹PDFæ–‡æœ¬
            
        Returns:
            str: æ¸…ç†åçš„æ–‡æœ¬
        """
        # æš‚ä¸åšæ¸…ç†ï¼Œç›´æ¥è¿”å›åŸæ–‡
        # PDFå±‚é¢çš„æ¸…ç†å®¹æ˜“è¯¯åˆå¹¶æ­£æ–‡æ®µè½
        return text
    
    def _parse_docx(self, file_path: str) -> str:
        """
        è§£æWordæ–‡æ¡£ï¼ˆæ”¯æŒæå–åµŒå…¥å›¾ç‰‡å¹¶OCRè¯†åˆ«ï¼‰
        
        Args:
            file_path: Wordæ–‡ä»¶è·¯å¾„
            
        Returns:
            str: æå–çš„æ–‡æœ¬å†…å®¹ï¼ˆåŒ…å«OCRè¯†åˆ«çš„å›¾ç‰‡æ–‡å­—ï¼‰
        """
        import os
        from core.logger import logger
        
        doc = docx.Document(file_path)
        text_parts = []
        
        # 1. æå–æ®µè½æ–‡æœ¬
        for paragraph in doc.paragraphs:
            if paragraph.text.strip():
                text_parts.append(paragraph.text)
        
        # 2. æå–å¹¶OCRè¯†åˆ«åµŒå…¥çš„å›¾ç‰‡ï¼ˆå¦‚æœå¯ç”¨OCRï¼‰
        use_ocr = os.getenv('OCR_ENABLED', 'true').lower() == 'true'
        if use_ocr and hasattr(doc, 'part'):
            try:
                # å»¶è¿Ÿåˆå§‹åŒ–OCR
                if self._ocr_extractor is None:
                    from engines.ocr_extractor import HybridTextExtractor
                    self._ocr_extractor = HybridTextExtractor(use_paddle_ocr=True)
                    logger.info("OCRæå–å™¨åˆå§‹åŒ–æˆåŠŸ")
                
                from engines.ocr_extractor import PaddleOCRExtractor
                ocr = PaddleOCRExtractor()
                
                # éå†æ–‡æ¡£ä¸­çš„å›¾ç‰‡å…³ç³»
                image_count = 0
                for rel in doc.part.rels.values():
                    if "image" in rel.target_ref:
                        try:
                            image_data = rel.target_part.blob
                            
                            # ä½¿ç”¨Tesseract OCRè¯†åˆ«å›¾ç‰‡
                            import pytesseract
                            from PIL import Image
                            import io
                            
                            img = Image.open(io.BytesIO(image_data))
                            ocr_text = pytesseract.image_to_string(img, lang='chi_sim+eng')
                            
                            if ocr_text and len(ocr_text.strip()) > 10:
                                text_parts.append(f"\n[å›¾ç‰‡å†…å®¹-{image_count+1}]\n{ocr_text}")
                                image_count += 1
                                logger.info(f"æˆåŠŸè¯†åˆ«å›¾ç‰‡ {image_count}: {len(ocr_text)} å­—ç¬¦")
                        except Exception as img_err:
                            logger.warning(f"å›¾ç‰‡OCRè¯†åˆ«å¤±è´¥: {img_err}")
                            continue
                
                if image_count > 0:
                    logger.info(f"æ–‡æ¡£ {os.path.basename(file_path)} å…±è¯†åˆ« {image_count} å¼ å›¾ç‰‡")
            
            except Exception as e:
                logger.warning(f"æ–‡æ¡£å›¾ç‰‡æå–å¤±è´¥: {e}")
        
        return '\n'.join(text_parts)
    
    def _extract_from_content(self, content: str) -> List[Dict]:
        """
        ä»æ­£æ–‡è¯†åˆ«æ¡æ¬¾ç»“æ„ï¼ˆæ™ºèƒ½ã€å¤šé˜¶æ®µè¯†åˆ«ï¼‰
        
        è¯†åˆ«ç­–ç•¥ï¼š
        1. è·³è¿‡ç›®å½•éƒ¨åˆ†ï¼ˆå¤§é‡"ä¸€ã€äºŒã€ä¸‰"ä½†ç¼–å·ä¸è¿ç»­ï¼‰
        2. è¯†åˆ«ç¼–å·çš„è¿ç»­æ€§ï¼ˆ1. 1.1 1.1.1 ç­‰åºåˆ—ï¼‰
        3. åŸºäºç¼–å·å‰ç¼€è¯†åˆ«å±‚çº§å…³ç³»
        4. ç¡®ä¿è¯†åˆ«çš„æ¡æ¬¾ä¸ç›®å½•å†…å®¹ä¸€è‡´
        
        æ”¯æŒçš„æ ¼å¼ï¼š
        - 1. æ¡æ¬¾æ ‡é¢˜ (L1ä¸»æ¡æ¬¾)
        - 1.1 å­æ¡æ¬¾ æˆ– 1.1å­æ¡æ¬¾ (L2, å…è®¸æ²¡æœ‰ç©ºæ ¼)
        - 1.1.1 å­å­æ¡æ¬¾ (L3)
        - 1.1.1.1 è¯¦ç»†å®šä¹‰ (L4)
        - ä¸€ã€äºŒã€ä¸‰ ç­‰ç›®å½•æ ¼å¼ï¼ˆä»…åœ¨å¼€å¤´ï¼‰
        
        Args:
            content: æ–‡æ¡£å…¨æ–‡
            
        Returns:
            list: ç« èŠ‚åˆ—è¡¨ï¼ŒåªåŒ…å«å®é™…çš„æ¡æ¬¾ç¼–å·
        """
        # ä¼˜å…ˆä½¿ç”¨å¢å¼ºç‰ˆæå–å™¨ï¼ˆæ”¯æŒâ€œç¬¬Xéƒ¨åˆ†/ä¸­æ–‡ç¼–å·/ä¸»ç« èŠ‚/é™„ä»¶â€å…¨å±‚çº§ï¼‰
        try:
            enhanced = self.enhanced_extractor.extract_chapters(content)
            if enhanced:
                return enhanced
        except Exception:
            # å›é€€åˆ°æ—§ç‰ˆé€»è¾‘
            pass

        lines = content.split('\n')
        
        # ===== ç¬¬ä¸€é˜¶æ®µï¼šæ‰¾åˆ°ç¬¬ä¸€ä¸ª"ä¸»æ¡æ¬¾"ï¼ˆé€šå¸¸æ˜¯1.ï¼‰=====
        main_clause_idx = self._find_first_main_clause(lines)
        if main_clause_idx < 0:
            return []
        
        # ===== ç¬¬äºŒé˜¶æ®µï¼šä»ä¸»æ¡æ¬¾å¼€å§‹æ”¶é›†æ‰€æœ‰ç¼–å·æ¡æ¬¾ =====
        chapters = []
        seen_numbers = set()  # é˜²æ­¢é‡å¤
        
        # æ¡æ¬¾ç¼–å·çš„æ­£åˆ™æ¨¡å¼ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼Œå…è®¸ç¼–å·å’Œæ ‡é¢˜ä¹‹é—´æ²¡æœ‰ç©ºæ ¼ï¼‰
        patterns = [
            # 4çº§: 1.1.1.1 (å¯é€‰ç©ºæ ¼) æ ‡é¢˜
            (r'^(\d+)\.(\d+)\.(\d+)\.(\d+)[\sã€€]*(.+)$', 4),
            # 3çº§: 1.1.1 (å¯é€‰ç©ºæ ¼) æ ‡é¢˜
            (r'^(\d+)\.(\d+)\.(\d+)[\sã€€]*(.+)$', 3),
            # 2çº§: 1.1 (å¯é€‰ç©ºæ ¼) æ ‡é¢˜
            (r'^(\d+)\.(\d+)[\sã€€]*(.+)$', 2),
            # 1çº§: 1. æˆ– 1 . (å¼ºåˆ¶æœ‰ç©ºæ ¼/ç‚¹å·)
            (r'^(\d+)[\sã€€]\.[\sã€€]*(.+)$', 1),
        ]
        
        for line_idx in range(main_clause_idx, len(lines)):
            line = lines[line_idx].strip()
            
            if not line or len(line) < 3:
                continue
            
            # å°è¯•åŒ¹é…ç¼–å·æ¨¡å¼
            matched = False
            for pattern, level in patterns:
                match = re.match(pattern, line)
                if not match:
                    continue
                
                # æå–ç¼–å·å’Œæ ‡é¢˜
                if level == 1:
                    number = match.group(1)
                    title = match.group(2).strip()
                elif level in [2, 3, 4]:
                    # è·å–æ‰€æœ‰æ•°å­—éƒ¨åˆ†ç»„æˆç¼–å·
                    groups = match.groups()[:-1]  # å»æ‰æ ‡é¢˜
                    number = '.'.join(str(g) for g in groups)
                    title = match.groups()[-1].strip()
                else:
                    continue
                
                # è¿‡æ»¤æ— æ•ˆæ ‡é¢˜
                if len(title) < 2 or title in ['ã€‚', 'ï¼Œ', 'ã€', 'ï¼›', 'ï¼š', 'â€¦']:
                    break
                
                # ===== æ–°å¢ï¼šè¿‡æ»¤æ•°å­—ç›¸å…³çš„æ— æ•ˆç« èŠ‚ =====
                # 1. æ ‡é¢˜åªæœ‰1-3ä¸ªå­—ç¬¦ä¸”åŒ…å«å•ä½è¯çš„ï¼Œä¸æ˜¯ç« èŠ‚æ ‡é¢˜ï¼ˆå¦‚"ä¸‡å…ƒ"ã€"ç±³"ã€"å¤©"ï¼‰
                if len(title) <= 3:
                    if any(unit in title for unit in ['å…ƒ', 'ç±³', 'å¤©', 'å¹´', 'æœˆ', 'æ—¥', 'å¨', 'ä¸ª', 'æ¬¡', 'é¡¹']):
                        break
                
                # 2. æ ‡é¢˜ä»¥"æ¬¾"ã€"æ¡"ç­‰æ³•å¾‹ç”¨è¯å¼€å¤´ï¼Œä¸”åé¢è·Ÿç€ä¸­æ–‡æ‹¬å·ï¼Œå¾ˆå¯èƒ½æ˜¯æ­£æ–‡ç‰‡æ®µ
                if title.startswith(('æ¬¾', 'æ¡', 'é¡¹')) and ('ã€”' in title or 'ã€' in title or 'ï¼ˆ' in title):
                    break
                
                # 3. ç¼–å·ä¸åˆç†ï¼šè¶…è¿‡50ï¼ˆä¸€èˆ¬åˆåŒæœ€å¤š21-30ç« ï¼‰ä¸”level=2
                if level == 2:
                    try:
                        first_num = int(number.split('.')[0])
                        if first_num > 50:  # è¶…è¿‡50ç« æ˜æ˜¾ä¸å¯¹
                            break
                    except:
                        pass
                
                # 4. æ ‡é¢˜å¼€å¤´æ˜¯æ‹¬å·ã€æ•°å­—ï¼ˆä½†å…è®¸æ­£å¸¸çš„ä¸­æ–‡æ ‡é¢˜ï¼‰
                if title[0] in ['(', 'ï¼ˆ', '[', 'ã€', ')', 'ï¼‰', ']', 'ã€‘']:
                    break
                if title[0].isdigit() and len(title) <= 5:  # çº¯æ•°å­—å¼€å¤´ä¸”çŸ­æ ‡é¢˜æ‰è¿‡æ»¤
                    break
                
                # é˜²æ­¢é‡å¤
                if number in seen_numbers:
                    break
                
                seen_numbers.add(number)
                
                # ä»æ ‡é¢˜ä¸­å»æ‰å°¾éƒ¨çš„å®šä¹‰å†…å®¹ï¼ˆå†’å·ä¹‹åï¼‰
                # ä½†è¦ä¿æŒä¸€å®šçš„æ ‡é¢˜é•¿åº¦ï¼ˆé˜²æ­¢è¿‡åº¦è£å‰ªï¼‰
                if 'ï¼š' in title:
                    before_colon = title.split('ï¼š')[0].strip()
                    # åªåœ¨å†’å·å‰éƒ¨åˆ†è¶³å¤Ÿé•¿æ—¶æ‰ä½¿ç”¨
                    if len(before_colon) > 1:
                        title = before_colon
                
                # æ¸…ç†æ ‡é¢˜ä¸­å¯èƒ½å­˜åœ¨çš„å¤šè¡Œå†…å®¹
                # PDFæå–æ—¶ç»å¸¸å°†æ ‡é¢˜åˆ†æˆå¤šè¡Œ
                title = title.replace('\n', '').replace('ã€€', ' ').replace('  ', ' ').strip()
                
                # åˆ›å»ºç« èŠ‚æ¡ç›®
                chapter = {
                    'chapter_number': number,
                    'chapter_title': title,
                    'chapter_level': level,
                    'content': ''
                }
                chapters.append(chapter)
                matched = True
                break
        
        # ===== ç¬¬ä¸‰é˜¶æ®µï¼šéªŒè¯è¯†åˆ«ç»“æœ =====
        # è‡³å°‘éœ€è¦3ä¸ªæ¡æ¬¾
        if len(chapters) >= 3:
            # ç¬¬å››é˜¶æ®µï¼šåå¤„ç† - ä¿®å¤è¢«åˆ†å‰²çš„æ ‡é¢˜
            chapters = self._repair_split_titles(chapters)
            return chapters
        
        return []
    
    def _repair_split_titles(self, chapters: List[Dict]) -> List[Dict]:
        """
        ä¿®å¤è¢«PDFåˆ†å‰²å¯¼è‡´çš„æ ‡é¢˜ç¢ç‰‡åŒ–ï¼ˆä¿å®ˆç‰ˆï¼‰
        
        ç­–ç•¥ï¼šåªæ¸…ç†æ¯ä¸ªæ ‡é¢˜å†…éƒ¨çš„æ¢è¡Œå’Œç©ºæ ¼ï¼Œä¸åˆå¹¶ä¸åŒçš„æ¡æ¬¾
        
        Args:
            chapters: åŸå§‹æ¡æ¬¾åˆ—è¡¨
            
        Returns:
            list: ä¿®å¤åçš„æ¡æ¬¾åˆ—è¡¨
        """
        repaired = []
        
        for chapter in chapters:
            cleaned = chapter.copy()
            # æ¸…ç†æ ‡é¢˜ï¼šå»é™¤æ¢è¡Œã€å¤šä½™ç©ºæ ¼
            title = chapter['chapter_title']
            title = title.replace('\n', '').replace('  ', ' ').strip()
            cleaned['chapter_title'] = title
            repaired.append(cleaned)
        
        return repaired
    
    def _find_first_main_clause(self, lines: List[str]) -> int:
        """
        æ‰¾åˆ°ç¬¬ä¸€ä¸ªä¸»æ¡æ¬¾ï¼ˆ1. å¼€å¤´ï¼‰çš„è¡Œç´¢å¼•
        è¿™æ ‡å¿—ç€æ­£æ–‡æ¡æ¬¾å†…å®¹çš„çœŸæ­£å¼€å§‹
        
        å…³é”®ï¼šéœ€è¦åŒºåˆ†ä¸¤ç§"1."æ ¼å¼ï¼š
        1. ç›®å½•ä¸­çš„"1. æ¡æ¬¾......é¡µç "ï¼ˆæœ‰å¤§é‡ç‚¹å·ï¼‰
        2. æ­£æ–‡ä¸­çš„"1. æ¡æ¬¾" ï¼ˆæ— ç‚¹å·ï¼‰
        
        ç­–ç•¥ï¼š
        - æ‰¾æ‰€æœ‰"1."å¼€å¤´çš„è¡Œ
        - åé¢è·Ÿç€"1.1"ç­‰å­æ¡æ¬¾çš„æ‰æ˜¯çœŸæ­£çš„æ­£æ–‡
        
        Args:
            lines: åˆ†è¡Œçš„æ–‡æœ¬
            
        Returns:
            int: ç¬¬ä¸€ä¸ªä¸»æ¡æ¬¾çš„è¡Œç´¢å¼•ï¼Œæœªæ‰¾åˆ°è¿”å›-1
        """
        # ç¬¬ä¸€æ­¥ï¼šæ‰¾åˆ°æ‰€æœ‰å¯èƒ½æ˜¯"1."çš„è¡Œç´¢å¼•
        candidate_indices = []
        for idx, line in enumerate(lines):
            line_stripped = line.strip()
            if not line_stripped:
                continue
            # "1."å¼€å¤´ï¼Œä¸è¦æ±‚åé¢ä¸€å®šæœ‰ç©ºæ ¼
            if re.match(r'^1[\sã€€]*\.', line_stripped):
                candidate_indices.append(idx)
        
        # ç¬¬äºŒæ­¥ï¼šå¯¹æ¯ä¸ªå€™é€‰è€…ï¼Œæ£€æŸ¥åç»­æ˜¯å¦æœ‰"1.1"ç­‰å­æ¡æ¬¾
        # è¿™æ˜¯åŒºåˆ†ç›®å½•å’Œæ­£æ–‡çš„å…³é”®
        for idx in candidate_indices:
            # æ£€æŸ¥åç»­30è¡Œä¸­æ˜¯å¦æœ‰"1.1"å­æ¡æ¬¾
            has_sub_clause = False
            for check_idx in range(idx + 1, min(idx + 30, len(lines))):
                check_line = lines[check_idx].strip()
                # å¯»æ‰¾1.1å¼€å¤´çš„è¡Œï¼ˆå¸¦æˆ–ä¸å¸¦ç©ºæ ¼ï¼‰
                if re.match(r'^1\.1[\sã€€]*', check_line):
                    has_sub_clause = True
                    break
            
            # å¦‚æœæ‰¾åˆ°å­æ¡æ¬¾ï¼Œé‚£ä¹ˆè¿™ä¸ªå€™é€‰è€…å°±æ˜¯çœŸæ­£çš„æ­£æ–‡å¼€å§‹
            if has_sub_clause:
                return idx
        
        return -1
    
    def _clean_text(self, text: str) -> str:
        """
        æ–‡æœ¬æ¸…ç†ï¼šå»é™¤ä¸­æ–‡å­—ç¬¦é—´çš„ç©ºæ ¼

        Args:
            text: åŸå§‹æ–‡æœ¬

        Returns:
            str: æ¸…ç†åçš„æ–‡æœ¬
        """
        # 1. å»é™¤ä¸­æ–‡å­—ç¬¦é—´çš„ç©ºæ ¼å’Œå…¨è§’ç©ºæ ¼
        text = re.sub(r'([\u4e00-\u9fff])[\sã€€]+([\u4e00-\u9fff])', r'\1\2', text)
        
        # 2. å»é™¤ä¸­è‹±æ–‡é—´è¿‡å¤šçš„ç©ºæ ¼ï¼ˆä¿ç•™ä¸€ä¸ªï¼‰
        text = re.sub(r'([\u4e00-\u9fff])[\sã€€]{2,}([A-Za-z0-9])', r'\1 \2', text)
        text = re.sub(r'([A-Za-z0-9])[\sã€€]{2,}([\u4e00-\u9fff])', r'\1 \2', text)
        
        # 3. åˆå¹¶å¤šä¸ªç©ºæ ¼ä¸ºå•ä¸ª
        text = re.sub(r' {2,}', ' ', text)
        
        return text
    
    def _save_to_db(self, file_path: str, doc_type: str, content: str, chapters: List[Dict]) -> str:
        """
        ä¿å­˜æ–‡ä»¶å’Œç« èŠ‚åˆ°æ•°æ®åº“
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            doc_type: æ–‡æ¡£ç±»å‹
            content: å…¨æ–‡å†…å®¹
            chapters: ç« èŠ‚åˆ—è¡¨
            
        Returns:
            str: æ–‡ä»¶ID
        """
        filename = os.path.basename(file_path)
        filetype = os.path.splitext(filename)[1][1:]  # å»æ‰ç‚¹å·
        
        # 1. æ’å…¥æ–‡ä»¶è®°å½•
        allowed_doc_types = {"tender", "proposal", "reference"}
        safe_doc_type = doc_type if doc_type in allowed_doc_types else "reference"

        file_id = self.db.execute("""
            INSERT INTO files (filename, filepath, filetype, doc_type, content, metadata)
            VALUES (%s, %s, %s, %s, %s, %s)
            RETURNING id
        """, (filename, file_path, filetype, safe_doc_type, content, json.dumps({'total_chapters': len(chapters)})))
        
        # 2. æ‰¹é‡æ’å…¥ç« èŠ‚
        for idx, chapter in enumerate(chapters, start=1):
            self.db.execute("""
                INSERT INTO chapters (
                    file_id, chapter_number, chapter_title, chapter_level, 
                    content, position_order, structure_data
                ) VALUES (%s, %s, %s, %s, %s, %s, %s)
            """, (
                file_id,
                chapter['chapter_number'],
                chapter['chapter_title'],
                chapter['chapter_level'],
                chapter['content'],
                idx,
                json.dumps({'word_count': len(chapter['content'])})
            ))
        
        return file_id
