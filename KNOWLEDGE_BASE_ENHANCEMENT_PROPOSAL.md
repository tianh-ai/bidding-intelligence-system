# çŸ¥è¯†åº“ MCP å¢å¼ºæ–¹æ¡ˆ

## ğŸ“‹ ç°çŠ¶åˆ†æ

### âœ… å·²æœ‰åŸºç¡€è®¾æ–½

| ç»„ä»¶ | çŠ¶æ€ | ä½ç½® |
|------|------|------|
| **OpenAI é…ç½®** | âœ… å·²é…ç½® | `backend/core/config.py` |
| **å‘é‡æ•°æ®åº“** | âœ… å·²å¯ç”¨ | PostgreSQL + pgvector |
| **çŸ¥è¯†å›¾è°±** | âœ… å·²å®ç° | `backend/db/ontology.py` |
| **Embedding å­—æ®µ** | âœ… å·²åˆ›å»º | `knowledge_base.embedding VECTOR(1536)` |

### âŒ ç¼ºå°‘çš„æ ¸å¿ƒåŠŸèƒ½

| åŠŸèƒ½ | å½“å‰çŠ¶æ€ | é—®é¢˜ |
|------|---------|------|
| **å‘é‡æœç´¢** | âŒ æœªä½¿ç”¨ | åªæœ‰ LIKE æ¨¡ç³ŠåŒ¹é…ï¼Œæ— è¯­ä¹‰æœç´¢ |
| **çŸ¥è¯†å›¾è°±é›†æˆ** | âŒ æœªå…³è” | ontology ä¸ knowledge_base åˆ†ç¦» |
| **AI å¢å¼º** | âŒ æœªå®ç° | æ— è‡ªåŠ¨åˆ†ç±»ã€å…³é”®è¯æå–ã€æ‘˜è¦ç”Ÿæˆ |

---

## ğŸ¯ å»ºè®®å¢å¼ºæ–¹æ¡ˆ

### æ–¹æ¡ˆ 1: AI å‘é‡æœç´¢ï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸

#### åŠŸèƒ½æè¿°
ä½¿ç”¨ OpenAI Embeddings å®ç°è¯­ä¹‰æœç´¢ï¼Œæ›¿ä»£ç®€å•çš„ LIKE åŒ¹é…ã€‚

#### å®ç°å†…å®¹
```python
# 1. æ·»åŠ åˆ° knowledge_base.py
def search_knowledge_semantic(self, query: str, category=None, limit=10):
    """è¯­ä¹‰å‘é‡æœç´¢"""
    # ç”ŸæˆæŸ¥è¯¢å‘é‡
    query_embedding = openai.embeddings.create(
        input=query,
        model="text-embedding-3-small"
    ).data[0].embedding
    
    # å‘é‡ç›¸ä¼¼åº¦æœç´¢ï¼ˆä½™å¼¦è·ç¦»ï¼‰
    results = self.db.query("""
        SELECT 
            id, title, content, category,
            1 - (embedding <=> %s::vector) as similarity
        FROM knowledge_base
        WHERE embedding IS NOT NULL
            AND (category = %s OR %s IS NULL)
            AND 1 - (embedding <=> %s::vector) > 0.7
        ORDER BY embedding <=> %s::vector
        LIMIT %s
    """, (query_embedding, category, category, 
          query_embedding, query_embedding, limit))
    
    return results

# 2. è‡ªåŠ¨ç”Ÿæˆ embedding
def add_knowledge_entry(self, ..., auto_embed=True):
    """æ·»åŠ æ—¶è‡ªåŠ¨ç”Ÿæˆå‘é‡"""
    if auto_embed:
        embedding = openai.embeddings.create(
            input=f"{title}\n{content}",
            model="text-embedding-3-small"
        ).data[0].embedding
    
    self.db.execute("""
        INSERT INTO knowledge_base (...)
        VALUES (..., %s)
    """, (..., embedding))
```

#### ä¼˜åŠ¿
- âœ… è¯­ä¹‰ç†è§£ï¼ˆ"æŠ•æ ‡èµ„è´¨" = "æŠ•æ ‡äººèµ„æ ¼è¦æ±‚"ï¼‰
- âœ… è·¨è¯­è¨€æœç´¢
- âœ… æ¨¡ç³Šæ¦‚å¿µåŒ¹é…
- âœ… å‡†ç¡®ç‡æå‡ 30-50%

#### æ–°å¢ MCP å·¥å…·
- `search_knowledge_semantic` - è¯­ä¹‰æœç´¢
- `reindex_embeddings` - æ‰¹é‡é‡å»ºå‘é‡ç´¢å¼•

---

### æ–¹æ¡ˆ 2: çŸ¥è¯†å›¾è°±æ··åˆæ¶æ„ï¼ˆä¸­ä¼˜å…ˆçº§ï¼‰â­ï¸â­ï¸â­ï¸â­ï¸

#### åŠŸèƒ½æè¿°
å°† `knowledge_base` è¡¨ä¸ `ontology` çŸ¥è¯†å›¾è°±å…³è”ï¼Œå®ç°ç»“æ„åŒ– + éç»“æ„åŒ–æ··åˆå­˜å‚¨ã€‚

#### å®ç°å†…å®¹

##### 2.1 æ•°æ®åº“æ¶æ„æ‰©å±•
```sql
-- æ·»åŠ çŸ¥è¯†æ¡ç›®ä¸æœ¬ä½“èŠ‚ç‚¹çš„å…³è”è¡¨
CREATE TABLE knowledge_ontology_mapping (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    knowledge_id UUID REFERENCES knowledge_base(id) ON DELETE CASCADE,
    ontology_node_id UUID REFERENCES ontology_nodes(id) ON DELETE CASCADE,
    relation_type TEXT CHECK (relation_type IN (
        'describes',      -- æè¿°
        'supports',       -- æ”¯æŒ
        'contradicts',    -- çŸ›ç›¾
        'explains'        -- è§£é‡Š
    )),
    confidence_score DECIMAL(3,2) DEFAULT 1.0,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    UNIQUE(knowledge_id, ontology_node_id, relation_type)
);

-- ç´¢å¼•ä¼˜åŒ–
CREATE INDEX idx_ko_mapping_knowledge ON knowledge_ontology_mapping(knowledge_id);
CREATE INDEX idx_ko_mapping_ontology ON knowledge_ontology_mapping(ontology_node_id);
```

##### 2.2 æ··åˆæŸ¥è¯¢èƒ½åŠ›
```python
def search_with_graph_context(self, query: str, depth=2):
    """
    æ··åˆæœç´¢ï¼šå‘é‡æœç´¢ + å›¾è°±æ‰©å±•
    
    æµç¨‹ï¼š
    1. å‘é‡æœç´¢æ‰¾åˆ°ç›¸å…³çŸ¥è¯†æ¡ç›®
    2. é€šè¿‡å…³è”è¡¨æ‰¾åˆ°æœ¬ä½“èŠ‚ç‚¹
    3. å›¾éå†æ‰©å±•ç›¸å…³èŠ‚ç‚¹ï¼ˆ2å±‚æ·±åº¦ï¼‰
    4. è¿”å›çŸ¥è¯†æ¡ç›® + å…³è”çš„å›¾è°±ç»“æ„
    """
    # 1. å‘é‡æœç´¢
    knowledge_results = self.search_knowledge_semantic(query, limit=5)
    
    # 2. è·å–å…³è”çš„æœ¬ä½“èŠ‚ç‚¹
    knowledge_ids = [r['id'] for r in knowledge_results]
    ontology_nodes = self.db.query("""
        SELECT DISTINCT on.id, on.node_type, on.name
        FROM ontology_nodes on
        JOIN knowledge_ontology_mapping kom ON kom.ontology_node_id = on.id
        WHERE kom.knowledge_id = ANY(%s)
    """, (knowledge_ids,))
    
    # 3. å›¾éå†æ‰©å±•ï¼ˆé€’å½’ CTEï¼‰
    expanded_graph = self.db.query("""
        WITH RECURSIVE graph_expansion AS (
            -- èµ·å§‹èŠ‚ç‚¹
            SELECT id, node_type, name, 0 as depth
            FROM ontology_nodes
            WHERE id = ANY(%s)
            
            UNION ALL
            
            -- é€’å½’æ‰©å±•
            SELECT n.id, n.node_type, n.name, ge.depth + 1
            FROM ontology_nodes n
            JOIN ontology_relations r ON r.to_node_id = n.id
            JOIN graph_expansion ge ON r.from_node_id = ge.id
            WHERE ge.depth < %s
        )
        SELECT * FROM graph_expansion
    """, ([n['id'] for n in ontology_nodes], depth))
    
    return {
        "knowledge_entries": knowledge_results,
        "ontology_context": ontology_nodes,
        "expanded_graph": expanded_graph
    }
```

#### ä¼˜åŠ¿
- âœ… ç»“æ„åŒ–çŸ¥è¯† + éç»“æ„åŒ–æ–‡æœ¬
- âœ… å…³ç³»æ¨ç†èƒ½åŠ›ï¼ˆA ä¾èµ– Bï¼ŒB ä¾èµ– C â†’ A é—´æ¥ä¾èµ– Cï¼‰
- âœ… å†²çªæ£€æµ‹ï¼ˆå‘ç°çŸ›ç›¾çš„çŸ¥è¯†æ¡ç›®ï¼‰
- âœ… çŸ¥è¯†ç½‘ç»œå¯è§†åŒ–

#### æ–°å¢ MCP å·¥å…·
- `search_with_graph` - å›¾è°±å¢å¼ºæœç´¢
- `link_to_ontology` - å°†çŸ¥è¯†æ¡ç›®å…³è”åˆ°æœ¬ä½“èŠ‚ç‚¹
- `detect_conflicts` - æ£€æµ‹çŸ¥è¯†å†²çª
- `visualize_graph` - ç”ŸæˆçŸ¥è¯†å›¾è°±å¯è§†åŒ–æ•°æ®

---

### æ–¹æ¡ˆ 3: AI æ™ºèƒ½å¢å¼ºï¼ˆä¸­ä¼˜å…ˆçº§ï¼‰â­ï¸â­ï¸â­ï¸

#### åŠŸèƒ½æè¿°
ä½¿ç”¨ LLM è‡ªåŠ¨å¢å¼ºçŸ¥è¯†æ¡ç›®ï¼šåˆ†ç±»ã€å…³é”®è¯æå–ã€æ‘˜è¦ç”Ÿæˆã€å®ä½“è¯†åˆ«ã€‚

#### å®ç°å†…å®¹
```python
def enhance_knowledge_with_ai(self, knowledge_id: str):
    """
    AI æ™ºèƒ½å¢å¼ºçŸ¥è¯†æ¡ç›®
    
    åŠŸèƒ½ï¼š
    1. è‡ªåŠ¨åˆ†ç±»
    2. å…³é”®è¯æå–
    3. æ‘˜è¦ç”Ÿæˆ
    4. å®ä½“è¯†åˆ«ï¼ˆäººåã€æœºæ„ã€æŠ€æœ¯è§„æ ¼ç­‰ï¼‰
    5. æƒ…æ„Ÿåˆ†æï¼ˆé‡è¦æ€§è¯„åˆ†ï¼‰
    """
    # è·å–åŸå§‹å†…å®¹
    entry = self.get_knowledge_entry(knowledge_id)
    
    # è°ƒç”¨ OpenAI è¿›è¡Œå¢å¼º
    response = openai.chat.completions.create(
        model="gpt-4-turbo",
        messages=[{
            "role": "system",
            "content": """ä½ æ˜¯çŸ¥è¯†åº“æ™ºèƒ½å¢å¼ºåŠ©æ‰‹ã€‚åˆ†æç»™å®šçš„çŸ¥è¯†æ¡ç›®ï¼Œæå–ï¼š
1. category: åˆ†ç±»ï¼ˆtender/proposal/referenceï¼‰
2. keywords: 5-10ä¸ªå…³é”®è¯
3. summary: 100å­—æ‘˜è¦
4. entities: å®ä½“åˆ—è¡¨ {type: "person/org/spec", value: "..."}
5. importance_score: é‡è¦æ€§è¯„åˆ† 0-100
6. suggested_tags: å»ºè®®æ ‡ç­¾

ä»¥ JSON æ ¼å¼è¿”å›ã€‚"""
        }, {
            "role": "user",
            "content": f"æ ‡é¢˜: {entry['title']}\nå†…å®¹: {entry['content']}"
        }],
        response_format={"type": "json_object"}
    )
    
    # è§£æå¹¶æ›´æ–°
    enhancements = json.loads(response.choices[0].message.content)
    
    self.db.execute("""
        UPDATE knowledge_base
        SET 
            category = %s,
            keywords = %s,
            importance_score = %s,
            metadata = metadata || %s::jsonb
        WHERE id = %s
    """, (
        enhancements['category'],
        json.dumps(enhancements['keywords']),
        enhancements['importance_score'],
        json.dumps({
            'summary': enhancements['summary'],
            'entities': enhancements['entities'],
            'tags': enhancements['suggested_tags']
        }),
        knowledge_id
    ))
    
    return enhancements
```

#### ä¼˜åŠ¿
- âœ… å‡å°‘æ‰‹åŠ¨æ ‡æ³¨å·¥ä½œé‡
- âœ… æé«˜åˆ†ç±»å‡†ç¡®æ€§
- âœ… è‡ªåŠ¨å‘ç°å…³é”®ä¿¡æ¯
- âœ… ä¸€è‡´æ€§æ›´å¥½

#### æ–°å¢ MCP å·¥å…·
- `enhance_knowledge_ai` - AI å¢å¼ºå•ä¸ªæ¡ç›®
- `batch_enhance` - æ‰¹é‡å¢å¼º
- `extract_entities` - å®ä½“è¯†åˆ«
- `generate_summary` - è‡ªåŠ¨æ‘˜è¦

---

## ğŸ“Š ä¸‰ç§æ–¹æ¡ˆå¯¹æ¯”

| æ–¹æ¡ˆ | ä¼˜å…ˆçº§ | å®ç°éš¾åº¦ | æ•ˆæœæå‡ | ä¾èµ– AI | å¤‡æ³¨ |
|------|-------|---------|---------|---------|------|
| **å‘é‡æœç´¢** | â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸ | ä½ | é«˜ | æ˜¯ | **å¼ºçƒˆæ¨èä¼˜å…ˆå®ç°** |
| **çŸ¥è¯†å›¾è°±** | â­ï¸â­ï¸â­ï¸â­ï¸ | ä¸­ | ä¸­ | å¦ | é€‚åˆå¤æ‚å…³ç³»åœºæ™¯ |
| **AI å¢å¼º** | â­ï¸â­ï¸â­ï¸ | ä½ | ä¸­ | æ˜¯ | å‡å°‘äººå·¥å·¥ä½œ |

---

## ğŸ› ï¸ æ¨èå®æ–½é¡ºåº

### é˜¶æ®µ 1: å‘é‡æœç´¢ï¼ˆç«‹å³å®æ–½ï¼‰
```bash
# 1-2 å°æ—¶å¯å®Œæˆ
1. æ·»åŠ  search_knowledge_semantic() æ–¹æ³•
2. ä¿®æ”¹ add_knowledge_entry() è‡ªåŠ¨ç”Ÿæˆ embedding
3. æ·»åŠ  MCP å·¥å…·å®šä¹‰
4. æ›´æ–° TypeScript è·¯ç”±
5. æµ‹è¯•éªŒè¯
```

### é˜¶æ®µ 2: AI æ™ºèƒ½å¢å¼ºï¼ˆ1-2 å¤©ï¼‰
```bash
1. å®ç° enhance_knowledge_with_ai() æ–¹æ³•
2. æ·»åŠ æ‰¹é‡å¤„ç†èƒ½åŠ›
3. åˆ›å»ºåå°ä»»åŠ¡ï¼ˆCeleryï¼‰
4. å‰ç«¯å±•ç¤ºå¢å¼ºç»“æœ
```

### é˜¶æ®µ 3: çŸ¥è¯†å›¾è°±é›†æˆï¼ˆ3-5 å¤©ï¼‰
```bash
1. åˆ›å»º knowledge_ontology_mapping è¡¨
2. å®ç°æ··åˆæœç´¢
3. æ·»åŠ å›¾è°±å¯è§†åŒ–æ¥å£
4. å†²çªæ£€æµ‹ç®—æ³•
```

---

## ğŸ’¡ ä½¿ç”¨åœºæ™¯ç¤ºä¾‹

### åœºæ™¯ 1: æ™ºèƒ½æœç´¢
```python
# ç”¨æˆ·è¾“å…¥: "é¡¹ç›®ç»ç†éœ€è¦ä»€ä¹ˆèµ„è´¨ï¼Ÿ"

# å½“å‰å®ç°ï¼ˆLIKE åŒ¹é…ï¼‰ï¼š
results = search_knowledge("é¡¹ç›®ç»ç†", "tender")
# åªèƒ½åŒ¹é…åŒ…å«"é¡¹ç›®ç»ç†"æ–‡æœ¬çš„æ¡ç›®

# å¢å¼ºåï¼ˆå‘é‡æœç´¢ï¼‰ï¼š
results = search_knowledge_semantic("é¡¹ç›®ç»ç†éœ€è¦ä»€ä¹ˆèµ„è´¨ï¼Ÿ")
# å¯ä»¥æ‰¾åˆ°ï¼š
# - "é¡¹ç›®è´Ÿè´£äººèµ„æ ¼è¦æ±‚"ï¼ˆè¯­ä¹‰ç›¸ä¼¼ï¼‰
# - "å»ºé€ å¸ˆæ‰§ä¸šèµ„æ ¼è¯ä¹¦"ï¼ˆå…³è”æ¦‚å¿µï¼‰
# - "é¡¹ç›®ç®¡ç†ç»éªŒè¯æ˜"ï¼ˆç›¸å…³å†…å®¹ï¼‰
```

### åœºæ™¯ 2: çŸ¥è¯†ç½‘ç»œ
```python
# æŸ¥è¯¢: "æŠ•æ ‡ä¿è¯é‡‘"

# å¢å¼ºåï¼ˆå›¾è°±æœç´¢ï¼‰ï¼š
results = search_with_graph_context("æŠ•æ ‡ä¿è¯é‡‘", depth=2)

# è¿”å›ç»“æ„ï¼š
{
  "knowledge_entries": [
    {"title": "æŠ•æ ‡ä¿è¯é‡‘ç¼´çº³è¦æ±‚", "content": "..."}
  ],
  "ontology_context": [
    {"type": "requirement", "name": "æŠ•æ ‡ä¿è¯é‡‘"},
    {"type": "price_item", "name": "ä¿è¯é‡‘é‡‘é¢"},
    {"type": "constraint", "name": "ç¼´çº³æ—¶é™"}
  ],
  "relationships": [
    {"from": "æŠ•æ ‡ä¿è¯é‡‘", "to": "ä¿è¯é‡‘é‡‘é¢", "type": "requires"},
    {"from": "æŠ•æ ‡ä¿è¯é‡‘", "to": "ç¼´çº³æ—¶é™", "type": "depends_on"}
  ]
}

# å¯è§†åŒ–ï¼š
æŠ•æ ‡ä¿è¯é‡‘ â†’ requires â†’ ä¿è¯é‡‘é‡‘é¢ï¼ˆé¡¹ç›®æ€»ä»·2%ï¼‰
          â†“ depends_on
        ç¼´çº³æ—¶é™ï¼ˆæŠ•æ ‡æˆªæ­¢å‰24å°æ—¶ï¼‰
```

### åœºæ™¯ 3: è‡ªåŠ¨å¢å¼º
```python
# æ·»åŠ åŸå§‹çŸ¥è¯†æ¡ç›®
entry_id = add_knowledge_entry(
    title="èµ„è´¨è¦æ±‚",
    content="æŠ•æ ‡äººé¡»å…·æœ‰å»ºç­‘å·¥ç¨‹æ–½å·¥æ€»æ‰¿åŒ…ä¸€çº§åŠä»¥ä¸Šèµ„è´¨..."
)

# è‡ªåŠ¨ AI å¢å¼º
enhancements = enhance_knowledge_with_ai(entry_id)

# ç»“æœï¼š
{
  "category": "tender",  # è‡ªåŠ¨åˆ†ç±»
  "keywords": ["èµ„è´¨", "å»ºç­‘å·¥ç¨‹", "æ–½å·¥æ€»æ‰¿åŒ…", "ä¸€çº§"],
  "summary": "æŠ•æ ‡äººéœ€æŒæœ‰å»ºç­‘å·¥ç¨‹æ–½å·¥æ€»æ‰¿åŒ…ä¸€çº§æˆ–ä»¥ä¸Šèµ„è´¨è¯ä¹¦",
  "entities": [
    {"type": "qualification", "value": "å»ºç­‘å·¥ç¨‹æ–½å·¥æ€»æ‰¿åŒ…ä¸€çº§"},
  ],
  "importance_score": 92,  # é«˜é‡è¦æ€§
  "suggested_tags": ["èµ„è´¨è¦æ±‚", "æ€»æ‰¿åŒ…", "å‡†å…¥é—¨æ§›"]
}
```

---

## ğŸš¦ å†³ç­–å»ºè®®

### ç«‹å³å®æ–½ï¼ˆä»Šå¤©ï¼‰
âœ… **æ–¹æ¡ˆ 1: å‘é‡æœç´¢**
- æŠ•å…¥äº§å‡ºæ¯”æœ€é«˜
- å®ç°ç®€å•ï¼ˆ1-2å°æ—¶ï¼‰
- æ•ˆæœæ˜¾è‘—ï¼ˆå‡†ç¡®ç‡+30-50%ï¼‰

### çŸ­æœŸè§„åˆ’ï¼ˆæœ¬å‘¨ï¼‰
â³ **æ–¹æ¡ˆ 3: AI æ™ºèƒ½å¢å¼º**
- å‡å°‘æ‰‹åŠ¨æ ‡æ³¨
- æå‡æ•°æ®è´¨é‡
- ä¸ºå›¾è°±é›†æˆåšå‡†å¤‡

### ä¸­æœŸè§„åˆ’ï¼ˆä¸‹å‘¨ï¼‰
ğŸ“… **æ–¹æ¡ˆ 2: çŸ¥è¯†å›¾è°±é›†æˆ**
- å¤æ‚åº¦æœ€é«˜
- éœ€è¦å‰ç«¯å¯è§†åŒ–æ”¯æŒ
- é€‚åˆå·²æœ‰å¤§é‡çŸ¥è¯†æ¡ç›®åå®æ–½

---

## â“ éœ€è¦æ‚¨çš„å†³ç­–

è¯·å‘Šè¯‰æˆ‘ï¼š

1. **æ˜¯å¦å®æ–½å‘é‡æœç´¢ï¼Ÿ**ï¼ˆå¼ºçƒˆæ¨è âœ…ï¼‰
   - [ ] æ˜¯ï¼Œç«‹å³å®æ–½
   - [ ] å¦ï¼Œæš‚ç¼“

2. **æ˜¯å¦éœ€è¦çŸ¥è¯†å›¾è°±é›†æˆï¼Ÿ**
   - [ ] æ˜¯ï¼Œå®Œæ•´å®æ–½
   - [ ] æ˜¯ï¼Œä½†ç®€åŒ–ç‰ˆ
   - [ ] å¦ï¼Œæš‚ä¸éœ€è¦

3. **æ˜¯å¦éœ€è¦ AI æ™ºèƒ½å¢å¼ºï¼Ÿ**
   - [ ] æ˜¯ï¼Œå…¨éƒ¨åŠŸèƒ½
   - [ ] æ˜¯ï¼Œä»…è‡ªåŠ¨åˆ†ç±»å’Œå…³é”®è¯
   - [ ] å¦ï¼Œæ‰‹åŠ¨ç®¡ç†å³å¯

4. **OpenAI API Key é…ç½®ï¼Ÿ**
   - [ ] å·²é…ç½®åœ¨ .env æ–‡ä»¶
   - [ ] éœ€è¦æˆ‘æä¾›é…ç½®æŒ‡å¯¼
   - [ ] ä½¿ç”¨å…¶ä»– LLMï¼ˆè¯·è¯´æ˜ï¼‰

---

**æˆ‘çš„å»ºè®®**: å…ˆå®æ–½å‘é‡æœç´¢ï¼ˆæ–¹æ¡ˆ 1ï¼‰ï¼Œç«‹ç«¿è§å½±ã€‚çŸ¥è¯†å›¾è°±å’Œ AI å¢å¼ºå¯ä»¥åç»­è¿­ä»£æ·»åŠ ã€‚
