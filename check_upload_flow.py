#!/usr/bin/env python3
"""
å®Œæ•´ä¸Šä¼ æµç¨‹æ£€æŸ¥è„šæœ¬
éªŒè¯: æ–‡ä»¶å­˜å‚¨ã€æ•°æ®åº“è®°å½•ã€å›¾ç‰‡æå–ã€ç« èŠ‚è§£æçš„å®Œæ•´æ€§
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent / "backend"))

from database import db
from datetime import datetime, timedelta
import os


def print_header(title):
    print(f"\n{'='*70}")
    print(f"  {title}")
    print(f"{'='*70}\n")


def check_recent_uploads():
    """æ£€æŸ¥æœ€è¿‘ä¸Šä¼ çš„æ–‡ä»¶"""
    print_header("1. æ£€æŸ¥æœ€è¿‘ä¸Šä¼ çš„æ–‡ä»¶ (æ•°æ®åº“è®°å½•)")
    
    # è·å–æœ€è¿‘2å°æ—¶å†…ä¸Šä¼ çš„æ–‡ä»¶
    recent_time = datetime.now() - timedelta(hours=2)
    
    files = db.query(
        """
        SELECT 
            id, filename, semantic_filename,
            archive_path, category, status, file_size,
            created_at, status_updated_at
        FROM uploaded_files
        WHERE created_at >= %s
        ORDER BY created_at DESC
        """,
        (recent_time,)
    )
    
    if not files:
        print("âš ï¸  æœ€è¿‘2å°æ—¶å†…æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶")
        print("æç¤º: è¯·å…ˆä¸Šä¼ æ–‡ä»¶åå†è¿è¡Œæ­¤æ£€æŸ¥")
        return []
    
    print(f"æ‰¾åˆ° {len(files)} ä¸ªæœ€è¿‘ä¸Šä¼ çš„æ–‡ä»¶:\n")
    
    for i, f in enumerate(files, 1):
        print(f"æ–‡ä»¶ {i}:")
        print(f"  ID: {f['id']}")
        print(f"  æ–‡ä»¶å: {f['filename']}")
        print(f"  è¯­ä¹‰æ–‡ä»¶å: {f['semantic_filename']}")
        print(f"  åˆ†ç±»: {f['category']}")
        print(f"  çŠ¶æ€: {f['status']}")
        print(f"  æ–‡ä»¶å¤§å°: {f['file_size']} bytes")
        print(f"  å½’æ¡£è·¯å¾„: {f['archive_path']}")
        print(f"  ä¸Šä¼ æ—¶é—´: {f['created_at']}")
        print()
    
    return files


def check_physical_files(files):
    """æ£€æŸ¥ç‰©ç†æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    print_header("2. æ£€æŸ¥ç‰©ç†æ–‡ä»¶å­˜å‚¨")
    
    all_exist = True
    
    for f in files:
        archive_path = f['archive_path']
        filename = f['semantic_filename'] or f['filename']
        
        print(f"æ–‡ä»¶: {filename}")
        print(f"  è·¯å¾„: {archive_path}")
        
        if not archive_path:
            print(f"  âŒ archive_path ä¸ºç©º")
            all_exist = False
        elif os.path.exists(archive_path):
            size = os.path.getsize(archive_path)
            print(f"  âœ… æ–‡ä»¶å­˜åœ¨ ({size} bytes)")
            
            # æ£€æŸ¥å¤§å°æ˜¯å¦åŒ¹é…
            if f['file_size'] and abs(size - f['file_size']) > 1000:
                print(f"  âš ï¸  å¤§å°ä¸åŒ¹é… (æ•°æ®åº“:{f['file_size']}, å®é™…:{size})")
        else:
            print(f"  âŒ æ–‡ä»¶ä¸å­˜åœ¨")
            all_exist = False
        print()
    
    if all_exist:
        print("âœ… æ‰€æœ‰æ–‡ä»¶ç‰©ç†å­˜å‚¨æ­£ç¡®")
    else:
        print("âŒ éƒ¨åˆ†æ–‡ä»¶ç‰©ç†å­˜å‚¨ç¼ºå¤±")
    
    return all_exist


def check_parsed_content(files):
    """æ£€æŸ¥è§£æå†…å®¹"""
    print_header("3. æ£€æŸ¥æ–‡ä»¶è§£æå†…å®¹ (filesè¡¨)")
    
    all_parsed = True
    
    for f in files:
        file_id = str(f['id'])
        filename = f['semantic_filename'] or f['filename']
        
        print(f"æ–‡ä»¶: {filename}")
        
        # æŸ¥è¯¢filesè¡¨
        parsed = db.query_one(
            "SELECT id, filename, content, doc_type, created_at FROM files WHERE id = %s",
            (file_id,)
        )
        
        if not parsed:
            print(f"  âŒ filesè¡¨ä¸­æ²¡æœ‰è®°å½•")
            all_parsed = False
        else:
            content_len = len(parsed['content'] or '')
            print(f"  âœ… å·²è§£æ")
            print(f"  æ–‡æ¡£ç±»å‹: {parsed['doc_type']}")
            print(f"  å†…å®¹é•¿åº¦: {content_len} å­—ç¬¦")
            
            if content_len == 0:
                print(f"  âš ï¸  å†…å®¹ä¸ºç©ºï¼Œå¯èƒ½è§£æå¤±è´¥")
                all_parsed = False
            elif content_len < 50:
                print(f"  âš ï¸  å†…å®¹è¿‡çŸ­ï¼Œå¯èƒ½è§£æä¸å®Œæ•´")
        print()
    
    if all_parsed:
        print("âœ… æ‰€æœ‰æ–‡ä»¶å·²æ­£ç¡®è§£æ")
    else:
        print("âŒ éƒ¨åˆ†æ–‡ä»¶è§£æå¼‚å¸¸")
    
    return all_parsed


def check_chapters(files):
    """æ£€æŸ¥ç« èŠ‚æå–"""
    print_header("4. æ£€æŸ¥ç« èŠ‚ç»“æ„æå– (chaptersè¡¨)")
    
    all_have_chapters = True
    
    for f in files:
        file_id = str(f['id'])
        filename = f['semantic_filename'] or f['filename']
        
        print(f"æ–‡ä»¶: {filename}")
        
        # æŸ¥è¯¢ç« èŠ‚
        chapters = db.query(
            """
            SELECT 
                id, chapter_number, chapter_title, chapter_level,
                LENGTH(content) as content_len, position_order
            FROM chapters
            WHERE file_id = %s
            ORDER BY position_order
            """,
            (file_id,)
        )
        
        if not chapters:
            print(f"  âš ï¸  æ²¡æœ‰ç« èŠ‚è®°å½•ï¼ˆå¯èƒ½æ˜¯å•ç« èŠ‚æ–‡æ¡£ï¼‰")
        else:
            print(f"  âœ… æå–äº† {len(chapters)} ä¸ªç« èŠ‚:")
            
            for ch in chapters[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                print(f"    {ch['chapter_number']}. {ch['chapter_title'][:40]}")
                print(f"       çº§åˆ«:{ch['chapter_level']}, å†…å®¹:{ch['content_len']}å­—ç¬¦")
            
            if len(chapters) > 5:
                print(f"    ... è¿˜æœ‰ {len(chapters) - 5} ä¸ªç« èŠ‚")
        print()
    
    return all_have_chapters


def check_images(files):
    """æ£€æŸ¥å›¾ç‰‡æå–"""
    print_header("5. æ£€æŸ¥å›¾ç‰‡æå– (extracted_imagesè¡¨)")
    
    total_images = 0
    
    for f in files:
        file_id = str(f['id'])
        filename = f['semantic_filename'] or f['filename']
        
        print(f"æ–‡ä»¶: {filename}")
        
        # æŸ¥è¯¢å›¾ç‰‡
        images = db.query(
            """
            SELECT 
                id, image_path, image_number, format, 
                size, width, height, hash
            FROM extracted_images
            WHERE file_id = %s
            ORDER BY image_number
            """,
            (file_id,)
        )
        
        if not images:
            print(f"  â„¹ï¸  æ²¡æœ‰æå–åˆ°å›¾ç‰‡ï¼ˆæ–‡æ¡£å¯èƒ½ä¸åŒ…å«å›¾ç‰‡ï¼‰")
        else:
            print(f"  âœ… æå–äº† {len(images)} å¼ å›¾ç‰‡:")
            total_images += len(images)
            
            for img in images[:3]:  # åªæ˜¾ç¤ºå‰3å¼ 
                print(f"    å›¾ç‰‡ {img['image_number']}: {img['format']}, {img['width']}x{img['height']}, {img['size']} bytes")
                print(f"      è·¯å¾„: {img['image_path']}")
                
                # æ£€æŸ¥å›¾ç‰‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                if os.path.exists(img['image_path']):
                    print(f"      âœ… æ–‡ä»¶å­˜åœ¨")
                else:
                    print(f"      âŒ æ–‡ä»¶ä¸å­˜åœ¨")
            
            if len(images) > 3:
                print(f"    ... è¿˜æœ‰ {len(images) - 3} å¼ å›¾ç‰‡")
        print()
    
    print(f"æ€»è®¡æå–å›¾ç‰‡: {total_images} å¼ ")
    return total_images


def check_storage_structure():
    """æ£€æŸ¥å­˜å‚¨ç›®å½•ç»“æ„"""
    print_header("6. æ£€æŸ¥å­˜å‚¨ç›®å½•ç»“æ„")
    
    base_path = Path("/Volumes/ssd/bidding-data")
    
    directories = {
        "ä¸´æ—¶ä¸Šä¼ ": base_path / "uploads" / "temp",
        "å½’æ¡£ç›®å½•": base_path / "archive",
        "å›¾ç‰‡ç›®å½•": base_path / "images",
        "æ—¥å¿—ç›®å½•": base_path / "logs",
    }
    
    for name, path in directories.items():
        print(f"{name}: {path}")
        if path.exists():
            # ç»Ÿè®¡æ–‡ä»¶æ•°é‡
            if path.is_dir():
                file_count = sum(1 for _ in path.rglob('*') if _.is_file())
                dir_count = sum(1 for _ in path.rglob('*') if _.is_dir())
                print(f"  âœ… å­˜åœ¨ ({file_count} ä¸ªæ–‡ä»¶, {dir_count} ä¸ªå­ç›®å½•)")
            else:
                print(f"  âœ… å­˜åœ¨")
        else:
            print(f"  âŒ ä¸å­˜åœ¨")
        print()


def check_knowledge_base():
    """æ£€æŸ¥çŸ¥è¯†åº“å‘é‡åŒ–"""
    print_header("7. æ£€æŸ¥çŸ¥è¯†åº“å‘é‡åŒ– (å¯é€‰)")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å‘é‡è¡¨
    try:
        tables = db.query(
            """
            SELECT tablename 
            FROM pg_tables 
            WHERE schemaname = 'public' 
            AND tablename LIKE '%vector%' OR tablename LIKE '%embedding%'
            """
        )
        
        if tables:
            print("æ‰¾åˆ°å‘é‡ç›¸å…³è¡¨:")
            for t in tables:
                print(f"  - {t['tablename']}")
                
                # ç»Ÿè®¡è®°å½•æ•°
                count = db.query_one(f"SELECT COUNT(*) as count FROM {t['tablename']}")
                print(f"    è®°å½•æ•°: {count['count']}")
        else:
            print("â„¹ï¸  æœªå‘ç°å‘é‡è¡¨ï¼ˆçŸ¥è¯†åº“åŠŸèƒ½å¯èƒ½æœªå¯ç”¨ï¼‰")
            
    except Exception as e:
        print(f"âš ï¸  æ£€æŸ¥å‘é‡è¡¨å¤±è´¥: {e}")


def generate_report(files):
    """ç”Ÿæˆæ£€æŸ¥æŠ¥å‘Š"""
    print_header("æ£€æŸ¥æ€»ç»“")
    
    print(f"ğŸ“Š ä¸Šä¼ æ–‡ä»¶æ•°: {len(files)}")
    
    # ç»Ÿè®¡å„é¡¹æŒ‡æ ‡
    total_size = sum(f['file_size'] or 0 for f in files)
    
    total_parsed = db.query_one(
        """
        SELECT COUNT(*) as count, SUM(LENGTH(content)) as total_content
        FROM files
        WHERE id = ANY(%s::uuid[])
        """,
        ([str(f['id']) for f in files],)
    )
    
    total_chapters = db.query_one(
        """
        SELECT COUNT(*) as count
        FROM chapters
        WHERE file_id = ANY(%s::uuid[])
        """,
        ([str(f['id']) for f in files],)
    )
    
    total_images = db.query_one(
        """
        SELECT COUNT(*) as count, SUM(size) as total_size
        FROM extracted_images
        WHERE file_id = ANY(%s::uuid[])
        """,
        ([str(f['id']) for f in files],)
    )
    
    print(f"ğŸ“ æ–‡ä»¶æ€»å¤§å°: {total_size:,} bytes ({total_size/1024/1024:.2f} MB)")
    print(f"ğŸ“„ è§£æå†…å®¹æ€»é•¿åº¦: {total_parsed['total_content'] or 0:,} å­—ç¬¦")
    print(f"ğŸ“‘ ç« èŠ‚æ€»æ•°: {total_chapters['count'] or 0}")
    print(f"ğŸ–¼ï¸  å›¾ç‰‡æ€»æ•°: {total_images['count'] or 0} å¼  ({(total_images['total_size'] or 0)/1024:.1f} KB)")
    
    print("\n" + "="*70)


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "="*70)
    print("  æ ‡ä¹¦æ™ºèƒ½ç³»ç»Ÿ - ä¸Šä¼ æµç¨‹å®Œæ•´æ€§æ£€æŸ¥")
    print("  æ£€æŸ¥èŒƒå›´: æœ€è¿‘2å°æ—¶å†…ä¸Šä¼ çš„æ–‡ä»¶")
    print("="*70)
    
    try:
        # 1. æ£€æŸ¥æ•°æ®åº“è®°å½•
        files = check_recent_uploads()
        
        if not files:
            return
        
        # 2. æ£€æŸ¥ç‰©ç†æ–‡ä»¶
        check_physical_files(files)
        
        # 3. æ£€æŸ¥è§£æå†…å®¹
        check_parsed_content(files)
        
        # 4. æ£€æŸ¥ç« èŠ‚
        check_chapters(files)
        
        # 5. æ£€æŸ¥å›¾ç‰‡
        check_images(files)
        
        # 6. æ£€æŸ¥å­˜å‚¨ç»“æ„
        check_storage_structure()
        
        # 7. æ£€æŸ¥çŸ¥è¯†åº“
        check_knowledge_base()
        
        # 8. ç”ŸæˆæŠ¥å‘Š
        generate_report(files)
        
        print("\nâœ… æ£€æŸ¥å®Œæˆ!")
        
    except KeyboardInterrupt:
        print("\n\næ£€æŸ¥ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æ£€æŸ¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
