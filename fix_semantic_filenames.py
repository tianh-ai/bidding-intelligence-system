#!/usr/bin/env python3
"""
ç´§æ€¥ä¿®å¤è„šæœ¬ï¼šä¿®æ­£å·²ä¸Šä¼ æ–‡ä»¶çš„è¯­ä¹‰æ–‡ä»¶å
ä¸ºæ‰€æœ‰æ²¡æœ‰hashåç¼€çš„æ–‡ä»¶é‡æ–°ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent / "backend"))

from database import db
from engines.document_classifier import DocumentClassifier
import shutil
import os


def fix_uploaded_files():
    """ä¿®å¤æ‰€æœ‰æ²¡æœ‰hashåç¼€çš„æ–‡ä»¶"""
    
    print("\n" + "="*70)
    print("  ç´§æ€¥ä¿®å¤ï¼šä¸ºå·²ä¸Šä¼ æ–‡ä»¶æ·»åŠ hashåç¼€")
    print("="*70 + "\n")
    
    # è·å–æ‰€æœ‰è¯­ä¹‰æ–‡ä»¶åæ²¡æœ‰hashçš„æ–‡ä»¶
    files = db.query(
        """
        SELECT id, filename, semantic_filename, archive_path, category
        FROM uploaded_files
        WHERE semantic_filename IS NOT NULL
        ORDER BY created_at DESC
        LIMIT 100
        """
    )
    
    if not files:
        print("âœ… æ²¡æœ‰éœ€è¦ä¿®å¤çš„æ–‡ä»¶")
        return
    
    print(f"æ‰¾åˆ° {len(files)} ä¸ªéœ€è¦ä¿®å¤çš„æ–‡ä»¶\n")
    
    classifier = DocumentClassifier()
    fixed_count = 0
    failed_count = 0
    
    for f in files:
        file_id = str(f['id'])
        old_semantic = f['semantic_filename']
        old_path = f['archive_path']
        original_filename = f['filename']
        category = f['category']
        
        print(f"å¤„ç†: {original_filename}")
        print(f"  å½“å‰è¯­ä¹‰å: {old_semantic}")
        
        try:
            # ç”Ÿæˆæ–°çš„è¯­ä¹‰æ–‡ä»¶åï¼ˆå¸¦hashï¼‰
            new_semantic = classifier.generate_semantic_filename(
                original_filename=original_filename,
                category=category,
                metadata={},
                content=''
            )
            
            print(f"  æ–°è¯­ä¹‰å: {new_semantic}")
            
            if old_semantic == new_semantic:
                print(f"  â„¹ï¸  æ–‡ä»¶åæœªå˜åŒ–ï¼Œè·³è¿‡")
                continue
            
            # ç”Ÿæˆæ–°è·¯å¾„
            new_path = old_path.replace(old_semantic, new_semantic) if old_path else None
            
            if new_path and old_path and os.path.exists(old_path):
                # ç¡®ä¿æ–°è·¯å¾„çš„ç›®å½•å­˜åœ¨
                os.makedirs(os.path.dirname(new_path), exist_ok=True)
                
                # å¦‚æœæ–°æ–‡ä»¶å·²å­˜åœ¨ï¼Œæ·»åŠ é¢å¤–åç¼€
                if os.path.exists(new_path):
                    print(f"  âš ï¸  ç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨: {new_path}")
                    # ä¸è¦†ç›–ï¼Œä¿ç•™æ—§çš„
                    print(f"  â„¹ï¸  åªæ›´æ–°æ•°æ®åº“è®°å½•")
                else:
                    # ç§»åŠ¨æ–‡ä»¶
                    shutil.move(old_path, new_path)
                    print(f"  âœ… æ–‡ä»¶å·²ç§»åŠ¨åˆ°: {new_path}")
            else:
                if not old_path:
                    print(f"  âš ï¸  archive_pathä¸ºç©º")
                elif not os.path.exists(old_path):
                    print(f"  âš ï¸  åŸæ–‡ä»¶ä¸å­˜åœ¨: {old_path}")
                new_path = None
            
            # æ›´æ–°æ•°æ®åº“
            db.execute(
                """
                UPDATE uploaded_files
                SET semantic_filename = %s,
                    archive_path = %s
                WHERE id = %s
                """,
                (new_semantic, new_path or old_path, file_id)
            )
            
            print(f"  âœ… æ•°æ®åº“å·²æ›´æ–°")
            fixed_count += 1
            
        except Exception as e:
            print(f"  âŒ ä¿®å¤å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            failed_count += 1
        
        print()
    
    print("="*70)
    print(f"ä¿®å¤å®Œæˆ: æˆåŠŸ{fixed_count}ä¸ª, å¤±è´¥{failed_count}ä¸ª")
    print("="*70 + "\n")
    
    # æ˜¾ç¤ºå½“å‰æ–‡ä»¶åˆ†å¸ƒ
    print("\nå½“å‰å½’æ¡£ç›®å½•æ–‡ä»¶åˆ†å¸ƒ:")
    print()
    
    archive_base = Path("/Volumes/ssd/bidding-data/archive")
    if archive_base.exists():
        for category_dir in ['tender', 'proposal', 'reference']:
            category_path = archive_base / "2025" / "12" / category_dir
            if category_path.exists():
                files = list(category_path.glob("*.docx"))
                print(f"  {category_dir}/: {len(files)} ä¸ªæ–‡ä»¶")
                for f in files[:5]:
                    size_mb = f.stat().st_size / 1024 / 1024
                    print(f"    - {f.name} ({size_mb:.2f} MB)")
                if len(files) > 5:
                    print(f"    ... è¿˜æœ‰ {len(files)-5} ä¸ª")
            else:
                print(f"  {category_dir}/: ç›®å½•ä¸å­˜åœ¨")
            print()


def check_duplicates():
    """æ£€æŸ¥æ˜¯å¦è¿˜æœ‰é‡å¤çš„è¯­ä¹‰æ–‡ä»¶å"""
    print("\næ£€æŸ¥é‡å¤æ–‡ä»¶å...")
    
    duplicates = db.query(
        """
        SELECT semantic_filename, COUNT(*) as count
        FROM uploaded_files
        WHERE semantic_filename IS NOT NULL
        GROUP BY semantic_filename
        HAVING COUNT(*) > 1
        ORDER BY count DESC
        """
    )
    
    if duplicates:
        print(f"\nâš ï¸  å‘ç° {len(duplicates)} ç»„é‡å¤æ–‡ä»¶å:")
        for dup in duplicates:
            print(f"  - {dup['semantic_filename']}: {dup['count']} ä¸ªæ–‡ä»¶")
    else:
        print("âœ… æ²¡æœ‰é‡å¤æ–‡ä»¶å")


if __name__ == "__main__":
    try:
        fix_uploaded_files()
        check_duplicates()
        
        print("\nğŸ’¡ å»ºè®®:")
        print("1. é‡æ–°ä¸Šä¼ ä¹‹å‰ä¸¢å¤±çš„æ–‡ä»¶ï¼ˆå¦‚æœè¿˜æœ‰å¤‡ä»½ï¼‰")
        print("2. æ¸…ç†æ•°æ®åº“ä¸­çš„é‡å¤è®°å½•")
        print("3. éªŒè¯æ‰€æœ‰æ–‡ä»¶çš„ç‰©ç†å­˜å‚¨å’Œè§£æå†…å®¹")
        
    except KeyboardInterrupt:
        print("\n\nä¿®å¤ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ ä¿®å¤å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
