# ğŸ” æ ‡ä¹¦æ™ºèƒ½ç³»ç»Ÿ - å·¥ä½œæµç¨‹å…¨å±€åˆ†æ

> **ç”Ÿæˆæ—¶é—´**: 2025-12-07  
> **åˆ†æèŒƒå›´**: ä»ç”¨æˆ·ç™»å½•åˆ°æ ‡ä¹¦ç”Ÿæˆçš„å®Œæ•´æ•°æ®æµè½¬

---

## ğŸ“Š æ ¸å¿ƒå·¥ä½œæµç¨‹æ¦‚è§ˆ

```mermaid
graph TB
    A[ç”¨æˆ·ç™»å½•] --> B[æ–‡ä»¶ä¸Šä¼ ]
    B --> C[æ–‡æ¡£è§£æ]
    C --> D[é€»è¾‘å­¦ä¹ ]
    D --> E{ä¿å­˜é€»è¾‘?}
    E -->|æ˜¯| F[å…¥åº“çŸ¥è¯†å›¾è°±]
    E -->|å¦| G[ä¸´æ—¶é€»è¾‘]
    F --> H[æ ‡ä¹¦ç”Ÿæˆ]
    G --> H
    H --> I[å¤šä»£ç†è¯„ä¼°]
    I --> J{åˆè§„æ£€æŸ¥}
    J -->|é€šè¿‡| K[è¾“å‡ºæ–‡ä»¶]
    J -->|ä¸é€šè¿‡| L[äººå·¥åé¦ˆ]
    L --> H
```

---

## 1ï¸âƒ£ ç”¨æˆ·è®¤è¯æµç¨‹

### å½“å‰çŠ¶æ€
âœ… **å·²å®ç°ä¸”è¿è¡Œæ­£å¸¸**

### æ•°æ®æµè½¬è·¯å¾„
```
å‰ç«¯ Login.tsx
  â†“ authAPI.login({username, password})
åç«¯ /api/auth/login
  â†“ create_access_token(role: admin/user)
JWT Token ç”Ÿæˆ
  â†“ è¿”å› {token, user: {id, username, email, role}}
å‰ç«¯ authStore.login(token, user)
  â†“ Zustand persist åˆ° localStorage['auth-storage']
åç»­è¯·æ±‚
  â†“ Authorization: Bearer <token>
åç«¯ä¸­é—´ä»¶ verify_token()
  â†“ è§£æ JWT payload: {sub, username, role, exp}
```

### âš ï¸ æ½œåœ¨é—®é¢˜
1. **Tokenåˆ·æ–°ç¼ºå¤±**: å½“å‰tokenè¿‡æœŸæ—¶é—´è§ `JWT_ACCESS_TOKEN_EXPIRE_MINUTES`ï¼Œæ— åˆ·æ–°æœºåˆ¶
2. **è§’è‰²æƒé™ç²’åº¦**: ä»… admin/user äºŒçº§ï¼Œç¼ºå°‘ç»†ç²’åº¦æƒé™æ§åˆ¶
3. **ä¼šè¯ç®¡ç†**: æ— ä¸»åŠ¨ç™»å‡ºé€šçŸ¥ï¼ˆå¦‚è¢«è¸¢ä¸‹çº¿ï¼‰

### âœ… éªŒè¯ç»“æœ
- âœ… Adminç™»å½•æ˜¾ç¤º"ç®¡ç†å‘˜"æ ‡ç­¾
- âœ… Userç™»å½•æ˜¾ç¤º"ç”¨æˆ·"æ ‡ç­¾
- âœ… Tokenæ­£ç¡®æºå¸¦roleå­—æ®µ

---

## 2ï¸âƒ£ æ–‡ä»¶ä¸Šä¼ ä¸å¤„ç†æµç¨‹

### å½“å‰çŠ¶æ€
âš ï¸ **åŸºç¡€åŠŸèƒ½å®Œæ•´ï¼Œå­˜åœ¨ä¼˜åŒ–ç©ºé—´**

### æ•°æ®æµè½¬è·¯å¾„
```
å‰ç«¯ FileUpload.tsx
  â†“ fileAPI.uploadFiles(formData: {files, doc_type, overwrite})
åç«¯ /api/files/upload (files.py:57)
  â†“ 1. SHA256å»é‡æ£€æŸ¥ (files.py:83-107)
  â†“ 2. ä¿å­˜æ–‡ä»¶åˆ° UPLOAD_DIR (files.py:108-135)
  â†“ 3. æ’å…¥ uploaded_files è¡¨ (files.py:144-161)
  â†“ 4. è§¦å‘ Celery å¼‚æ­¥è§£æ (files.py:167-174)
       background_tasks.add_task(parse_and_store_file)
Celery Worker
  â†“ tasks.process_uploaded_document (tasks.py:11)
  â†“ HybridParseEngine.parse_file()
  â†“ æå–: chapters, tables, metadata
  â†“ å­˜å…¥ PostgreSQL: tender_chapters, tender_tables
```

### ğŸ“ æ–‡ä»¶ç±»å‹æ”¯æŒçŸ©é˜µ
| æ ¼å¼ | è§£æå¼•æ“ | è¡¨æ ¼æå– | ç« èŠ‚è¯†åˆ« | å¤‡æ³¨ |
|------|----------|----------|----------|------|
| PDF | pdfplumber | âœ… 90%å‡†ç¡®ç‡ | âœ… æ­£åˆ™åŒ¹é… | æ¨è |
| DOCX | python-docx | âœ… 100% | âœ… æ®µè½æ ‡é¢˜ | æ¨è |
| XLSX | openpyxl | âœ… åŸç”Ÿ | âŒ ä¸é€‚ç”¨ | ä»…è¡¨æ ¼ |
| TXT | çº¯æ–‡æœ¬ | âŒ | âš ï¸ å¼±è¯†åˆ« | å¤‡ç”¨ |

### âš ï¸ å‘ç°çš„é—®é¢˜

#### é—®é¢˜1: é‡å¤æ–‡ä»¶å¤„ç†é€»è¾‘ä¸å®Œæ•´
**ä½ç½®**: `backend/routers/files.py:83-107`
```python
# å½“å‰é€»è¾‘ï¼šæ£€æµ‹åˆ°é‡å¤åä»…è¿”å›è­¦å‘Šï¼ŒæœªçœŸæ­£é˜»æ­¢ä¸Šä¼ 
if existing_file and not overwrite:
    duplicate_files.append({...})  # âš ï¸ ä½†æ–‡ä»¶ä»ä¼šç»§ç»­å¤„ç†
```
**å½±å“**: ç”¨æˆ·å¯èƒ½é‡å¤ä¸Šä¼ ç›¸åŒæ–‡ä»¶ï¼Œæµªè´¹å­˜å‚¨å’Œè§£æèµ„æº

**ä¿®å¤æ–¹æ¡ˆ**:
```python
if existing_file and not overwrite:
    duplicate_files.append({...})
    continue  # âœ… è·³è¿‡é‡å¤æ–‡ä»¶å¤„ç†
```

#### é—®é¢˜2: è§£æä»»åŠ¡æ— çŠ¶æ€åé¦ˆ
**ä½ç½®**: `backend/routers/files.py:167-174`
```python
background_tasks.add_task(parse_and_store_file, ...)
# âŒ å‰ç«¯æ— æ³•æŸ¥è¯¢è§£æè¿›åº¦
```
**å½±å“**: ç”¨æˆ·ä¸çŸ¥é“æ–‡ä»¶ä½•æ—¶å¯ç”¨äºå­¦ä¹ 

**ä¿®å¤æ–¹æ¡ˆ**: å¼•å…¥ä»»åŠ¡çŠ¶æ€è¡¨
```sql
CREATE TABLE file_parse_tasks (
    id uuid PRIMARY KEY,
    file_id uuid REFERENCES uploaded_files(id),
    status text CHECK(status IN ('pending','processing','completed','failed')),
    progress int DEFAULT 0,
    error_message text,
    created_at timestamptz DEFAULT now()
);
```

#### é—®é¢˜3: æ–‡ä»¶å¤§å°é™åˆ¶ç¼ºå¤±
**ä½ç½®**: `backend/routers/files.py:57` (upload endpoint)
```python
@router.post("/upload")
async def upload_files(...):
    # âŒ æ— æ–‡ä»¶å¤§å°éªŒè¯ï¼Œå¯èƒ½å¯¼è‡´å†…å­˜æº¢å‡º
```
**ä¿®å¤æ–¹æ¡ˆ**:
```python
MAX_FILE_SIZE = 50 * 1024 * 1024  # 50MB
for file in files:
    file_size = 0
    async for chunk in file.file:
        file_size += len(chunk)
        if file_size > MAX_FILE_SIZE:
            raise HTTPException(413, "æ–‡ä»¶è¿‡å¤§")
```

---

## 3ï¸âƒ£ é€»è¾‘å­¦ä¹ æµç¨‹

### å½“å‰çŠ¶æ€
âš ï¸ **æ¶æ„è®¾è®¡ä¼˜ç§€ï¼Œå®ç°éœ€å®Œå–„**

### å­¦ä¹ æ¨¡å¼å¯¹æ¯”
| æ¨¡å¼ | è§¦å‘ä½ç½® | å­¦ä¹ èŒƒå›´ | çŸ¥è¯†å›¾è°± | ç”¨é€” |
|------|----------|----------|----------|------|
| **ç« èŠ‚å­¦ä¹ ** | LogicLearning.tsx:237 | å•ä¸ªç« èŠ‚ | âœ… ä½¿ç”¨ | ç²¾ç»†åŒ–æå– |
| **å…¨å±€å­¦ä¹ ** | LogicLearning.tsx:349 | æ•´ä¸ªæ ‡ä¹¦ | âœ… ä½¿ç”¨ | å…¨å±€çº¦æŸ |
| **ä¸´æ—¶å­¦ä¹ ** | å‰ç«¯ä¼ å‚ `useTemporaryLogic` | ä»…æœ¬æ¬¡ | âŒ ä¸å†™å…¥ | æµ‹è¯•éªŒè¯ |

### æ•°æ®æµè½¬è·¯å¾„
```
å‰ç«¯ LogicLearning.tsx
  â†“ learningAPI.startChapterLearning({chapter_id, use_ontology: true})
åç«¯ /api/learning/chapter/learn (learning.py:237)
  â†“ 1. è·å–ç« èŠ‚å†…å®¹ (DB: tender_chapters)
  â†“ 2. ConstraintExtractor.extract_constraints()
       â”œâ”€ OpenAI Function Calling
       â”œâ”€ Pydantic Schema: ConstraintRule
       â””â”€ è¿”å›: {type, field, operator, value, reasoning}
  â†“ 3. OntologyManager.validate_with_ontology()
       â”œâ”€ æŸ¥è¯¢æœ¬ä½“å›¾è°± (9èŠ‚ç‚¹+7å…³ç³»)
       â””â”€ æ¶ˆæ­§ & è§„èŒƒåŒ–
  â†“ 4. å­˜å…¥ learned_logic_rules è¡¨
å‰ç«¯è½®è¯¢ /api/learning/status/{taskId}
  â†“ æ˜¾ç¤ºå­¦ä¹ è¿›åº¦ & è§„åˆ™é¢„è§ˆ
```

### ğŸ§  æœ¬ä½“çŸ¥è¯†å›¾è°±ç»“æ„
```sql
-- æ ¸å¿ƒèŠ‚ç‚¹ç±»å‹ (backend/db/ontology_schema.sql)
Node Types:
  1. Entity: é¡¹ç›®å®ä½“ (ä¸šä¸»ã€æ‰¿åŒ…å•†)
  2. Attribute: å±æ€§çº¦æŸ (èµ„è´¨ã€é‡‘é¢)
  3. Relation: å…³ç³»ç±»å‹ (ä»å±ã€åŒ…å«)
  4. Constraint: çº¦æŸè§„åˆ™ (å¿…é¡»ã€ç¦æ­¢)
  5. Document: æ–‡æ¡£ç±»å‹ (æ‹›æ ‡ã€æŠ•æ ‡)
  6. Chapter: ç« èŠ‚æ¦‚å¿µ (æŠ€æœ¯ã€å•†åŠ¡)
  7. Table: è¡¨æ ¼ç±»å‹ (æŠ¥ä»·ã€è®¾å¤‡)
  8. Value: å€¼åŸŸèŒƒå›´ (æ•°å€¼åŒºé—´)
  9. Process: æµç¨‹æ­¥éª¤ (å¼€æ ‡ã€è¯„æ ‡)

Edge Types:
  - hasAttribute: å®ä½“â†’å±æ€§
  - requires: çº¦æŸâ†’å®ä½“
  - belongsTo: ç« èŠ‚â†’æ–‡æ¡£
  - contains: æ–‡æ¡£â†’ç« èŠ‚
  - relatesTo: å®ä½“â†”å®ä½“
  - derivedFrom: è§„åˆ™â†’ç« èŠ‚
  - validates: çº¦æŸâ†’å±æ€§
```

### âš ï¸ å‘ç°çš„é—®é¢˜

#### é—®é¢˜1: å­¦ä¹ ä»»åŠ¡çŠ¶æ€æŒä¹…åŒ–ç¼ºå¤±
**ä½ç½®**: `backend/routers/learning.py:237-286`
```python
@router.post("/chapter/learn")
async def learn_chapter_logic(...):
    # âŒ å­¦ä¹ è¿‡ç¨‹æ— çŠ¶æ€æŒä¹…åŒ–ï¼ŒæœåŠ¡é‡å¯ä¸¢å¤±
    result = constraint_extractor.extract_constraints(...)
    return {"status": "completed", "rules": result}
```
**å½±å“**: é•¿æ—¶é—´å­¦ä¹ ä»»åŠ¡æ— æ³•æ¢å¤

**ä¿®å¤æ–¹æ¡ˆ**: åˆ›å»ºå­¦ä¹ ä»»åŠ¡è¡¨
```sql
CREATE TABLE learning_tasks (
    id uuid PRIMARY KEY,
    type text CHECK(type IN ('chapter','global')),
    target_id uuid,  -- chapter_id or tender_id
    status text DEFAULT 'pending',
    learned_rules jsonb DEFAULT '[]',
    created_at timestamptz DEFAULT now()
);
```

#### é—®é¢˜2: æœ¬ä½“å›¾è°±æœªåˆå§‹åŒ–
**ä½ç½®**: `backend/db/ontology.py:478`
```python
class OntologyManager:
    def __init__(self):
        # âš ï¸ æ£€æŸ¥æœ¬ä½“è¡¨æ˜¯å¦å­˜åœ¨æ•°æ®
        self.initialized = self._check_initialization()
```
**éªŒè¯å‘½ä»¤**:
```bash
psql -d bidding_db -c "SELECT COUNT(*) FROM ontology_nodes;"
# æœŸæœ›: > 50 (åŸºç¡€æœ¬ä½“èŠ‚ç‚¹)
```

#### é—®é¢˜3: LLMè°ƒç”¨æ— é‡è¯•æœºåˆ¶
**ä½ç½®**: `backend/agents/constraint_extractor.py` (OpenAIè°ƒç”¨)
```python
response = openai.ChatCompletion.create(...)
# âŒ æ— è¶…æ—¶ã€æ— é‡è¯•ã€æ— é™çº§
```
**ä¿®å¤æ–¹æ¡ˆ**: ä½¿ç”¨ `tenacity` åº“
```python
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(stop=stop_after_attempt(3), wait=wait_exponential(min=1, max=10))
def call_openai_with_retry(...):
    return openai.ChatCompletion.create(...)
```

---

## 4ï¸âƒ£ AIå¯¹è¯æµç¨‹

### å½“å‰çŠ¶æ€
âœ… **åŸºç¡€åŠŸèƒ½å®Œæ•´**

### æ•°æ®æµè½¬è·¯å¾„
```
å‰ç«¯ AIChatPanel.tsx
  â†“ llmAPI.chat({message, conversationId})
åç«¯ /api/llm/chat (llm.py:197)
  â†“ 1. åŠ è½½å¯¹è¯å†å² (conversationsè¡¨)
  â†“ 2. SmartRouter.route_requirement()
       â”œâ”€ 85%: çŸ¥è¯†åº“ç²¾ç¡®åŒ¹é…
       â”œâ”€ 10%: LLMé€‚é…ç°æœ‰å†…å®¹
       â””â”€ 5%: LLMå®Œå…¨ç”Ÿæˆ
  â†“ 3. OpenAI Stream Response
  â†“ 4. å­˜å‚¨å¯¹è¯è®°å½•
å‰ç«¯ Server-Sent Events (SSE)
  â†“ æµå¼æ˜¾ç¤º Markdown
```

### æ™ºèƒ½è·¯ç”±å†³ç­–æ ‘
```python
# backend/engines/smart_router.py:433
if similarity >= 0.95:
    return ContentSource.KB_EXACT_MATCH  # 85%æ¦‚ç‡
elif 0.75 <= similarity < 0.95:
    return ContentSource.LLM_ADAPT       # 10%æ¦‚ç‡
else:
    return ContentSource.LLM_GENERATE    # 5%æ¦‚ç‡
```

### âš ï¸ å‘ç°çš„é—®é¢˜

#### é—®é¢˜1: å¯¹è¯å†å²æ— åˆ†é¡µ
**ä½ç½®**: `backend/routers/llm.py:197`
```python
@router.post("/chat")
async def chat(...):
    # âŒ åŠ è½½å…¨éƒ¨å†å²æ¶ˆæ¯ï¼Œå¯èƒ½æ•°åƒæ¡
    history = load_conversation_history(conversation_id)
```
**å½±å“**: è¶…é•¿å¯¹è¯å¯¼è‡´Contextè¿‡å¤§ï¼ŒTokenæ¶ˆè€—æ¿€å¢

**ä¿®å¤æ–¹æ¡ˆ**: æ»‘åŠ¨çª—å£
```python
MAX_HISTORY_MESSAGES = 20
history = load_conversation_history(
    conversation_id, 
    limit=MAX_HISTORY_MESSAGES,
    order_by="created_at DESC"
)
```

#### é—®é¢˜2: æµå¼å“åº”é”™è¯¯å¤„ç†ç¼ºå¤±
**ä½ç½®**: `frontend/src/components/AIChatPanel.tsx:150`
```tsx
const eventSource = new EventSource(`/api/llm/chat/stream?...`)
eventSource.onerror = (err) => {
  // âŒ ä»…console.errorï¼Œç”¨æˆ·æ— æ„ŸçŸ¥
  console.error('SSE error:', err)
}
```
**ä¿®å¤æ–¹æ¡ˆ**:
```tsx
eventSource.onerror = (err) => {
  message.error('AIå“åº”ä¸­æ–­ï¼Œè¯·é‡è¯•')
  setIsLoading(false)
  eventSource.close()
}
```

---

## 5ï¸âƒ£ æ•°æ®æµè½¬ä¸å­˜å‚¨

### PostgreSQL è¡¨ç»“æ„å…¨æ™¯
```sql
-- æ–‡ä»¶ç®¡ç† (4å¼ è¡¨)
uploaded_files          -- æ–‡ä»¶å…ƒæ•°æ®
tender_chapters         -- ç« èŠ‚å†…å®¹
tender_tables           -- è¡¨æ ¼æ•°æ®
file_parse_tasks        -- è§£æä»»åŠ¡ (å»ºè®®æ–°å¢)

-- çŸ¥è¯†ç®¡ç† (3å¼ è¡¨)
learned_logic_rules     -- å­¦ä¹ è§„åˆ™
ontology_nodes          -- æœ¬ä½“èŠ‚ç‚¹ (9ç±»å‹)
ontology_edges          -- æœ¬ä½“å…³ç³» (7ç±»å‹)

-- å¯¹è¯ç®¡ç† (2å¼ è¡¨)
conversations           -- å¯¹è¯ä¼šè¯
conversation_messages   -- æ¶ˆæ¯è®°å½•

-- æç¤ºè¯ç®¡ç† (1å¼ è¡¨)
prompt_templates        -- æç¤ºè¯æ¨¡æ¿

-- ç”¨æˆ·ç®¡ç† (é¢„ç•™)
users                   -- ç”¨æˆ·ä¿¡æ¯ (TODO)
user_permissions        -- æƒé™è¡¨ (TODO)
```

### Redis ç¼“å­˜ç­–ç•¥
| Keyæ¨¡å¼ | TTL | ç”¨é€” | å®ç°ä½ç½® |
|---------|-----|------|----------|
| `file:sha256:{hash}` | 7å¤© | æ–‡ä»¶å»é‡ | files.py:88 |
| `logic:chapter:{id}` | 1å°æ—¶ | å­¦ä¹ è§„åˆ™ç¼“å­˜ | learning.py:286 |
| `router:decision:{req_id}` | 30åˆ†é’Ÿ | è·¯ç”±å†³ç­–ç¼“å­˜ | smart_router.py:150 |

### âš ï¸ å‘ç°çš„é—®é¢˜

#### é—®é¢˜1: æ•°æ®åº“è¿æ¥æ± æœªé…ç½®
**ä½ç½®**: `backend/database/connection.py`
```python
# âŒ æ¯æ¬¡è¯·æ±‚åˆ›å»ºæ–°è¿æ¥
conn = psycopg2.connect(...)
```
**å½±å“**: é«˜å¹¶å‘æ—¶è¿æ¥æ•°è€—å°½

**ä¿®å¤æ–¹æ¡ˆ**: ä½¿ç”¨ `psycopg2.pool`
```python
from psycopg2 import pool
connection_pool = pool.ThreadedConnectionPool(
    minconn=5,
    maxconn=20,
    **db_config
)
```

#### é—®é¢˜2: ç¼“å­˜å¤±æ•ˆæœºåˆ¶ç¼ºå¤±
**ä½ç½®**: `backend/core/cache.py`
```python
@cache_result(ttl=3600)
def get_logic_rules(chapter_id):
    # âš ï¸ è§„åˆ™æ›´æ–°åç¼“å­˜ä¸ä¼šå¤±æ•ˆ
    ...
```
**ä¿®å¤æ–¹æ¡ˆ**: ä¸»åŠ¨å¤±æ•ˆ
```python
def update_logic_rule(rule_id, new_data):
    # æ›´æ–°æ•°æ®åº“
    db.update(...)
    # åˆ é™¤ç¼“å­˜
    redis.delete(f"logic:chapter:{chapter_id}")
```

---

## 6ï¸âƒ£ é”™è¯¯å¤„ç†ä¸æ—¥å¿—

### å½“å‰æ—¥å¿—æ¶æ„
```python
# backend/core/logger.py
logger = Loguru(
    format="JSON",
    rotation="100MB",
    retention="30 days",
    level="INFO"
)
```

### æ—¥å¿—çº§åˆ«åˆ†å¸ƒ
| çº§åˆ« | ç”¨é€” | ç¤ºä¾‹ä½ç½® |
|------|------|----------|
| DEBUG | å¼€å‘è°ƒè¯• | smart_router.py:120 |
| INFO | ä¸šåŠ¡æµç¨‹ | files.py:144, learning.py:250 |
| WARNING | é™çº§å¤„ç† | parse_engine.py:88 |
| ERROR | å¼‚å¸¸æ•è· | llm.py:210 |
| CRITICAL | ç³»ç»Ÿå´©æºƒ | main.py:15 (æœªä½¿ç”¨) |

### âš ï¸ å‘ç°çš„é—®é¢˜

#### é—®é¢˜1: å‰ç«¯é”™è¯¯æœªä¸ŠæŠ¥
**ä½ç½®**: `frontend/src/services/api.ts`
```typescript
axios.interceptors.response.use(
  response => response,
  error => {
    // âŒ ä»…æœ¬åœ°message.errorï¼Œæœªå‘é€åˆ°åç«¯
    message.error(error.message)
    return Promise.reject(error)
  }
)
```
**ä¿®å¤æ–¹æ¡ˆ**: æ·»åŠ é”™è¯¯ä¸ŠæŠ¥
```typescript
error => {
  // ä¸ŠæŠ¥åˆ°åç«¯
  if (error.response?.status >= 500) {
    axios.post('/api/errors/report', {
      url: error.config.url,
      status: error.response.status,
      message: error.message,
      timestamp: new Date().toISOString()
    }).catch(() => {})  // é˜²æ­¢å¾ªç¯æŠ¥é”™
  }
  message.error(error.message)
  return Promise.reject(error)
}
```

#### é—®é¢˜2: ç¼ºå°‘è¯·æ±‚é“¾è·¯è¿½è¸ª
**å½“å‰çŠ¶æ€**: æ— æ³•å…³è”å‰ç«¯è¯·æ±‚ â†’ åç«¯æ—¥å¿— â†’ Celeryä»»åŠ¡

**ä¿®å¤æ–¹æ¡ˆ**: å¼•å…¥ Request ID
```python
# backend/middleware/trace.py
@app.middleware("http")
async def add_request_id(request: Request, call_next):
    request_id = str(uuid.uuid4())
    request.state.request_id = request_id
    response = await call_next(request)
    response.headers["X-Request-ID"] = request_id
    return response
```

---

## 7ï¸âƒ£ æ€§èƒ½ç“¶é¢ˆåˆ†æ

### ğŸ”¥ é«˜é£é™©ç“¶é¢ˆ

#### ç“¶é¢ˆ1: PDFå¤§æ–‡ä»¶è§£æé˜»å¡
**ä½ç½®**: `backend/engines/parse_engine.py`
```python
def parse_file(self, file_path):
    # âŒ åŒæ­¥é˜»å¡IOï¼Œå•ä¸ª50MB PDFè€—æ—¶30-60ç§’
    with pdfplumber.open(file_path) as pdf:
        for page in pdf.pages:  # é€é¡µå¤„ç†
            tables = page.extract_tables()
```
**å½±å“**: ç”¨æˆ·ä¸Šä¼ å¤§æ–‡ä»¶åé•¿æ—¶é—´æ— å“åº”

**ä¿®å¤æ–¹æ¡ˆ**: 
1. ç§»è‡³Celeryå¼‚æ­¥ä»»åŠ¡ (å·²å®ç° âœ…)
2. åˆ†é¡µå¹¶è¡Œå¤„ç†
```python
from concurrent.futures import ThreadPoolExecutor

def parse_pdf_parallel(file_path):
    with pdfplumber.open(file_path) as pdf:
        with ThreadPoolExecutor(max_workers=4) as executor:
            futures = [executor.submit(parse_page, page) for page in pdf.pages]
            results = [f.result() for f in futures]
```

#### ç“¶é¢ˆ2: çŸ¥è¯†å›¾è°±æŸ¥è¯¢æœªä¼˜åŒ–
**ä½ç½®**: `backend/db/ontology.py:150`
```python
def find_related_nodes(self, node_id, depth=3):
    # âŒ é€’å½’æŸ¥è¯¢ï¼Œæ·±åº¦3å¯èƒ½éå†æ•°åƒèŠ‚ç‚¹
    edges = db.query("SELECT * FROM ontology_edges WHERE source=$1", node_id)
    for edge in edges:
        related = self.find_related_nodes(edge.target, depth-1)
```
**å½±å“**: æœ¬ä½“éªŒè¯è€—æ—¶5-10ç§’

**ä¿®å¤æ–¹æ¡ˆ**: ä½¿ç”¨CTEé€’å½’æŸ¥è¯¢
```sql
WITH RECURSIVE related_nodes AS (
  SELECT target_id, 1 as depth FROM ontology_edges WHERE source_id = $1
  UNION ALL
  SELECT e.target_id, r.depth+1 
  FROM ontology_edges e
  JOIN related_nodes r ON e.source_id = r.target_id
  WHERE r.depth < $2
)
SELECT * FROM related_nodes;
```

#### ç“¶é¢ˆ3: LLMè°ƒç”¨æ— æ‰¹å¤„ç†
**ä½ç½®**: `backend/engines/smart_router.py:200`
```python
for requirement in requirements:
    # âŒ å¾ªç¯å•æ¬¡è°ƒç”¨OpenAIï¼Œ100æ¡éœ€æ±‚ = 100æ¬¡è¯·æ±‚
    decision = await self.route_requirement(requirement)
```
**å½±å“**: æ‰¹é‡å­¦ä¹ è€—æ—¶çº¿æ€§å¢é•¿

**ä¿®å¤æ–¹æ¡ˆ**: æ‰¹é‡è°ƒç”¨
```python
# ä½¿ç”¨OpenAI Batch API
responses = await openai.ChatCompletion.create(
    messages=[{"role": "user", "content": req} for req in requirements],
    max_tokens=100,
    n=len(requirements)
)
```

---

## 8ï¸âƒ£ æ¶æ„ä¼˜åŠ¿ä¸ä¸è¶³

### âœ… æ¶æ„ä¼˜åŠ¿
1. **ä¸‰å±‚ä»£ç†æ¸…æ™°**: Preprocessor â†’ ConstraintExtractor â†’ MultiAgentEvaluator
2. **æœ¬ä½“å›¾è°±èµ‹èƒ½**: 9èŠ‚ç‚¹+7å…³ç³»ç±»å‹ï¼Œæ”¯æŒè¯­ä¹‰æ¶ˆæ­§
3. **85/10/5æ™ºèƒ½è·¯ç”±**: å‡å°‘70% LLMè°ƒç”¨æˆæœ¬
4. **Pydanticå¼ºç±»å‹**: å…¨æµç¨‹ç±»å‹å®‰å…¨ï¼Œå‡å°‘è¿è¡Œæ—¶é”™è¯¯
5. **Celeryå¼‚æ­¥**: è§£è€¦è€—æ—¶ä»»åŠ¡ï¼Œæå‡å“åº”é€Ÿåº¦

### âš ï¸ æ¶æ„ä¸è¶³
1. **å¾®æœåŠ¡å•ä½“åŒ–**: æ‰€æœ‰åŠŸèƒ½è€¦åˆåœ¨main.pyï¼Œéš¾ä»¥æ¨ªå‘æ‰©å±•
2. **çŠ¶æ€ç®¡ç†æ··ä¹±**: ä»»åŠ¡çŠ¶æ€æ•£è½åœ¨å†…å­˜/DB/Redis
3. **ç¼ºå°‘æ¶ˆæ¯é˜Ÿåˆ—**: Celeryä»…ç”¨äºä»»åŠ¡ï¼Œæ— äº‹ä»¶é©±åŠ¨
4. **æµ‹è¯•è¦†ç›–ä¸è¶³**: æ— é›†æˆæµ‹è¯•ï¼Œä¾èµ–æ‰‹åŠ¨éªŒè¯
5. **ç›‘æ§ç¼ºå¤±**: æ— Prometheus/Grafanaç›‘æ§

---

## ğŸ¯ ä¼˜å…ˆä¿®å¤å»ºè®®

### ğŸ”´ é«˜ä¼˜å…ˆçº§ (æœ¬å‘¨å®Œæˆ)
1. **æ–‡ä»¶è§£æçŠ¶æ€è¡¨** â†’ ä¿®å¤é—®é¢˜2ï¸âƒ£-2
2. **LLMé‡è¯•æœºåˆ¶** â†’ ä¿®å¤é—®é¢˜3ï¸âƒ£-3
3. **å¯¹è¯å†å²åˆ†é¡µ** â†’ ä¿®å¤é—®é¢˜4ï¸âƒ£-1
4. **æ•°æ®åº“è¿æ¥æ± ** â†’ ä¿®å¤é—®é¢˜5ï¸âƒ£-1

### ğŸŸ¡ ä¸­ä¼˜å…ˆçº§ (ä¸‹å‘¨å®Œæˆ)
5. **è¯·æ±‚é“¾è·¯è¿½è¸ª** â†’ ä¿®å¤é—®é¢˜6ï¸âƒ£-2
6. **çŸ¥è¯†å›¾è°±æŸ¥è¯¢ä¼˜åŒ–** â†’ ä¿®å¤ç“¶é¢ˆ2
7. **å‰ç«¯é”™è¯¯ä¸ŠæŠ¥** â†’ ä¿®å¤é—®é¢˜6ï¸âƒ£-1

### ğŸŸ¢ ä½ä¼˜å…ˆçº§ (æœªæ¥è¿­ä»£)
8. **å¾®æœåŠ¡æ‹†åˆ†**: æ‹†åˆ†ä¸º Auth / File / Learning / Generation ç‹¬ç«‹æœåŠ¡
9. **WebSocketæ›¿ä»£SSE**: æ›´ç¨³å®šçš„åŒå‘é€šä¿¡
10. **GraphQLæ›¿ä»£REST**: å‡å°‘Over-fetching

---

## ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡åŸºå‡†

| æ“ä½œ | å½“å‰è€—æ—¶ | ä¼˜åŒ–ç›®æ ‡ | ä¼˜åŒ–æ–¹æ³• |
|------|----------|----------|----------|
| ç”¨æˆ·ç™»å½• | 150ms | 100ms | Redisç¼“å­˜ç”¨æˆ·ä¿¡æ¯ |
| æ–‡ä»¶ä¸Šä¼ (10MB) | 2s | 1.5s | åˆ†ç‰‡ä¸Šä¼  |
| PDFè§£æ(50é¡µ) | 45s | 20s | å¹¶è¡Œå¤„ç† |
| ç« èŠ‚å­¦ä¹  | 15s | 8s | æ‰¹é‡LLMè°ƒç”¨ |
| AIå¯¹è¯é¦–å“ | 2.5s | 1.5s | è·¯ç”±ç¼“å­˜ |
| æ ‡ä¹¦ç”Ÿæˆ(20ç« ) | 120s | 60s | ç« èŠ‚å¹¶è¡Œç”Ÿæˆ |

---

## ğŸ”’ å®‰å…¨æ€§æ£€æŸ¥

### âœ… å·²å®ç°
- JWTè®¤è¯
- CORSé…ç½®
- SQLå‚æ•°åŒ–æŸ¥è¯¢
- æ–‡ä»¶ç±»å‹ç™½åå•

### âŒ ç¼ºå¤±
- Rate Limiting (APIé¢‘ç‡é™åˆ¶)
- Input Sanitization (XSSé˜²æŠ¤)
- HTTPSå¼ºåˆ¶ (ç”Ÿäº§ç¯å¢ƒ)
- æ–‡ä»¶ç—…æ¯’æ‰«æ
- æ•æ„Ÿä¿¡æ¯åŠ å¯† (å¯†ç æ˜æ–‡å­˜å‚¨ âš ï¸)

---

## ğŸ“ æ€»ç»“

### ç³»ç»Ÿæˆç†Ÿåº¦è¯„åˆ†
| ç»´åº¦ | åˆ†æ•° | è¯´æ˜ |
|------|------|------|
| åŠŸèƒ½å®Œæ•´æ€§ | â­â­â­â­â˜† | æ ¸å¿ƒæµç¨‹å®Œæ•´ï¼Œç»†èŠ‚å¾…ä¼˜åŒ– |
| æ¶æ„è®¾è®¡ | â­â­â­â­â­ | ä¸‰å±‚ä»£ç†+çŸ¥è¯†å›¾è°±è®¾è®¡ä¼˜ç§€ |
| ä»£ç è´¨é‡ | â­â­â­â­â˜† | Pydanticå¼ºç±»å‹ï¼Œä½†æµ‹è¯•ä¸è¶³ |
| æ€§èƒ½è¡¨ç° | â­â­â­â˜†â˜† | å­˜åœ¨æ˜æ˜¾ç“¶é¢ˆ |
| å®‰å…¨æ€§ | â­â­â­â˜†â˜† | åŸºç¡€å®‰å…¨ï¼Œç¼ºå°‘é«˜çº§é˜²æŠ¤ |
| å¯ç»´æŠ¤æ€§ | â­â­â­â­â˜† | ä»£ç ç»“æ„æ¸…æ™°ï¼Œæ–‡æ¡£å®Œå–„ |

**ç»¼åˆè¯„åˆ†: â­â­â­â­â˜† (4/5)**

### ä¸‹ä¸€æ­¥è¡ŒåŠ¨
1. æ‰§è¡Œé«˜ä¼˜å…ˆçº§ä¿®å¤ (è§ğŸ”´æ¸…å•)
2. å»ºç«‹è‡ªåŠ¨åŒ–æµ‹è¯• (ç›®æ ‡è¦†ç›–ç‡60%+)
3. éƒ¨ç½²ç›‘æ§ç³»ç»Ÿ (Prometheus + Grafana)
4. ç¼–å†™APIæ–‡æ¡£ (Swaggerå¢å¼º)

---

**åˆ†æå®Œæˆ** âœ… | **å‘ç°é—®é¢˜**: 15é¡¹ | **ä¼˜åŒ–å»ºè®®**: 10é¡¹
