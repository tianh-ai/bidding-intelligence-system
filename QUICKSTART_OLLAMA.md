# ğŸš€ Ollama å‘é‡æœç´¢ - å¿«é€Ÿå¯åŠ¨æŒ‡å—

## ä¸€é”®å®‰è£…å’Œæµ‹è¯•ï¼ˆ5 åˆ†é’Ÿï¼‰

### æ­¥éª¤ 1: å®‰è£… Ollama

```bash
# macOS/Linux
curl -fsSL https://ollama.com/install.sh | sh

# æˆ–è®¿é—® https://ollama.com ä¸‹è½½å®‰è£…ç¨‹åºï¼ˆWindowsï¼‰
```

### æ­¥éª¤ 2: å¯åŠ¨ Ollama æœåŠ¡

```bash
# åœ¨æ–°ç»ˆç«¯çª—å£è¿è¡Œï¼ˆä¿æŒè¿è¡Œï¼‰
ollama serve
```

### æ­¥éª¤ 3: è¿è¡Œè‡ªåŠ¨åŒ–é…ç½®

```bash
# ç»™è„šæœ¬æ·»åŠ æ‰§è¡Œæƒé™
chmod +x setup_ollama.sh
chmod +x test_ollama.py

# è¿è¡Œé…ç½®è„šæœ¬ï¼ˆè‡ªåŠ¨ä¸‹è½½æ¨¡å‹å’Œé…ç½®ï¼‰
./setup_ollama.sh
```

**è¯¥è„šæœ¬ä¼šè‡ªåŠ¨**:
- âœ… æ£€æŸ¥ Ollama å®‰è£…
- âœ… éªŒè¯æœåŠ¡çŠ¶æ€
- âœ… ä¸‹è½½ nomic-embed-text æ¨¡å‹ï¼ˆ274MBï¼‰
- âœ… æµ‹è¯• embedding ç”Ÿæˆ
- âœ… éªŒè¯ Python å®¢æˆ·ç«¯
- âœ… æ£€æŸ¥ pgvector æ‰©å±•

### æ­¥éª¤ 4: è¿è¡Œæµ‹è¯•å¥—ä»¶

```bash
# è¿è¡Œå®Œæ•´æµ‹è¯•
python test_ollama.py
```

**æµ‹è¯•å†…å®¹**:
- âœ… Ollama è¿æ¥æµ‹è¯•
- âœ… Embedding ç”Ÿæˆæµ‹è¯•
- âœ… è¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—
- âœ… çŸ¥è¯†åº“é›†æˆéªŒè¯

### æ­¥éª¤ 5: å¯åŠ¨åç«¯æœåŠ¡

```bash
cd backend
python main.py
```

### æ­¥éª¤ 6: æµ‹è¯•è¯­ä¹‰æœç´¢ API

```bash
# è¯­ä¹‰æœç´¢
curl -X POST http://localhost:8000/api/knowledge/search/semantic \
  -H "Content-Type: application/json" \
  -d '{
    "query": "é¡¹ç›®ç»ç†éœ€è¦ä»€ä¹ˆèµ„è´¨ï¼Ÿ",
    "limit": 5,
    "min_similarity": 0.7
  }'

# é‡å»ºç´¢å¼•ï¼ˆå¦‚æœæœ‰ç°æœ‰æ•°æ®ï¼‰
curl -X POST http://localhost:8000/api/knowledge/reindex \
  -H "Content-Type: application/json" \
  -d '{"batch_size": 10}'
```

---

## å¸¸ç”¨å‘½ä»¤

### Ollama ç®¡ç†

```bash
# å¯åŠ¨æœåŠ¡
ollama serve

# åˆ—å‡ºå·²å®‰è£…æ¨¡å‹
ollama list

# ä¸‹è½½æ¨¡å‹
ollama pull nomic-embed-text

# æµ‹è¯•æ¨¡å‹
ollama run nomic-embed-text

# åˆ é™¤æ¨¡å‹
ollama rm nomic-embed-text
```

### API æµ‹è¯•

```bash
# å¥åº·æ£€æŸ¥
curl http://localhost:8000/api/knowledge/health

# å…³é”®è¯æœç´¢ï¼ˆæ—§æ–¹æ³•ï¼‰
curl -X POST http://localhost:8000/api/knowledge/search \
  -H "Content-Type: application/json" \
  -d '{"query": "æŠ•æ ‡", "limit": 5}'

# è¯­ä¹‰æœç´¢ï¼ˆæ–°æ–¹æ³•ï¼Œæ¨èï¼‰
curl -X POST http://localhost:8000/api/knowledge/search/semantic \
  -H "Content-Type: application/json" \
  -d '{"query": "æŠ•æ ‡è¦æ±‚", "limit": 5}'

# æ·»åŠ çŸ¥è¯†æ¡ç›®ï¼ˆè‡ªåŠ¨ç”Ÿæˆ embeddingï¼‰
curl -X POST http://localhost:8000/api/knowledge/entries \
  -H "Content-Type: application/json" \
  -d '{
    "file_id": "test-001",
    "category": "tender",
    "title": "æµ‹è¯•æ¡ç›®",
    "content": "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å†…å®¹",
    "keywords": ["æµ‹è¯•"],
    "importance_score": 80
  }'

# è·å–ç»Ÿè®¡ä¿¡æ¯
curl http://localhost:8000/api/knowledge/statistics

# æ‰¹é‡é‡å»ºç´¢å¼•
curl -X POST http://localhost:8000/api/knowledge/reindex \
  -d '{"batch_size": 10}'
```

---

## é…ç½®è¯´æ˜

### ç¯å¢ƒå˜é‡ï¼ˆ.envï¼‰

```bash
# Ollama é…ç½®ï¼ˆå·²è‡ªåŠ¨é…ç½®ï¼‰
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_EMBEDDING_MODEL=nomic-embed-text
USE_OLLAMA_FOR_EMBEDDINGS=True
```

### ä¿®æ”¹é…ç½®

```python
# backend/core/config.py

# æ›´æ¢ embedding æ¨¡å‹
OLLAMA_EMBEDDING_MODEL: str = "mxbai-embed-large"  # æ›´é«˜ç²¾åº¦

# è°ƒæ•´ç›¸ä¼¼åº¦é˜ˆå€¼
# åœ¨ API è°ƒç”¨ä¸­è®¾ç½® min_similarity
# 0.9+ : å‡ ä¹ç›¸åŒ
# 0.7-0.9 : é«˜åº¦ç›¸å…³ï¼ˆæ¨èï¼‰
# 0.5-0.7 : ç›¸å…³
# <0.5 : å¼±ç›¸å…³
```

---

## æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: è¿æ¥å¤±è´¥

**é”™è¯¯**: `Failed to connect to http://localhost:11434`

**è§£å†³**:
```bash
# ç¡®ä¿ Ollama æ­£åœ¨è¿è¡Œ
ollama serve

# åœ¨å¦ä¸€ä¸ªç»ˆç«¯æµ‹è¯•
curl http://localhost:11434/api/tags
```

### é—®é¢˜ 2: æ¨¡å‹æœªæ‰¾åˆ°

**é”™è¯¯**: `model 'nomic-embed-text' not found`

**è§£å†³**:
```bash
ollama pull nomic-embed-text
ollama list  # éªŒè¯
```

### é—®é¢˜ 3: å‘é‡ç±»å‹é”™è¯¯

**é”™è¯¯**: `type "vector" does not exist`

**è§£å†³**:
```bash
psql -h localhost -U postgres -d bidding_db -c "CREATE EXTENSION vector;"
```

### é—®é¢˜ 4: æœç´¢æ— ç»“æœ

**æ£€æŸ¥**:
```sql
-- æŸ¥çœ‹ç´¢å¼•çŠ¶æ€
SELECT 
    COUNT(*) FILTER (WHERE embedding IS NOT NULL) as indexed,
    COUNT(*) FILTER (WHERE embedding IS NULL) as not_indexed
FROM knowledge_base;

-- å¦‚æœ indexed = 0ï¼Œéœ€è¦é‡å»ºç´¢å¼•
```

**é‡å»ºç´¢å¼•**:
```bash
curl -X POST http://localhost:8000/api/knowledge/reindex
```

---

## æ€§èƒ½ä¼˜åŒ–

### 1. GPU åŠ é€Ÿï¼ˆè‡ªåŠ¨ï¼‰

Ollama è‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨ GPU:
- macOS: Metal
- Linux: CUDA / ROCm  
- Windows: CUDA

### 2. æ‰¹é‡å¤„ç†

```bash
# å°å†…å­˜è®¾å¤‡
curl ... -d '{"batch_size": 5}'

# é«˜æ€§èƒ½è®¾å¤‡
curl ... -d '{"batch_size": 50}'
```

### 3. è°ƒæ•´é˜ˆå€¼

```python
# é«˜ç²¾åº¦ï¼ˆç»“æœå°‘ä½†å‡†ç¡®ï¼‰
min_similarity = 0.85

# å¹³è¡¡ï¼ˆæ¨èï¼‰
min_similarity = 0.70

# é«˜å¬å›ï¼ˆç»“æœå¤šä½†å¯èƒ½ä¸å¤ªç›¸å…³ï¼‰
min_similarity = 0.50
```

---

## ä¸‹ä¸€æ­¥

1. âœ… **åŸºç¡€åŠŸèƒ½å·²å®Œæˆ**
   - Ollama é›†æˆ
   - è¯­ä¹‰æœç´¢
   - è‡ªåŠ¨ embedding
   - æ‰¹é‡ç´¢å¼•

2. ğŸ”„ **å¯é€‰å¢å¼º**ï¼ˆè§ `KNOWLEDGE_BASE_ENHANCEMENT_PROPOSAL.md`ï¼‰
   - AI æ™ºèƒ½åˆ†ç±»
   - çŸ¥è¯†å›¾è°±é›†æˆ
   - å‘é‡èšç±»åˆ†æ

3. ğŸ¨ **å‰ç«¯å¼€å‘**
   - è¯­ä¹‰æœç´¢ UI
   - ç´¢å¼•ç®¡ç†é¢æ¿
   - ç›¸ä¼¼åº¦å¯è§†åŒ–

---

## æ–‡æ¡£ç´¢å¼•

- **å®Œæ•´å®æ–½æŠ¥å‘Š**: `OLLAMA_IMPLEMENTATION_COMPLETE.md`
- **ä½¿ç”¨æŒ‡å—**: `OLLAMA_VECTOR_SEARCH.md`
- **å¢å¼ºæ–¹æ¡ˆ**: `KNOWLEDGE_BASE_ENHANCEMENT_PROPOSAL.md`
- **MCP æ–‡æ¡£**: `KNOWLEDGE_BASE_MCP_COMPLETE.md`

---

## æŠ€æœ¯æ”¯æŒ

- **æµ‹è¯•è„šæœ¬**: `python test_ollama.py`
- **é…ç½®è„šæœ¬**: `./setup_ollama.sh`
- **æ—¥å¿—æ–‡ä»¶**: `backend/logs/app.log`
- **Ollama æ–‡æ¡£**: https://ollama.com/docs

---

**å‡†å¤‡å°±ç»ªï¼å¼€å§‹ä½¿ç”¨ Ollama å‘é‡æœç´¢å§ï¼** ğŸ‰
