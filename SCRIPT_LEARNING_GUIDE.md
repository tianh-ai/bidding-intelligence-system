# ğŸ“š ä¸¤ä¸ªå…³é”®è„šæœ¬æ·±åº¦å­¦ä¹ æŒ‡å—

## è„šæœ¬1: verify_new_parser.py - è§£æå™¨éªŒè¯è„šæœ¬

### ğŸ“– è„šæœ¬ç›®çš„
éªŒè¯PDFè§£æå¼•æ“æå–çš„ç« èŠ‚ç»“æ„æ˜¯å¦ä¸PDFåŸå§‹ç›®å½•ä¸€è‡´ã€‚è¿™æ˜¯**éªŒæ”¶æµ‹è¯•**è„šæœ¬ï¼Œç”¨æ¥æµ‹é‡è§£æå‡†ç¡®ç‡ã€‚

### ğŸ—ï¸ æ¶æ„è®¾è®¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PDFæ–‡ä»¶   â”‚ (bidding_example.pdf)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ParseEngine           â”‚ è°ƒç”¨: pdfplumber + æ–‡æœ¬è§£æ
â”‚   - æ‰“å¼€PDFæ–‡ä»¶         â”‚
â”‚   - æå–æ‰€æœ‰æ–‡æœ¬        â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ è¿”å›: raw_text
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EnhancedChapterExtractor        â”‚ è°ƒç”¨: æ­£åˆ™è¡¨è¾¾å¼ + ç« èŠ‚æ£€æµ‹ç®—æ³•
â”‚ - è¯†åˆ«ç« èŠ‚æ ‡è®° (ç¬¬ã€ç« ã€èŠ‚ç­‰)    â”‚
â”‚ - æ„å»ºç« èŠ‚æ ‘ç»“æ„                  â”‚
â”‚ - è¿”å› ChapterNode åˆ—è¡¨          â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ è¿”å›: extracted_chapters
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å¯¹æ¯”éªŒè¯ (æ ¸å¿ƒé€»è¾‘)      â”‚
â”‚  toc_items vs chapters   â”‚
â”‚  - é€é¡¹åŒ¹é…              â”‚
â”‚  - è®¡ç®—æˆåŠŸç‡            â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ è¾“å‡ºç»“æœ               â”‚
â”‚ - åŒ¹é…æˆåŠŸæ•° N/16      â”‚
â”‚ - æˆåŠŸç‡ç™¾åˆ†æ¯”         â”‚
â”‚ - ç»“æ„ç»Ÿè®¡ (ç« /èŠ‚æ•°)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ’» å…³é”®ä»£ç è¯¦è§£

#### 1ï¸âƒ£ å‚è€ƒTOCå®šä¹‰ (lines 1-30)
```python
toc_items = [
    "ç¬¬ä¸€éƒ¨åˆ†  æŠ•æ ‡é‚€è¯·",
    "ä¸€ã€æŠ•æ ‡è¯´æ˜",
    "äºŒã€æŠ•æ ‡äººèµ„æ ¼è¦æ±‚",
    "ä¸‰ã€æŠ•æ ‡äººåº”å…·å¤‡çš„æ¡ä»¶",
    "å››ã€æ‹›æ ‡äººè”ç³»æ–¹å¼",
    # ... å…±16é¡¹
]
```
**ä½œç”¨**: å®šä¹‰PDFåŸå§‹ç›®å½•ï¼Œä½œä¸ºéªŒè¯çš„åŸºå‡†çº¿

#### 2ï¸âƒ£ ä¸»éªŒè¯æµç¨‹ (lines 32-65)
```python
# Step 1: åˆå§‹åŒ–è§£æå¼•æ“
parser = ParseEngine()
raw_text = parser.parse(pdf_path)

# Step 2: æå–ç« èŠ‚ç»“æ„
extractor = EnhancedChapterExtractor()
chapters = extractor.extract_chapters(raw_text)

# Step 3: æ„å»ºæŸ¥æ‰¾å­—å…¸ (æ€§èƒ½ä¼˜åŒ–)
ch_dict = {ch.title: ch for ch in chapters}

# Step 4: é€é¡¹éªŒè¯ (æ ¸å¿ƒåŒ¹é…é€»è¾‘)
matched = 0
for item in toc_items:
    if match_chapter(item, ch_dict):
        matched += 1
        print(f"âœ“ {item}")
    else:
        print(f"âœ— {item}")

# Step 5: è®¡ç®—æˆåŠŸç‡
success_rate = (matched / len(toc_items)) * 100
print(f"æˆåŠŸç‡: {success_rate:.1f}% ({matched}/{len(toc_items)})")
```

#### 3ï¸âƒ£ ç« èŠ‚åŒ¹é…é€»è¾‘ (lines 40-52)
```python
def match_chapter(toc_item, ch_dict):
    """
    æ ¸å¿ƒåŒ¹é…ç®—æ³•:
    1. æ£€æŸ¥ç« èŠ‚å·æ˜¯å¦å­˜åœ¨ (e.g., "ä¸€" in ch_dict)
    2. æ£€æŸ¥æ ‡é¢˜ç›¸ä¼¼åº¦ (ä½¿ç”¨ difflib.SequenceMatcher)
    3. ç›¸ä¼¼åº¦é˜ˆå€¼ > 0.8 åˆ™è§†ä¸ºåŒ¹é…
    """
    # æå–ç« èŠ‚å· (e.g., "ä¸€" from "ä¸€ã€æŠ•æ ‡è¯´æ˜")
    chapter_num = extract_chapter_number(toc_item)
    
    if chapter_num not in ch_dict:
        return False
    
    # è®¡ç®—å­—ç¬¦ä¸²ç›¸ä¼¼åº¦
    ch_title = ch_dict[chapter_num].title
    ratio = difflib.SequenceMatcher(None, toc_item, ch_title).ratio()
    
    return ratio > 0.8  # ç›¸ä¼¼åº¦é˜ˆå€¼
```

### ğŸ”§ ä½¿ç”¨æ–¹æ³•

```bash
# æ–¹æ³•1: é»˜è®¤éªŒè¯ (ä½¿ç”¨ç¤ºä¾‹PDF)
cd backend
python verify_new_parser.py

# æ–¹æ³•2: éªŒè¯ç‰¹å®šPDF (ä¿®æ”¹è„šæœ¬ä¸­çš„ pdf_path)
# ç¼–è¾‘ verify_new_parser.py ç¬¬75è¡Œ
pdf_path = "/Volumes/ssd/bidding-data/uploads/your_pdf.pdf"
python verify_new_parser.py

# æ–¹æ³•3: ä½œä¸ºæ¨¡å—å¯¼å…¥ (åœ¨å…¶ä»–è„šæœ¬ä¸­ä½¿ç”¨)
from verify_new_parser import verify_parser_accuracy
success_rate = verify_parser_accuracy("path/to/pdf.pdf")
```

### ğŸ“Š è¾“å‡ºç¤ºä¾‹

```
éªŒè¯PDFè§£æå™¨å‡†ç¡®ç‡
PDFæ–‡ä»¶: bidding_example.pdf

TOC å¯¹æ¯”ç»“æœ:
âœ“ ç¬¬ä¸€éƒ¨åˆ†  æŠ•æ ‡é‚€è¯·
âœ“ ä¸€ã€æŠ•æ ‡è¯´æ˜
âœ— äºŒã€æŠ•æ ‡äººèµ„æ ¼è¦æ±‚  [ç¼ºå¤±]
âœ“ ä¸‰ã€æŠ•æ ‡äººåº”å…·å¤‡çš„æ¡ä»¶
...

è§£æç»Ÿè®¡:
- æ€»ç›®å½•é¡¹: 16
- æˆåŠŸæå–: 14
- æˆåŠŸç‡: 87.5%

ç« èŠ‚ç»“æ„:
- æ€»ç« èŠ‚æ•°: 15
- æ€»èŠ‚æ•°: 42
```

### ğŸ¯ å…³é”®å­¦ä¹ ç‚¹

| æ¦‚å¿µ | è¯´æ˜ |
|------|------|
| **ParseEngine** | è´Ÿè´£æ‰“å¼€PDFå¹¶æå–åŸå§‹æ–‡æœ¬ï¼Œæ”¯æŒè¡¨æ ¼è¯†åˆ« |
| **EnhancedChapterExtractor** | ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ£€æµ‹ç« èŠ‚æ¨¡å¼ (å¦‚"ç¬¬ä¸€"ã€"ä¸€ã€"ç­‰) |
| **SequenceMatcher** | Pythonæ ‡å‡†åº“ç®—æ³•ï¼Œè®¡ç®—å­—ç¬¦ä¸²ç›¸ä¼¼åº¦ (0-1ä¹‹é—´) |
| **threshold 0.8** | ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œé«˜äºæ­¤å€¼è§†ä¸ºæˆåŠŸåŒ¹é… |
| **æˆåŠŸç‡** | (matched_count / total_toc_items) * 100 |

---

## è„šæœ¬2: init_database.py - æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬

### ğŸ“– è„šæœ¬ç›®çš„
åˆå§‹åŒ–æŠ•æ ‡æ™ºèƒ½ç³»ç»Ÿçš„PostgreSQLæ•°æ®åº“ï¼Œåˆ›å»ºæ‰€æœ‰å¿…éœ€çš„è¡¨ã€ç´¢å¼•å’Œçº¦æŸã€‚

### ğŸ—ï¸ æ•°æ®åº“æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     PostgreSQL æ•°æ®åº“è®¾è®¡          â”‚
â”‚     bidding_db (on SSD)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚            â”‚            â”‚
    â–¼            â–¼            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚knowledge_   â”‚â”‚uploaded_     â”‚â”‚parsing_            â”‚
â”‚base         â”‚â”‚files         â”‚â”‚results             â”‚
â”‚(çŸ¥è¯†åº“)     â”‚â”‚(ä¸Šä¼ è¿½è¸ª)    â”‚â”‚(è§£æç»“æœ)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                 â”‚                    â”‚
    â”œâ”€id (UUID)      â”œâ”€id (UUID)         â”œâ”€id (UUID)
    â”œâ”€title          â”œâ”€file_name         â”œâ”€file_id (FK)
    â”œâ”€content        â”œâ”€file_path         â”œâ”€chapter_count
    â”œâ”€category       â”œâ”€file_size         â”œâ”€parsing_time
    â”œâ”€file_id (FK)   â”œâ”€upload_status     â”œâ”€parsing_status
    â”œâ”€file_name      â”œâ”€parse_status      â”œâ”€error_message
    â”œâ”€source         â”œâ”€storage_location  â”œâ”€result_json
    â”œâ”€embedding      â””â”€created_at        â””â”€created_at
    â””â”€timestamps
```

### ğŸ’» æ ¸å¿ƒè¡¨ç»“æ„è¯¦è§£

#### è¡¨1ï¸âƒ£: knowledge_base (çŸ¥è¯†åº“è¡¨)
```sql
CREATE TABLE knowledge_base (
    -- ä¸»é”®
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    
    -- å†…å®¹å­—æ®µ
    title VARCHAR(255) NOT NULL,           -- æ¡ç›®æ ‡é¢˜
    content TEXT NOT NULL,                 -- å®Œæ•´å†…å®¹
    category VARCHAR(100),                 -- åˆ†ç±» (e.g., "èµ„æ ¼", "æ¡ä»¶", "æ–‡ä»¶")
    
    -- æº¯æºå­—æ®µ
    file_id UUID REFERENCES uploaded_files(id),  -- æ¥æºæ–‡ä»¶
    file_name VARCHAR(255),                      -- æ¥æºæ–‡ä»¶å
    source VARCHAR(100),                        -- æ¥æº (e.g., "æ‹›æ ‡æ–‡ä»¶", "API")
    
    -- AIå¢å¼ºå­—æ®µ
    embedding vector(1536),                -- OpenAI åµŒå…¥ (ç”¨äºè¯­ä¹‰æœç´¢)
    
    -- æ—¶é—´æˆ³
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- ç´¢å¼• (åŠ å¿«æŸ¥è¯¢)
CREATE INDEX idx_knowledge_base_file_id ON knowledge_base(file_id);
CREATE INDEX idx_knowledge_base_category ON knowledge_base(category);
```

**ç”¨é€”**: å­˜å‚¨ä»æ‹›æ ‡æ–‡ä»¶ä¸­æå–çš„æ‰€æœ‰çŸ¥è¯†æ¡ç›® (èµ„æ ¼è¦æ±‚ã€æŠ•æ ‡æ¡ä»¶ã€æŠ€æœ¯è§„æ ¼ç­‰)

**ç¤ºä¾‹æ•°æ®**:
```json
{
  "id": "f47ac10b-58cc-4372-a567-0e02b2c3d479",
  "title": "é¡¹ç›®ç»ç†èµ„è´¨è¦æ±‚",
  "content": "é¡¹ç›®ç»ç†åº”å…·å¤‡: 1) 5å¹´ä»¥ä¸Šç›¸å…³å·¥ä½œç»éªŒ 2) PMPè®¤è¯æˆ–åŒç­‰èµ„è´¨ 3)...",
  "category": "èµ„æ ¼æ¡ä»¶",
  "file_id": "a1b2c3d4-e5f6-...",
  "file_name": "æ‹›æ ‡æ–‡ä»¶.pdf",
  "source": "æ‹›æ ‡æ–‡ä»¶",
  "embedding": [0.001, 0.042, -0.023, ... (1536ä¸ªç»´åº¦)]
}
```

#### è¡¨2ï¸âƒ£: uploaded_files (ä¸Šä¼ æ–‡ä»¶è¿½è¸ªè¡¨)
```sql
CREATE TABLE uploaded_files (
    -- ä¸»é”®
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    
    -- æ–‡ä»¶ä¿¡æ¯
    file_name VARCHAR(255) NOT NULL,           -- åŸå§‹æ–‡ä»¶å
    file_path TEXT NOT NULL,                   -- å®Œæ•´æ–‡ä»¶è·¯å¾„
    file_size BIGINT,                          -- æ–‡ä»¶å¤§å° (å­—èŠ‚)
    
    -- å¤„ç†çŠ¶æ€ (å·¥ä½œæµ)
    upload_status TEXT DEFAULT 'pending',      -- pending|completed|failed
    parse_status TEXT DEFAULT 'pending',       -- pending|processing|completed|failed
    
    -- å­˜å‚¨ä½ç½® (å…³é”®: æŒ‡å‘SSD)
    storage_location TEXT DEFAULT '/Volumes/ssd/bidding-data/uploads',
    
    -- æ—¶é—´æˆ³
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- ç´¢å¼• (åŠ å¿«çŠ¶æ€æŸ¥è¯¢)
CREATE INDEX idx_uploaded_files_name 
    ON uploaded_files(file_name);
CREATE INDEX idx_uploaded_files_status 
    ON uploaded_files(upload_status, parse_status);
```

**ç”¨é€”**: è·Ÿè¸ªç”¨æˆ·ä¸Šä¼ çš„æ–‡ä»¶ç”Ÿå‘½å‘¨æœŸ

**çŠ¶æ€æµè½¬**:
```
ä¸Šä¼ æ–‡ä»¶
   â”‚
   â”œâ”€ upload_status: pending â†’ completed
   â””â”€ parse_status: pending â†’ processing â†’ completed/failed
```

**ç¤ºä¾‹æ•°æ®**:
```json
{
  "id": "b2c3d4e5-f6a7-...",
  "file_name": "æ‹›æ ‡æ–‡ä»¶_2024.pdf",
  "file_path": "/Volumes/ssd/bidding-data/uploads/æ‹›æ ‡æ–‡ä»¶_2024.pdf",
  "file_size": 2048576,  // 2MB
  "upload_status": "completed",
  "parse_status": "completed",
  "storage_location": "/Volumes/ssd/bidding-data/uploads",
  "created_at": "2024-01-15T10:30:00Z"
}
```

#### è¡¨3ï¸âƒ£: parsing_results (è§£æç»“æœè¡¨)
```sql
CREATE TABLE parsing_results (
    -- ä¸»é”®
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    
    -- å¤–é”®å…³ç³»
    file_id UUID REFERENCES uploaded_files(id) ON DELETE CASCADE,
    
    -- è§£æç»“æœ
    chapter_count INTEGER,                     -- æå–çš„ç« èŠ‚æ•°
    parsing_time FLOAT,                        -- è§£æè€—æ—¶ (ç§’)
    parsing_status TEXT DEFAULT 'pending',     -- pending|completed|failed
    error_message TEXT,                        -- å¤±è´¥æ—¶çš„é”™è¯¯ä¿¡æ¯
    
    -- ç»“æœæ•°æ® (JSONæ ¼å¼çµæ´»å­˜å‚¨)
    result_json JSONB,                         -- å®Œæ•´è§£æç»“æœ
    
    -- å­˜å‚¨ä½ç½® (æŒ‡å‘SSDè§£æç»“æœç›®å½•)
    storage_location TEXT DEFAULT '/Volumes/ssd/bidding-data/parsed',
    
    -- æ—¶é—´æˆ³
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- ç´¢å¼• (æŒ‰æ–‡ä»¶æŸ¥è¯¢)
CREATE INDEX idx_parsing_results_file_id 
    ON parsing_results(file_id);
```

**ç”¨é€”**: å­˜å‚¨PDFè§£æçš„ç»“æœå’Œå…ƒæ•°æ®

**ç¤ºä¾‹æ•°æ®**:
```json
{
  "id": "c3d4e5f6-a7b8-...",
  "file_id": "b2c3d4e5-f6a7-...",
  "chapter_count": 24,
  "parsing_time": 3.45,  // ç§’
  "parsing_status": "completed",
  "error_message": null,
  "result_json": {
    "chapters": [
      {"num": "ç¬¬ä¸€éƒ¨åˆ†", "title": "æŠ•æ ‡é‚€è¯·", "content": "..."},
      {"num": "ä¸€", "title": "æŠ•æ ‡è¯´æ˜", "content": "..."}
    ],
    "total_pages": 156,
    "extraction_accuracy": 0.92
  },
  "storage_location": "/Volumes/ssd/bidding-data/parsed",
  "created_at": "2024-01-15T10:31:00Z"
}
```

### ğŸ’» ä»£ç æ‰§è¡Œæµç¨‹

#### Step 1: åˆå§‹åŒ–æ•°æ®åº“è¿æ¥ (lines 1-25)
```python
import asyncio
import asyncpg
from loguru import logger

# é…ç½®æ•°æ®åº“è¿æ¥å‚æ•°
DB_HOST = "localhost"
DB_PORT = 5432
DB_NAME = "bidding_db"
DB_USER = "postgres"
DB_PASSWORD = "postgres"

# è¿æ¥å­—ç¬¦ä¸²
DB_URL = f"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}"

async def get_db_connection():
    """è·å–å¼‚æ­¥æ•°æ®åº“è¿æ¥"""
    return await asyncpg.connect(
        host=DB_HOST,
        port=DB_PORT,
        database=DB_NAME,
        user=DB_USER,
        password=DB_PASSWORD
    )
```

#### Step 2: ä¸»åˆå§‹åŒ–å‡½æ•° (lines 26-50)
```python
async def init_database():
    """ä¸»åˆå§‹åŒ–å‡½æ•° - åè°ƒæ‰€æœ‰è¡¨çš„åˆ›å»º"""
    try:
        db = await get_db_connection()
        logger.info("âœ“ æ•°æ®åº“è¿æ¥æˆåŠŸ")
        
        # æŒ‰ä¾èµ–é¡ºåºåˆ›å»ºè¡¨
        # 1. å…ˆåˆ›å»ºç‹¬ç«‹è¡¨ (æ²¡æœ‰å¤–é”®ä¾èµ–)
        await create_uploaded_files_table(db)
        
        # 2. å†åˆ›å»ºæœ‰å¤–é”®çš„è¡¨ (ä¾èµ– uploaded_files)
        await create_knowledge_base_table(db)
        await create_parsing_results_table(db)
        
        await db.close()
        logger.info("âœ“ æ‰€æœ‰è¡¨åˆ›å»ºå®Œæˆ")
        return True
        
    except Exception as e:
        logger.error(f"âœ— æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
        return False
```

#### Step 3: åˆ›å»ºuploaded_filesè¡¨ (lines 51-75)
```python
async def create_uploaded_files_table(db):
    """åˆ›å»ºä¸Šä¼ æ–‡ä»¶è¿½è¸ªè¡¨"""
    try:
        query = """
        CREATE TABLE IF NOT EXISTS uploaded_files (
            id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
            file_name VARCHAR(255) NOT NULL,
            file_path TEXT NOT NULL,
            file_size BIGINT,
            upload_status TEXT DEFAULT 'pending',
            parse_status TEXT DEFAULT 'pending',
            storage_location TEXT DEFAULT '/Volumes/ssd/bidding-data/uploads',
            created_at TIMESTAMPTZ DEFAULT NOW(),
            updated_at TIMESTAMPTZ DEFAULT NOW()
        )
        """
        await db.execute(query)
        logger.info("âœ“ uploaded_files è¡¨å·²åˆ›å»º")
        
        # åˆ›å»ºç´¢å¼• (åŠ é€ŸæŸ¥è¯¢)
        await db.execute("""
            CREATE INDEX IF NOT EXISTS idx_uploaded_files_name 
            ON uploaded_files(file_name)
        """)
        
    except Exception as e:
        logger.warning(f"è¡¨å¯èƒ½å·²å­˜åœ¨: {e}")
```

#### Step 4: åˆ›å»ºknowledge_baseè¡¨ (ç±»ä¼¼ç»“æ„)

#### Step 5: åˆ›å»ºparsing_resultsè¡¨ (ç±»ä¼¼ç»“æ„)

#### Step 6: éªŒè¯å­˜å‚¨è·¯å¾„ (lines 140-155)
```python
async def verify_storage_paths():
    """ç¡®ä¿æ‰€æœ‰SSDå­˜å‚¨ç›®å½•å­˜åœ¨"""
    paths = [
        "/Volumes/ssd/bidding-data/uploads",
        "/Volumes/ssd/bidding-data/parsed",
        "/Volumes/ssd/bidding-data/archive",
        "/Volumes/ssd/bidding-data/logs"
    ]
    
    for path in paths:
        if os.path.exists(path):
            logger.info(f"âœ“ {path}")
        else:
            logger.warning(f"âš ï¸ {path} ä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»º...")
            os.makedirs(path, exist_ok=True)
```

#### Step 7: ä¸»å‡½æ•°å…¥å£ (lines 156-195)
```python
async def main():
    """è„šæœ¬ä¸»å…¥å£"""
    print("=" * 60)
    print("ğŸš€ æ•°æ®åº“åˆå§‹åŒ–")
    print("=" * 60)
    
    # 1. éªŒè¯SSDå­˜å‚¨è·¯å¾„
    await verify_storage_paths()
    
    # 2. åˆå§‹åŒ–æ•°æ®åº“
    success = await init_database()
    
    # 3. è¾“å‡ºç»“æœ
    if success:
        print("âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆï¼")
        print("\nå­˜å‚¨é…ç½®:")
        print("  - æ–‡ä»¶ä¸Šä¼ : /Volumes/ssd/bidding-data/uploads")
        print("  - è§£æç»“æœ: /Volumes/ssd/bidding-data/parsed")
        print("  - å½’æ¡£æ–‡ä»¶: /Volumes/ssd/bidding-data/archive")
        print("  - æ—¥å¿—æ–‡ä»¶: /Volumes/ssd/bidding-data/logs")
    else:
        print("âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥")
        return 1
    
    return 0

if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
```

### ğŸ”§ ä½¿ç”¨æ–¹æ³•

```bash
# 1. ç¡®ä¿PostgreSQLè¿è¡Œä¸­
psql -U postgres  # éªŒè¯è¿æ¥

# 2. åˆ›å»ºæ•°æ®åº“ (å¦‚æœä¸å­˜åœ¨)
createdb bidding_db

# 3. è¿è¡Œåˆå§‹åŒ–è„šæœ¬
cd backend
python3 init_database.py

# è¾“å‡ºåº”è¯¥ç±»ä¼¼äº:
# ============================================================
# ğŸš€ æ•°æ®åº“åˆå§‹åŒ–
# ============================================================
# 
# éªŒè¯å­˜å‚¨è·¯å¾„:
#   âœ“ /Volumes/ssd/bidding-data/uploads
#   âœ“ /Volumes/ssd/bidding-data/parsed
#   âœ“ /Volumes/ssd/bidding-data/archive
#   âœ“ /Volumes/ssd/bidding-data/logs
# 
# âœ“ æ•°æ®åº“è¿æ¥æˆåŠŸ
# âœ“ uploaded_files è¡¨å·²åˆ›å»º
# âœ“ knowledge_base è¡¨å·²åˆ›å»º
# âœ“ parsing_results è¡¨å·²åˆ›å»º
# 
# ============================================================
# âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆï¼
# ...
```

### ğŸ“Š æ‰§è¡Œåçš„éªŒè¯

```bash
# è¿›å…¥PostgreSQL
psql -U postgres -d bidding_db

# æŸ¥çœ‹åˆ›å»ºçš„è¡¨
\dt

# é¢„æœŸè¾“å‡º:
#           List of relations
#  Schema |        Name         | Type  | Owner
# â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€
#  public | knowledge_base      | table | postgres
#  public | parsing_results     | table | postgres
#  public | uploaded_files      | table | postgres

# æŸ¥çœ‹è¡¨ç»“æ„
\d knowledge_base
\d uploaded_files
\d parsing_results

# æŸ¥çœ‹ç´¢å¼•
\di

# æ’å…¥æµ‹è¯•æ•°æ®
INSERT INTO uploaded_files (file_name, file_path, file_size) 
VALUES ('test.pdf', '/path/to/test.pdf', 1024);

# æŸ¥è¯¢æ•°æ®
SELECT * FROM uploaded_files;
```

### ğŸ¯ å…³é”®å­¦ä¹ ç‚¹

| æ¦‚å¿µ | è¯´æ˜ |
|------|------|
| **UUIDä¸»é”®** | åˆ†å¸ƒå¼ç³»ç»Ÿå‹å¥½çš„å”¯ä¸€æ ‡è¯†ç¬¦ (ä¼˜äºè‡ªå¢ID) |
| **Foreign Key** | `file_id REFERENCES uploaded_files(id)` ç»´æŠ¤å…³ç³»å®Œæ•´æ€§ |
| **ON DELETE CASCADE** | åˆ é™¤çˆ¶è®°å½•æ—¶è‡ªåŠ¨åˆ é™¤ç›¸å…³å­è®°å½• |
| **JSONB** | PostgreSQLçµæ´»çš„JSONæ•°æ®ç±»å‹ |
| **Vector(1536)** | OpenAIåµŒå…¥å‘é‡ (ç”¨äºè¯­ä¹‰ç›¸ä¼¼åº¦æœç´¢) |
| **å¼‚æ­¥æ‰§è¡Œ** | `asyncio + asyncpg` æé«˜å¹¶å‘æ€§èƒ½ |
| **ç´¢å¼•ç­–ç•¥** | åœ¨ç»å¸¸æŸ¥è¯¢çš„åˆ—ä¸Šåˆ›å»ºç´¢å¼• (file_id, statusç­‰) |
| **IF NOT EXISTS** | å¹‚ç­‰æ“ä½œ (å¤šæ¬¡è¿è¡Œä¸ä¼šæŠ¥é”™) |

---

## ğŸ”— ä¸¤ä¸ªè„šæœ¬çš„å…³ç³»

```
æ–‡ä»¶ä¸Šä¼ æµç¨‹:

1ï¸âƒ£ ç”¨æˆ·ä¸Šä¼ PDF
   â†“
2ï¸âƒ£ inserted INTO uploaded_files (file_name, file_path, ...)
   â†“
3ï¸âƒ£ verify_new_parser.py éªŒè¯ (æµ‹è¯•ç¯èŠ‚)
   â”œâ”€ ParseEngine æå–æ–‡æœ¬
   â”œâ”€ EnhancedChapterExtractor æå–ç« èŠ‚
   â””â”€ ä¸å‚è€ƒTOCå¯¹æ¯” â†’ å¾—å‡ºå‡†ç¡®ç‡
   â†“
4ï¸âƒ£ INSERT INTO parsing_results (file_id, chapter_count, result_json, ...)
   â†“
5ï¸âƒ£ INSERT INTO knowledge_base (file_id, title, content, category, embedding, ...)
   â†“
âœ… ç³»ç»Ÿå‡†å¤‡å¥½è¿›è¡Œæ™ºèƒ½æ¨ç†
```

---

## â­ï¸ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

### ç«‹å³æ‰§è¡Œæ¸…å•:

- [ ] **è¿è¡Œinit_database.py** åˆå§‹åŒ–æ•°æ®åº“
  ```bash
  cd backend && python3 init_database.py
  ```

- [ ] **éªŒè¯æ•°æ®åº“è¡¨** é€šè¿‡psqlç¡®è®¤è¡¨å·²åˆ›å»º
  ```bash
  psql -U postgres -d bidding_db -c "\dt"
  ```

- [ ] **å‡†å¤‡æµ‹è¯•PDF** æ”¾å…¥ `/Volumes/ssd/bidding-data/uploads/`

- [ ] **è¿è¡Œverify_new_parser.py** æµ‹è¯•è§£æå‡†ç¡®ç‡
  ```bash
  cd backend && python3 verify_new_parser.py
  ```

- [ ] **æ£€æŸ¥SSDå­˜å‚¨** éªŒè¯æ‰€æœ‰æ–‡ä»¶å·²å†™å…¥
  ```bash
  du -sh /Volumes/ssd/bidding-data/*
  ```

---

**å‡†å¤‡æ‰§è¡Œè¿™äº›æ­¥éª¤å—?** æˆ‘å¯ä»¥é€æ­¥æŒ‡å¯¼æ‚¨è¿è¡Œè¿™äº›è„šæœ¬ã€‚
