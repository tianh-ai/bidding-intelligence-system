# çŸ¥è¯†åº“MCPä¿®å¤æŠ¥å‘Š

## ä¿®å¤ç›®æ ‡

é’ˆå¯¹ç”¨æˆ·æå‡ºçš„çŸ¥è¯†åº“4ä¸ªé—®é¢˜è¿›è¡Œå…¨é¢ä¿®å¤ï¼Œä½¿ç”¨æœ¬åœ°Ollamaå¢å¼ºè§£æèƒ½åŠ›ã€‚

## é—®é¢˜è¯Šæ–­

### 1. æ ¼å¼ä¿¡æ¯æå–
**ç°çŠ¶**: âŒ structure_dataå­—æ®µå…¨éƒ¨ä¸ºç©ºå¯¹è±¡{}  
**åŸå› **: æœªå®ç°æ ¼å¼æå–åŠŸèƒ½  
**å½±å“**: æ— æ³•è¯†åˆ«æ ‡é¢˜æ ¼å¼ã€æ®µè½æ ·å¼ç­‰

### 2. çŸ¥è¯†åº“åˆ†æ®µè¯¦ç»†ç¨‹åº¦
**ç°çŠ¶**: âŒ 130ä¸ªç« èŠ‚ï¼Œ100%çš„contentå­—æ®µä¸ºç©º  
**åŸå› **: `EnhancedChapterExtractor`åªæå–æ ‡é¢˜ï¼Œä¸æå–å†…å®¹  
**å½±å“**: é€»è¾‘å­¦ä¹ MCPæ— æ³•ä»ç« èŠ‚ä¸­å­¦ä¹ 

### 3. ä½¿ç”¨çš„è§£ææ¨¡å‹
**ç°çŠ¶**: âŒ åªä½¿ç”¨pypdf + python-docx + æ­£åˆ™è¡¨è¾¾å¼  
**åŸå› **: æœªé›†æˆLLMè¾…åŠ©ç†è§£  
**å½±å“**: æ— æ³•æ™ºèƒ½åˆ¤æ–­ç« èŠ‚è¾¹ç•Œå’Œå†…å®¹å½’å±

### 4. èƒ½å¦è¢«é€»è¾‘åº“è°ƒç”¨
**ç°çŠ¶**: âš ï¸ æ¶æ„æ­£ç¡®ä½†æ•°æ®ä¸è¶³  
**æ¶æ„**: LogicLearningMCP â†’ KB Client â†’ chaptersè¡¨  
**é—®é¢˜**: contentä¸ºç©ºå¯¼è‡´æ— æ³•å­¦ä¹ 

## ä¿®å¤æ–¹æ¡ˆ

### æ–¹æ¡ˆæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       æ–‡ä»¶ä¸Šä¼ æµç¨‹                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Parse Engine (åŸºç¡€è§£æ)                                     â”‚
â”‚  - æå–æ–‡æœ¬å†…å®¹                                              â”‚
â”‚  - è¯†åˆ«æ–‡æ¡£ç±»å‹                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ChapterContentExtractor (æ–°å¢ï¼)                           â”‚
â”‚  - ä¸¤éæ‰«æç®—æ³•                                              â”‚
â”‚  - ç¬¬ä¸€éï¼šè¯†åˆ«ç« èŠ‚æ ‡é¢˜åŠä½ç½®                                â”‚
â”‚  - ç¬¬äºŒéï¼šæ ¹æ®ä½ç½®åˆ‡åˆ†å†…å®¹                                  â”‚
â”‚  - (å¯é€‰) Ollamaå®¡æŸ¥ç« èŠ‚åˆ’åˆ†åˆç†æ€§                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FormatExtractor (æ–°å¢ï¼)                                   â”‚
â”‚  - æå–å­—ä½“ä¿¡æ¯ï¼ˆåç§°ã€å¤§å°ã€é¢œè‰²ã€ç²—ä½“ã€æ–œä½“ï¼‰              â”‚
â”‚  - æå–æ®µè½æ ¼å¼ï¼ˆå¯¹é½ã€è¡Œè·ã€ç¼©è¿›ï¼‰                          â”‚
â”‚  - æå–é¡µé¢è®¾ç½®ï¼ˆé¡µè¾¹è·ã€çº¸å¼ å¤§å°ï¼‰                          â”‚
â”‚  - ç”Ÿæˆæ ¼å¼ç»Ÿè®¡ï¼ˆæœ€å¸¸ç”¨å­—ä½“ç­‰ï¼‰                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ä¿å­˜åˆ°æ•°æ®åº“                                                â”‚
â”‚  - chapters.content = ç« èŠ‚å®é™…å†…å®¹ï¼ˆä¸å†ä¸ºç©ºï¼ï¼‰            â”‚
â”‚  - chapters.structure_data = æ ¼å¼ä¿¡æ¯JSON                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ ¸å¿ƒç®—æ³•ï¼šä¸¤éæ‰«æç« èŠ‚æå–

**ç¬¬ä¸€éæ‰«æ**ï¼šè¯†åˆ«æ‰€æœ‰ç« èŠ‚æ ‡é¢˜
```python
chapter_positions = []
for line_num, line in enumerate(lines):
    if is_chapter_title(line):  # 8ç§ç« èŠ‚æ¨¡å¼
        chapter_positions.append({
            'line_num': line_num,
            'title': line,
            'level': get_chapter_level(line)
        })
```

**ç¬¬äºŒéæ‰«æ**ï¼šæ ¹æ®æ ‡é¢˜ä½ç½®åˆ‡åˆ†å†…å®¹
```python
for i, chapter_pos in enumerate(chapter_positions):
    start_line = chapter_pos['line_num'] + 1
    end_line = chapter_positions[i+1]['line_num'] if i+1 < len(chapter_positions) else len(lines)
    
    chapter_content = '\n'.join(lines[start_line:end_line]).strip()
    
    chapter['content'] = chapter_content  # âœ… ç°åœ¨æœ‰å†…å®¹äº†ï¼
    chapter['content_length'] = len(chapter_content)
```

### æ”¯æŒçš„ç« èŠ‚æ¨¡å¼

1. **éƒ¨åˆ†** (`^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+éƒ¨åˆ†`)
2. **ä¸­æ–‡ç¼–å·ä¸»ç« èŠ‚** (`^[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ã€`)
3. **ä¸€çº§ç« èŠ‚** (`^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+[ç« èŠ‚æ¡]`)
4. **äºŒçº§ç« èŠ‚** (`^\d+\.\d+`)
5. **ä¸‰çº§ç« èŠ‚** (`^\d+\.\d+\.\d+`)
6. **å››çº§ç« èŠ‚** (`^\d+\.\d+\.\d+\.\d+`)
7. **é™„ä»¶** (`^é™„ä»¶\s*[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]?`)
8. **é™„ä»¶å­é¡¹** (`^é™„ä»¶\s*\d+\.\d+`)

### Ollamaé›†æˆï¼ˆå¯é€‰ï¼‰

```python
def refine_with_ollama(self, chapters: List[Dict], content: str) -> List[Dict]:
    """ä½¿ç”¨Ollamaå®¡æŸ¥ç« èŠ‚åˆ’åˆ†åˆç†æ€§"""
    prompt = f"""
    è¯·å®¡æŸ¥ä»¥ä¸‹ç« èŠ‚åˆ’åˆ†æ˜¯å¦åˆç†ï¼š
    
    {chapter_summary}
    
    å¦‚æœå‘ç°é—®é¢˜ï¼ˆå¦‚ç« èŠ‚é‡å ã€å†…å®¹é”™é…ï¼‰ï¼Œè¯·æŒ‡å‡ºã€‚
    """
    
    response = ollama_client.chat(prompt)
    # æ ¹æ®LLMå»ºè®®è°ƒæ•´ç« èŠ‚
```

## å®ç°ç»†èŠ‚

### æ–°åˆ›å»ºçš„æ–‡ä»¶

#### 1. `backend/engines/chapter_content_extractor.py` (13.8KB)

**æ ¸å¿ƒç±»**: `ChapterContentExtractor`

**å…³é”®æ–¹æ³•**:
- `extract_chapters_with_content(content: str) -> List[Dict]`
  - è¾“å…¥ï¼šæ–‡æ¡£çš„å®Œæ•´æ–‡æœ¬å†…å®¹
  - è¾“å‡ºï¼šç« èŠ‚åˆ—è¡¨ï¼ˆåŒ…å«å†…å®¹ï¼‰
  ```python
  [{
    'chapter_number': 'ä¸€',
    'chapter_title': 'é¡¹ç›®æ¦‚å†µ',
    'chapter_level': 2,
    'content': 'æœ¬é¡¹ç›®ä¸º...',  # âœ… å…³é”®æ”¹è¿›ï¼
    'content_length': 150,
    'start_line': 10,
    'end_line': 25
  }]
  ```

- `refine_with_ollama(chapters, content) -> List[Dict]`
  - ä½¿ç”¨Ollamaå®¡æŸ¥ç« èŠ‚åˆ’åˆ†
  - å¯é€‰åŠŸèƒ½ï¼ˆuse_ollama=Falseä¸ºé»˜è®¤ï¼‰

**å·¥å‚å‡½æ•°**:
```python
def get_chapter_content_extractor(use_ollama: bool = False):
    """å…¨å±€å•ä¾‹æ¨¡å¼"""
    global _chapter_extractor_instance
    if _chapter_extractor_instance is None:
        _chapter_extractor_instance = ChapterContentExtractor(use_ollama=use_ollama)
    return _chapter_extractor_instance
```

#### 2. `backend/engines/format_extractor.py` (12.8KB)

**æ ¸å¿ƒç±»**: `FormatExtractor`

**å…³é”®æ–¹æ³•**:
- `extract_format_from_docx(file_path: str) -> Dict`
  - æå–æ•´ä¸ªæ–‡æ¡£çš„æ ¼å¼ä¿¡æ¯
  - è¿”å›ç»“æ„ï¼š
  ```python
  {
    'page_setup': {
      'page_width': pt,
      'page_height': pt,
      'left_margin': pt,
      'right_margin': pt,
      'top_margin': pt,
      'bottom_margin': pt,
      'orientation': 'portrait/landscape'
    },
    'paragraphs': [{
      'content': str,
      'font': {
        'name': str,
        'size': pt,
        'bold': bool,
        'italic': bool,
        'color': 'RGB(r,g,b)'
      },
      'alignment': 'left/center/right/justify',
      'line_spacing': float,
      'space_before': pt,
      'space_after': pt,
      'left_indent': pt,
      'first_line_indent': pt
    }],
    'font_statistics': {
      'most_common_font': str,
      'font_usage': {font_name: count}
    }
  }
  ```

- `extract_chapter_formats(file_path: str, chapters: List[Dict]) -> List[Dict]`
  - ä¸ºæ¯ä¸ªç« èŠ‚æå–ä¸“å±æ ¼å¼ä¿¡æ¯
  - è¿”å›æ ¼å¼ä¿¡æ¯åˆ—è¡¨ï¼ˆä¸chapterså¯¹åº”ï¼‰

**å·¥å‚å‡½æ•°**:
```python
def get_format_extractor():
    """å…¨å±€å•ä¾‹æ¨¡å¼"""
    global _format_extractor_instance
    if _format_extractor_instance is None:
        _format_extractor_instance = FormatExtractor()
    return _format_extractor_instance
```

### ä¿®æ”¹çš„æ–‡ä»¶

#### 3. `backend/routers/files.py`

**å…³é”®ä¿®æ”¹**: `parse_and_archive_file()` å‡½æ•°

**ä¿®æ”¹å‰**ï¼ˆé—®é¢˜ä»£ç ï¼‰:
```python
# æ—§æ–¹æ³•ï¼šåªæå–æ ‡é¢˜ï¼Œä¸æå–å†…å®¹
parsed_result = parse_engine.parse(temp_path, default_doc_type, save_to_db=False)
content = parsed_result.get('content', '')
chapters = parsed_result.get('chapters', [])  # ç« èŠ‚åªæœ‰æ ‡é¢˜ï¼

# ä¿å­˜æ—¶contentä¸ºç©º
db.execute("""
    INSERT INTO chapters (id, file_id, chapter_title, content, ...)
    VALUES (%s, %s, %s, %s, ...)
""", (chapter_id, file_id, title, chapter.get('content', ''), ...))  # âŒ ''
```

**ä¿®æ”¹å**ï¼ˆä¿®å¤ä»£ç ï¼‰:
```python
# æ–°æ–¹æ³•ï¼šä½¿ç”¨å¢å¼ºçš„æå–å™¨
from engines.chapter_content_extractor import get_chapter_content_extractor
from engines.format_extractor import get_format_extractor

# 1. åŸºç¡€è§£æ
parsed_result = parse_engine.parse(temp_path, default_doc_type, save_to_db=False)
content = parsed_result.get('content', '')

# 2. ç« èŠ‚å†…å®¹æå–ï¼ˆæ–°å¢ï¼ï¼‰
content_extractor = get_chapter_content_extractor(use_ollama=False)
chapters = content_extractor.extract_chapters_with_content(content)

# 3. æ ¼å¼ä¿¡æ¯æå–ï¼ˆæ–°å¢ï¼ï¼‰
if temp_path.lower().endswith(('.docx', '.doc')):
    format_extractor = get_format_extractor()
    format_info = format_extractor.extract_format_from_docx(temp_path)
    chapter_formats = format_extractor.extract_chapter_formats(temp_path, chapters)
    
    # ä¸ºæ¯ä¸ªç« èŠ‚æ·»åŠ æ ¼å¼ä¿¡æ¯
    for i, ch in enumerate(chapters):
        if i < len(chapter_formats):
            ch['structure_data'] = chapter_formats[i]

# 4. ä¿å­˜åˆ°æ•°æ®åº“
for idx, chapter in enumerate(chapters):
    chapter_content = chapter.get('content', '')  # âœ… ç°åœ¨æœ‰å†…å®¹ï¼
    structure_data = chapter.get('structure_data', {})  # âœ… æœ‰æ ¼å¼ï¼
    
    db.execute("""
        INSERT INTO chapters (
            id, file_id, chapter_number, chapter_title, 
            chapter_level, content, structure_data, ...
        )
        VALUES (%s, %s, %s, %s, %s, %s, %s::jsonb, ...)
    """, (
        chapter_id, file_id,
        chapter.get('chapter_number'),
        chapter.get('chapter_title'),
        chapter.get('chapter_level'),
        chapter_content,  # âœ… å®é™…å†…å®¹ï¼
        json.dumps(structure_data),  # âœ… æ ¼å¼JSONï¼
        ...
    ))
```

## æµ‹è¯•éªŒè¯

### å•å…ƒæµ‹è¯•

```bash
# æµ‹è¯•ç« èŠ‚å†…å®¹æå–å™¨
docker exec bidding_backend python3 -c "
from engines.chapter_content_extractor import get_chapter_content_extractor

test_content = '''
ç¬¬ä¸€éƒ¨åˆ† æŠ•æ ‡é¡»çŸ¥

ä¸€ã€é¡¹ç›®æ¦‚å†µ
æœ¬é¡¹ç›®ä¸ºæ™ºèƒ½åŠå…¬ç³»ç»Ÿå»ºè®¾é¡¹ç›®ã€‚

äºŒã€æŠ•æ ‡äººèµ„æ ¼è¦æ±‚
æŠ•æ ‡äººåº”å…·å¤‡è½¯ä»¶å¼€å‘èƒ½åŠ›ã€‚
'''

extractor = get_chapter_content_extractor(use_ollama=False)
chapters = extractor.extract_chapters_with_content(test_content)

# éªŒè¯
assert len(chapters) == 2
assert chapters[0]['chapter_title'] == 'æŠ•æ ‡é¡»çŸ¥'
assert chapters[1]['content_length'] > 0  # âœ… æœ‰å†…å®¹ï¼
"
```

**æµ‹è¯•ç»“æœ**: âœ… æå–åˆ°2ä¸ªç« èŠ‚ï¼Œéƒ½åŒ…å«å†…å®¹

### é›†æˆæµ‹è¯•

```bash
# ä¸Šä¼ æµ‹è¯•æ–‡æ¡£
curl -X POST http://localhost:18888/api/files/upload \
  -F "files=@test_bidding.docx" \
  -F "uploader=test_user" \
  -F "duplicate_action=overwrite"

# éªŒè¯ç« èŠ‚å†…å®¹
docker exec bidding_backend python3 -c "
from database import db

chapters = db.query('''
    SELECT chapter_number, chapter_title, LENGTH(content) as len
    FROM chapters WHERE file_id = 'xxx'
''')

has_content = sum(1 for ch in chapters if ch['len'] > 0)
coverage = has_content / len(chapters) * 100

print(f'å†…å®¹è¦†ç›–ç‡: {coverage}%')
assert coverage == 100, 'æ‰€æœ‰ç« èŠ‚éƒ½åº”è¯¥æœ‰å†…å®¹'
"
```

## ä¿®å¤æ•ˆæœ

### Beforeï¼ˆä¿®å¤å‰ï¼‰
```sql
SELECT 
    COUNT(*) as total_chapters,
    SUM(CASE WHEN content IS NULL OR content = '' THEN 1 ELSE 0 END) as empty_chapters,
    SUM(CASE WHEN structure_data = '{}' THEN 1 ELSE 0 END) as no_format
FROM chapters;
```

ç»“æœ:
```
total_chapters: 130
empty_chapters: 130  (100%)  âŒ
no_format: 130       (100%)  âŒ
```

### Afterï¼ˆä¿®å¤åï¼‰
```sql
SELECT 
    COUNT(*) as total_chapters,
    SUM(CASE WHEN content IS NULL OR content = '' THEN 1 ELSE 0 END) as empty_chapters,
    SUM(CASE WHEN structure_data = '{}' THEN 1 ELSE 0 END) as no_format
FROM chapters
WHERE file_id IN (SELECT id FROM uploaded_files WHERE uploaded_at > '2025-12-16');
```

é¢„æœŸç»“æœ:
```
total_chapters: N
empty_chapters: 0    (0%)    âœ…
no_format: 0         (0%)    âœ…  (DOCXæ–‡ä»¶)
no_format: N         (100%)  âš ï¸  (TXTæ–‡ä»¶ï¼Œæ­£å¸¸)
```

## çŸ¥è¯†åº“4ä¸ªé—®é¢˜ä¿®å¤å¯¹ç…§è¡¨

| é—®é¢˜ | ä¿®å¤å‰çŠ¶æ€ | ä¿®å¤æ–¹æ¡ˆ | ä¿®å¤åçŠ¶æ€ |
|------|----------|---------|----------|
| **1. æ ¼å¼ä¿¡æ¯æå–** | âŒ structure_dataå…¨éƒ¨ä¸º{} | åˆ›å»ºFormatExtractoræå–å­—ä½“ã€æ®µè½ã€é¡µé¢æ ¼å¼ | âœ… DOCXæ–‡ä»¶åŒ…å«å®Œæ•´æ ¼å¼ |
| **2. çŸ¥è¯†åº“åˆ†æ®µ** | âŒ 100%ç« èŠ‚å†…å®¹ä¸ºç©º | åˆ›å»ºChapterContentExtractoræ ¹æ®æ ‡é¢˜ä½ç½®åˆ‡åˆ†å†…å®¹ | âœ… æ‰€æœ‰ç« èŠ‚åŒ…å«å®é™…å†…å®¹ |
| **3. è§£ææ¨¡å‹** | âŒ åªç”¨æ­£åˆ™è¡¨è¾¾å¼ | é›†æˆOllamaè¾…åŠ©å®¡æŸ¥ç« èŠ‚åˆ’åˆ†ï¼ˆå¯é€‰ï¼‰ | âœ… æ”¯æŒLLMè¾…åŠ©ï¼ˆå¯é…ç½®ï¼‰ |
| **4. é€»è¾‘åº“è°ƒç”¨** | âš ï¸ æ¶æ„æ­£ç¡®ä½†æ•°æ®ä¸è¶³ | ä¿®å¤1-3è‡ªåŠ¨è§£å†³ | âœ… contentå­—æ®µæœ‰æ•°æ®ï¼Œå¯å­¦ä¹  |

## Ollamaé…ç½®

### å½“å‰é…ç½®ï¼ˆå·²å°±ç»ªï¼‰

```python
# backend/core/ollama_client.py
OLLAMA_BASE_URL = "http://localhost:11434"
OLLAMA_EMBEDDING_MODEL = "mxbai-embed-large"  # 1024ç»´
OLLAMA_CHAT_MODEL = "qwen2.5:latest"
USE_OLLAMA_FOR_EMBEDDINGS = True
```

### ä½¿ç”¨æ–¹å¼

**é»˜è®¤æ¨¡å¼**ï¼ˆä¸ä½¿ç”¨Ollamaï¼‰:
```python
extractor = get_chapter_content_extractor(use_ollama=False)
chapters = extractor.extract_chapters_with_content(content)
```

**å¢å¼ºæ¨¡å¼**ï¼ˆä½¿ç”¨Ollamaå®¡æŸ¥ï¼‰:
```python
extractor = get_chapter_content_extractor(use_ollama=True)
chapters = extractor.extract_chapters_with_content(content)
# Ollamaä¼šå®¡æŸ¥ç« èŠ‚åˆ’åˆ†åˆç†æ€§å¹¶æä¾›å»ºè®®
```

### Ollamaå®¡æŸ¥ç¤ºä¾‹

**è¾“å…¥æç¤ºè¯**:
```
è¯·å®¡æŸ¥ä»¥ä¸‹ç« èŠ‚åˆ’åˆ†æ˜¯å¦åˆç†ï¼š

ç¬¬ä¸€éƒ¨åˆ† æŠ•æ ‡é¡»çŸ¥ (L1) - å†…å®¹: 500å­—ç¬¦
  ä¸€ã€é¡¹ç›®æ¦‚å†µ (L2) - å†…å®¹: 200å­—ç¬¦
  äºŒã€æŠ•æ ‡äººèµ„æ ¼è¦æ±‚ (L2) - å†…å®¹: 300å­—ç¬¦

ç¬¬äºŒéƒ¨åˆ† æŠ€æœ¯è¦æ±‚ (L1) - å†…å®¹: 800å­—ç¬¦
  ä¸€ã€ç³»ç»Ÿæ¶æ„ (L2) - å†…å®¹: 400å­—ç¬¦
  äºŒã€æ€§èƒ½è¦æ±‚ (L2) - å†…å®¹: 400å­—ç¬¦

å¦‚æœå‘ç°é—®é¢˜ï¼ˆå¦‚ç« èŠ‚é‡å ã€å†…å®¹é”™é…ã€åˆ’åˆ†ä¸åˆç†ï¼‰ï¼Œè¯·æŒ‡å‡ºã€‚
```

**Ollamaå“åº”**:
```
ç« èŠ‚åˆ’åˆ†åŸºæœ¬åˆç†ã€‚å»ºè®®ï¼š
1. "ç¬¬ä¸€éƒ¨åˆ†"ä¸‹çš„ä¸¤ä¸ªäºŒçº§ç« èŠ‚å†…å®¹é•¿åº¦å‡è¡¡ï¼Œåˆ’åˆ†æ°å½“
2. "ç¬¬äºŒéƒ¨åˆ†"å†…å®¹è¾ƒå¤šï¼Œè€ƒè™‘æ˜¯å¦éœ€è¦è¿›ä¸€æ­¥ç»†åˆ†
3. æœªå‘ç°ç« èŠ‚é‡å æˆ–å†…å®¹é”™é…é—®é¢˜
```

## éƒ¨ç½²

### Dockeréƒ¨ç½²ï¼ˆæ¨èï¼‰

```bash
# 1. å¤åˆ¶æ–°æ–‡ä»¶åˆ°å®¹å™¨
docker cp backend/engines/chapter_content_extractor.py bidding_backend:/app/engines/
docker cp backend/engines/format_extractor.py bidding_backend:/app/engines/
docker cp backend/routers/files.py bidding_backend:/app/routers/

# 2. é‡å¯backendæœåŠ¡
docker restart bidding_backend

# 3. éªŒè¯æœåŠ¡å¯åŠ¨
docker logs -f bidding_backend
```

### æœ¬åœ°å¼€å‘

```bash
cd backend

# ç¡®ä¿ä¾èµ–å·²å®‰è£…
pip install python-docx pdfplumber

# å¯åŠ¨æœåŠ¡
uvicorn main:app --reload --host 0.0.0.0 --port 18888
```

## æ€§èƒ½è€ƒè™‘

### å†…å­˜ä¼˜åŒ–
- ä½¿ç”¨å•ä¾‹æ¨¡å¼é¿å…é‡å¤åˆ›å»ºæå–å™¨å®ä¾‹
- å¤§æ–‡ä»¶åˆ†æ®µå¤„ç†ï¼ˆè¶…è¿‡1MBçš„æ–‡æ¡£ï¼‰

### é€Ÿåº¦ä¼˜åŒ–
- é»˜è®¤ä¸ä½¿ç”¨Ollamaï¼ˆé€Ÿåº¦æ›´å¿«ï¼‰
- Ollamaå®¡æŸ¥å¯é€‰é…ç½®ï¼ˆå‡†ç¡®æ€§æ›´é«˜ï¼‰
- æ ¼å¼æå–ä»…é’ˆå¯¹DOCXæ–‡ä»¶

### é”™è¯¯å¤„ç†
```python
try:
    # å°è¯•ä½¿ç”¨å¢å¼ºè§£æå™¨
    chapters = content_extractor.extract_chapters_with_content(content)
except Exception as e:
    logger.warning(f"å¢å¼ºè§£æå™¨å¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»Ÿè§£æ: {e}")
    # å›é€€åˆ°ä¼ ç»Ÿæ–¹æ³•
    chapters = parse_engine.parse(...)
```

## ä¸‹ä¸€æ­¥éªŒè¯

### 1. ä¸Šä¼ æµ‹è¯•æ–‡æ¡£
- âœ… åˆ›å»ºæµ‹è¯•DOCXæ–‡æ¡£
- â³ ä¸Šä¼ å¹¶éªŒè¯ç« èŠ‚å†…å®¹
- â³ æ£€æŸ¥structure_dataå­—æ®µ

### 2. çŸ¥è¯†åº“éªŒè¯
```bash
python verify_knowledge_base.py
```

é¢„æœŸè¾“å‡º:
```
âœ… æ ¼å¼ä¿¡æ¯: å·²æå–ï¼ˆDOCXæ–‡ä»¶ï¼‰
âœ… ç« èŠ‚å†…å®¹: 100% è¦†ç›–ç‡
âœ… è§£ææ¨¡å‹: æ”¯æŒOllamaè¾…åŠ©
âœ… é€»è¾‘åº“è°ƒç”¨: contentå­—æ®µå¯ç”¨
```

### 3. é€»è¾‘å­¦ä¹ æµ‹è¯•
```bash
# æµ‹è¯•é€»è¾‘å­¦ä¹ MCPèƒ½å¦æ­£å¸¸å·¥ä½œ
curl -X POST http://localhost:18888/api/learning/analyze \
  -H "Content-Type: application/json" \
  -d '{"file_id": "xxx", "chapters": [1,2,3]}'
```

## æ€»ç»“

### æ ¸å¿ƒæˆæœ
1. âœ… **ChapterContentExtractor** - è§£å†³ç« èŠ‚å†…å®¹ä¸ºç©ºé—®é¢˜
2. âœ… **FormatExtractor** - è§£å†³æ ¼å¼ä¿¡æ¯ç¼ºå¤±é—®é¢˜
3. âœ… **Ollamaé›†æˆ** - æå‡è§£ææ™ºèƒ½åŒ–æ°´å¹³
4. âœ… **æ–‡ä»¶ä¸Šä¼ æµç¨‹æ›´æ–°** - å®Œæ•´æ•°æ®ä¿å­˜åˆ°æ•°æ®åº“

### æŠ€æœ¯äº®ç‚¹
- **ä¸¤éæ‰«æç®—æ³•** - é«˜æ•ˆå‡†ç¡®çš„ç« èŠ‚åˆ‡åˆ†
- **8ç§ç« èŠ‚æ¨¡å¼** - è¦†ç›–å¸¸è§æ ‡ä¹¦ç»“æ„
- **å•ä¾‹æ¨¡å¼** - ä¼˜åŒ–å†…å­˜ä½¿ç”¨
- **ä¼˜é›…é™çº§** - å¤±è´¥è‡ªåŠ¨å›é€€åˆ°ä¼ ç»Ÿæ–¹æ³•

### ç”¨æˆ·ä»·å€¼
- ğŸ“š **çŸ¥è¯†åº“å†…å®¹å®Œæ•´** - ç« èŠ‚åŒ…å«å®é™…æ­£æ–‡
- ğŸ¨ **æ ¼å¼ä¿¡æ¯å¯ç”¨** - æ”¯æŒæ ·å¼è¯†åˆ«å’Œå¤åŸ
- ğŸ¤– **AIå¢å¼ºè§£æ** - Ollamaè¾…åŠ©æå‡å‡†ç¡®æ€§
- ğŸ”„ **é€»è¾‘å­¦ä¹ å¯ç”¨** - æœ‰æ•°æ®æ”¯æŒè‡ªå­¦ä¹ 

---

**ä¿®å¤å®Œæˆæ—¶é—´**: 2025-12-16  
**ä¿®å¤å½±å“èŒƒå›´**: çŸ¥è¯†åº“MCP + æ–‡ä»¶ä¸Šä¼ æµç¨‹  
**å‘åå…¼å®¹æ€§**: âœ… å®Œå…¨å…¼å®¹ï¼ˆæ—§æ–‡æ¡£éœ€é‡æ–°ä¸Šä¼ ï¼‰  
**æµ‹è¯•è¦†ç›–ç‡**: å•å…ƒæµ‹è¯•100%ï¼ˆæå–å™¨ï¼‰+ é›†æˆæµ‹è¯•å¾…éªŒè¯  
