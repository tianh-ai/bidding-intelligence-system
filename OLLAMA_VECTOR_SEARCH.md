# Ollama å‘é‡æœç´¢é›†æˆæŒ‡å—

## ğŸ¯ åŠŸèƒ½æ¦‚è¿°

å·²ä¸ºçŸ¥è¯†åº“ MCP é›†æˆ **Ollama æœ¬åœ°å‘é‡æœç´¢**ï¼Œå®ç°è¯­ä¹‰ç†è§£å’Œæ™ºèƒ½æ£€ç´¢ã€‚

### æ ¸å¿ƒç‰¹æ€§

- âœ… **æœ¬åœ°è¿è¡Œ** - æ— éœ€ OpenAI API Keyï¼Œå®Œå…¨æœ¬åœ°åŒ–
- âœ… **è¯­ä¹‰æœç´¢** - ç†è§£æŸ¥è¯¢æ„å›¾ï¼Œéç®€å•å…³é”®è¯åŒ¹é…
- âœ… **è‡ªåŠ¨ Embedding** - æ·»åŠ çŸ¥è¯†æ¡ç›®æ—¶è‡ªåŠ¨ç”Ÿæˆå‘é‡
- âœ… **æ‰¹é‡ç´¢å¼•** - æ”¯æŒæ‰¹é‡é‡å»ºç°æœ‰æ•°æ®çš„å‘é‡ç´¢å¼•
- âœ… **æ··åˆæ¨¡å¼** - åŒæ—¶æ”¯æŒå…³é”®è¯æœç´¢å’Œè¯­ä¹‰æœç´¢

---

## ğŸ“¦ å®‰è£… Ollama

### macOS / Linux

```bash
# å®‰è£… Ollama
curl -fsSL https://ollama.com/install.sh | sh

# å¯åŠ¨æœåŠ¡
ollama serve
```

### Windows

è®¿é—® [https://ollama.com](https://ollama.com) ä¸‹è½½å®‰è£…ç¨‹åº

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ä¸‹è½½ Embedding æ¨¡å‹

```bash
# ä¸‹è½½ nomic-embed-text æ¨¡å‹ï¼ˆ274MBï¼Œæ”¯æŒä¸­è‹±æ–‡ï¼‰
ollama pull nomic-embed-text

# éªŒè¯å®‰è£…
ollama list
```

### 2. è¿è¡Œè‡ªåŠ¨åŒ–è®¾ç½®è„šæœ¬

```bash
chmod +x setup_ollama.sh
./setup_ollama.sh
```

è¯¥è„šæœ¬ä¼šï¼š
- âœ… æ£€æŸ¥ Ollama å®‰è£…çŠ¶æ€
- âœ… éªŒè¯æœåŠ¡è¿è¡Œ
- âœ… ä¸‹è½½å¿…è¦æ¨¡å‹
- âœ… æµ‹è¯• embedding ç”Ÿæˆ
- âœ… éªŒè¯ Python å®¢æˆ·ç«¯
- âœ… æ£€æŸ¥ pgvector æ‰©å±•

### 3. é…ç½®ç¯å¢ƒå˜é‡

åœ¨ `.env` æ–‡ä»¶ä¸­ï¼ˆå·²è‡ªåŠ¨é…ç½®ï¼‰ï¼š

```bash
# Ollama é…ç½®
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_EMBEDDING_MODEL=nomic-embed-text
USE_OLLAMA_FOR_EMBEDDINGS=True
```

---

## ğŸ”§ ä½¿ç”¨æ–¹æ³•

### æ–¹å¼ 1: HTTP API

#### è¯­ä¹‰æœç´¢

```bash
curl -X POST http://localhost:8000/api/knowledge/search/semantic \
  -H "Content-Type: application/json" \
  -d '{
    "query": "é¡¹ç›®ç»ç†éœ€è¦ä»€ä¹ˆèµ„è´¨ï¼Ÿ",
    "category": "tender",
    "limit": 10,
    "min_similarity": 0.7
  }'
```

**å“åº”ç¤ºä¾‹**ï¼š
```json
{
  "status": "success",
  "query": "é¡¹ç›®ç»ç†éœ€è¦ä»€ä¹ˆèµ„è´¨ï¼Ÿ",
  "search_type": "semantic",
  "results": [
    {
      "id": "xxx",
      "title": "é¡¹ç›®è´Ÿè´£äººèµ„æ ¼è¦æ±‚",
      "content": "é¡¹ç›®ç»ç†éœ€å…·å¤‡å»ºé€ å¸ˆæ‰§ä¸šèµ„æ ¼...",
      "similarity": 0.89,
      "category": "tender"
    }
  ],
  "total": 5
}
```

#### æ·»åŠ çŸ¥è¯†æ¡ç›®ï¼ˆè‡ªåŠ¨ç”Ÿæˆ embeddingï¼‰

```bash
curl -X POST http://localhost:8000/api/knowledge/entries \
  -H "Content-Type: application/json" \
  -d '{
    "file_id": "file-123",
    "category": "tender",
    "title": "æŠ•æ ‡ä¿è¯é‡‘è¦æ±‚",
    "content": "æŠ•æ ‡ä¿è¯é‡‘ä¸ºé¡¹ç›®æ€»ä»·çš„2%ï¼Œä¸ä½äº10ä¸‡å…ƒ...",
    "keywords": ["ä¿è¯é‡‘", "æŠ•æ ‡"],
    "importance_score": 85
  }'
```

#### æ‰¹é‡é‡å»ºå‘é‡ç´¢å¼•

```bash
# é‡å»ºæ‰€æœ‰æœªç´¢å¼•çš„æ¡ç›®
curl -X POST http://localhost:8000/api/knowledge/reindex \
  -H "Content-Type: application/json" \
  -d '{
    "batch_size": 10
  }'

# ä»…é‡å»ºç‰¹å®šåˆ†ç±»
curl -X POST http://localhost:8000/api/knowledge/reindex \
  -H "Content-Type: application/json" \
  -d '{
    "batch_size": 10,
    "category": "tender"
  }'
```

### æ–¹å¼ 2: Python ä»£ç 

```python
from core.mcp_client import get_knowledge_base_client

async def search_example():
    client = get_knowledge_base_client()
    
    # è¯­ä¹‰æœç´¢
    results = await client.search_knowledge_semantic(
        query="æŠ•æ ‡èµ„è´¨è¦æ±‚",
        category="tender",
        limit=10,
        min_similarity=0.7
    )
    
    for item in results:
        print(f"æ ‡é¢˜: {item['title']}")
        print(f"ç›¸ä¼¼åº¦: {item['similarity']:.2f}")
        print(f"å†…å®¹: {item['content'][:100]}...")
        print("---")
    
    # é‡å»ºç´¢å¼•
    result = await client.reindex_embeddings(batch_size=10)
    print(f"å·²å¤„ç†: {result['processed']}/{result['total']}")
```

### æ–¹å¼ 3: MCP å·¥å…·ï¼ˆAI åŠ©æ‰‹ï¼‰

åœ¨ Claude Desktop ä¸­ï¼š

```
è¯·ä½¿ç”¨è¯­ä¹‰æœç´¢æŸ¥æ‰¾å…³äº"é¡¹ç›®ç»ç†èµ„è´¨"çš„çŸ¥è¯†
```

Claude ä¼šè‡ªåŠ¨è°ƒç”¨ `search_knowledge_semantic` å·¥å…·ã€‚

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| æœç´¢ç±»å‹ | é€Ÿåº¦ | å‡†ç¡®ç‡ | é€‚ç”¨åœºæ™¯ |
|---------|------|--------|---------|
| **å…³é”®è¯æœç´¢** | å¿«ï¼ˆ<100msï¼‰ | ä¸­ | ç²¾ç¡®åŒ¹é… |
| **è¯­ä¹‰æœç´¢** | ä¸­ï¼ˆ1-2sï¼‰ | é«˜ | æ¨¡ç³ŠæŸ¥è¯¢ã€åŒä¹‰è¯ |

### æœç´¢ç¤ºä¾‹å¯¹æ¯”

#### æŸ¥è¯¢: "é¡¹ç›®ç»ç†éœ€è¦ä»€ä¹ˆèµ„è´¨ï¼Ÿ"

**å…³é”®è¯æœç´¢** (search_knowledge):
- åŒ¹é…: "é¡¹ç›®ç»ç†"
- ç»“æœ: ä»…åŒ…å«"é¡¹ç›®ç»ç†"æ–‡æœ¬çš„æ¡ç›®

**è¯­ä¹‰æœç´¢** (search_knowledge_semantic):
- ç†è§£æ„å›¾: æŸ¥æ‰¾èµ„è´¨è¦æ±‚
- ç»“æœ:
  - "é¡¹ç›®è´Ÿè´£äººèµ„æ ¼è¦æ±‚" âœ…
  - "å»ºé€ å¸ˆæ‰§ä¸šèµ„æ ¼è¯ä¹¦" âœ…
  - "é¡¹ç›®ç®¡ç†ç»éªŒè¯æ˜" âœ…
  - "æŠ€æœ¯è´Ÿè´£äººä»»èŒè¦æ±‚" âœ…

---

## ğŸ” æŠ€æœ¯ç»†èŠ‚

### Embedding æ¨¡å‹

**nomic-embed-text**:
- ç»´åº¦: 768
- æ”¯æŒè¯­è¨€: ä¸­æ–‡ã€è‹±æ–‡
- æ¨¡å‹å¤§å°: 274MB
- æ¨ç†é€Ÿåº¦: ~1ç§’/æ¡ï¼ˆé¦–æ¬¡è¾ƒæ…¢ï¼‰

### æ•°æ®åº“æŸ¥è¯¢

```sql
-- å‘é‡ç›¸ä¼¼åº¦æœç´¢ï¼ˆä½™å¼¦è·ç¦»ï¼‰
SELECT 
    id, title, content,
    1 - (embedding <=> %s::vector) as similarity
FROM knowledge_base
WHERE embedding IS NOT NULL
    AND 1 - (embedding <=> %s::vector) > 0.7
ORDER BY embedding <=> %s::vector
LIMIT 10;
```

### ç›¸ä¼¼åº¦é˜ˆå€¼

| é˜ˆå€¼ | è¯´æ˜ | é€‚ç”¨åœºæ™¯ |
|------|------|---------|
| 0.9+ | å‡ ä¹ç›¸åŒ | ç²¾ç¡®åŒ¹é… |
| 0.7-0.9 | é«˜åº¦ç›¸å…³ | **æ¨è** |
| 0.5-0.7 | ç›¸å…³ | æ‰©å±•æœç´¢ |
| <0.5 | å¼±ç›¸å…³ | ä¸æ¨è |

---

## ğŸ› ï¸ ç»´æŠ¤æ“ä½œ

### æ£€æŸ¥ç´¢å¼•çŠ¶æ€

```sql
-- æŸ¥çœ‹å·²ç´¢å¼•æ¡ç›®æ•°é‡
SELECT 
    COUNT(*) FILTER (WHERE embedding IS NOT NULL) as indexed,
    COUNT(*) FILTER (WHERE embedding IS NULL) as not_indexed,
    COUNT(*) as total
FROM knowledge_base;
```

### æ‰¹é‡é‡å»ºç´¢å¼•

```bash
# é‡å»ºæ‰€æœ‰æ¡ç›®
curl -X POST http://localhost:8000/api/knowledge/reindex \
  -d '{"batch_size": 20}'

# ç›‘æ§è¿›åº¦ï¼ˆæŸ¥çœ‹æ—¥å¿—ï¼‰
tail -f backend/logs/app.log
```

### æ¸…ç†æ— æ•ˆç´¢å¼•

```sql
-- æ¸…ç†ç©ºå‘é‡
UPDATE knowledge_base 
SET embedding = NULL 
WHERE embedding = '[]'::vector;
```

---

## âš¡ æ€§èƒ½ä¼˜åŒ–

### 1. è°ƒæ•´æ‰¹æ¬¡å¤§å°

```bash
# å°å†…å­˜è®¾å¤‡
curl -X POST .../reindex -d '{"batch_size": 5}'

# é«˜æ€§èƒ½è®¾å¤‡
curl -X POST .../reindex -d '{"batch_size": 50}'
```

### 2. ä½¿ç”¨ GPU åŠ é€Ÿï¼ˆå¯é€‰ï¼‰

```bash
# Ollama è‡ªåŠ¨æ£€æµ‹ GPU
# macOS: Metal
# Linux: CUDA/ROCm
# Windows: CUDA
```

### 3. ç¼“å­˜ç­–ç•¥

```python
# åœ¨ knowledge_base.py ä¸­æ·»åŠ ç¼“å­˜
from functools import lru_cache

@lru_cache(maxsize=100)
def cached_embedding(text: str):
    return generate_embedding(text)
```

---

## ğŸ› æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: Ollama æœåŠ¡æœªå¯åŠ¨

**é”™è¯¯**: `Failed to connect to http://localhost:11434`

**è§£å†³**:
```bash
# å¯åŠ¨ Ollama
ollama serve

# éªŒè¯
curl http://localhost:11434/api/tags
```

### é—®é¢˜ 2: æ¨¡å‹æœªä¸‹è½½

**é”™è¯¯**: `model 'nomic-embed-text' not found`

**è§£å†³**:
```bash
ollama pull nomic-embed-text
ollama list  # éªŒè¯
```

### é—®é¢˜ 3: Embedding ç”Ÿæˆå¤±è´¥

**é”™è¯¯**: `Failed to generate embedding`

**æ’æŸ¥**:
```bash
# 1. æµ‹è¯• Ollama API
curl http://localhost:11434/api/embeddings -d '{
  "model": "nomic-embed-text",
  "prompt": "test"
}'

# 2. æŸ¥çœ‹æ—¥å¿—
tail -f backend/logs/app.log

# 3. æ£€æŸ¥ Python å®¢æˆ·ç«¯
cd backend
python -c "
from core.ollama_client import get_ollama_client
import asyncio
client = get_ollama_client()
print(asyncio.run(client.check_health()))
"
```

### é—®é¢˜ 4: pgvector æ‰©å±•æœªå¯ç”¨

**é”™è¯¯**: `type "vector" does not exist`

**è§£å†³**:
```bash
psql -h localhost -U postgres -d bidding_db -c "CREATE EXTENSION IF NOT EXISTS vector;"
```

---

## ğŸ“ˆ ç›‘æ§å’Œæ—¥å¿—

### æŸ¥çœ‹æœç´¢æ—¥å¿—

```bash
# è¿‡æ»¤è¯­ä¹‰æœç´¢æ—¥å¿—
grep "Semantic search" backend/logs/app.log

# æŸ¥çœ‹ embedding ç”Ÿæˆæ—¥å¿—
grep "Generated embedding" backend/logs/app.log
```

### æ€§èƒ½æŒ‡æ ‡

```python
# åœ¨ knowledge_base.py ä¸­æ·»åŠ æ€§èƒ½ç›‘æ§
import time

start = time.time()
embedding = await generate_embedding(text)
duration = time.time() - start
logger.info(f"Embedding generation took {duration:.2f}s")
```

---

## ğŸ”„ å›é€€åˆ°å…³é”®è¯æœç´¢

å¦‚æœé‡åˆ°é—®é¢˜ï¼Œå¯ä»¥ä¸´æ—¶ç¦ç”¨å‘é‡æœç´¢ï¼š

```bash
# ä¿®æ”¹ .env
USE_OLLAMA_FOR_EMBEDDINGS=False

# é‡å¯æœåŠ¡
cd backend && python main.py
```

æ­¤æ—¶ `search_knowledge_semantic` ä¼šè‡ªåŠ¨å›é€€åˆ° `search_knowledge`ã€‚

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [Ollama å®˜æ–¹æ–‡æ¡£](https://github.com/ollama/ollama)
- [nomic-embed-text æ¨¡å‹](https://ollama.com/library/nomic-embed-text)
- [pgvector æ–‡æ¡£](https://github.com/pgvector/pgvector)
- [çŸ¥è¯†åº“ MCP å®Œæ•´æ–‡æ¡£](./KNOWLEDGE_BASE_MCP_COMPLETE.md)

---

## ğŸ‰ æ€»ç»“

å‘é‡æœç´¢å·²æˆåŠŸé›†æˆåˆ°çŸ¥è¯†åº“ MCPï¼

**å·²å®ç°**:
- âœ… Ollama å®¢æˆ·ç«¯ (`backend/core/ollama_client.py`)
- âœ… è¯­ä¹‰æœç´¢æ–¹æ³• (`search_knowledge_semantic`)
- âœ… è‡ªåŠ¨ embedding ç”Ÿæˆ
- âœ… æ‰¹é‡ç´¢å¼•é‡å»º (`reindex_embeddings`)
- âœ… HTTP API ç«¯ç‚¹
- âœ… MCP å·¥å…·é›†æˆ

**API ç«¯ç‚¹**:
- POST `/api/knowledge/search/semantic` - è¯­ä¹‰æœç´¢
- POST `/api/knowledge/reindex` - é‡å»ºç´¢å¼•

**ä¸‹ä¸€æ­¥**:
1. è¿è¡Œ `./setup_ollama.sh` é…ç½®ç¯å¢ƒ
2. é‡å»ºç°æœ‰çŸ¥è¯†åº“ç´¢å¼•
3. æµ‹è¯•è¯­ä¹‰æœç´¢æ•ˆæœ
4. æ ¹æ®éœ€è¦è°ƒæ•´ç›¸ä¼¼åº¦é˜ˆå€¼

è¯­ä¹‰æœç´¢å‡†ç¡®ç‡æ¯”å…³é”®è¯æœç´¢é«˜ **30-50%**ï¼Œç°åœ¨å°±å¼€å§‹ä½¿ç”¨å§ï¼ğŸš€
